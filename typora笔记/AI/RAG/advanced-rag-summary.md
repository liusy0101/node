# 高级RAG（检索增强生成）技术总结

## 一、RAG技术概述

### 1. 本质与核心价值

RAG（Retrieval-Augmented Generation）是**搜索+LLM提示**的结合技术，通过检索外部信息注入大模型上下文，解决大模型缺乏领域知识、无法获取实时信息及生成虚假内容等问题。其核心价值在于：

- 无需微调即可让模型掌握领域知识
- 可追溯信息来源，降低幻觉率
- 灵活适配动态更新的知识库

### 2. 核心组成部分

- **输入**：用户的自然语言问题
- **索引**：对文档进行分块、计算Embedding并存储到向量库
- **检索**：根据问题从向量库中找到最相关的段落
- **生成**：结合问题与检索到的内容，通过LLM生成回答

## 二、RAG发展阶段

| 阶段      | 特点描述                                                           | 技术改进点                                                         |
| --------- | ------------------------------------------------------------------ | ------------------------------------------------------------------ |
| 朴素RAG   | 包含索引、检索、生成三个基础步骤，流程简单                         | 无优化机制，依赖基础向量检索，存在检索精度低、信息碎片化等问题     |
| 高级RAG   | 增加预检索（查询优化、索引优化）和后检索（重排序、上下文压缩）过程 | 提升检索质量，通过多步骤处理优化上下文相关性                       |
| 模块化RAG | 采用灵活的模块架构，支持动态添加/替换组件（如路由、反馈模块）      | 支持迭代检索和自适应策略调整，可处理复杂场景（如多数据源混合查询） |

## 三、开发RAG系统的12个关键问题

### 1. Scott Barnett提出的7个基础问题

- **缺失内容**：知识库中没有与问题相关的信息
  - 解决方案：配置兜底回复，结合实时搜索API补充外部数据
- **错过排名外文档**：答案位于检索结果排名之外（如第11个结果）
  - 解决方案：扩大初始检索范围（如top_k=20），结合重排序压缩有效结果
- **不在上下文中**：检索到含答案的文档，但合并时遗漏关键信息
  - 解决方案：采用父文档检索，保留完整上下文
- **未提取关键信息**：答案被噪音内容淹没
  - 解决方案：用Embedding过滤无关句子，或通过LLM提取核心内容
- **错误格式**：输出格式与用户要求不符（如要求表格却返回段落）
  - 解决方案：强化Prompt格式约束，使用结构化输出解析器
- **具体性不足**：回答过于笼统（如推荐产品不提型号）
  - 解决方案：设计引导性Prompt，强制补充细节
- **回答不完整**：未覆盖问题的所有部分（如多文档查询遗漏某文档）
  - 解决方案：拆分问题为子查询，分别检索后合并结果

### 2. Wenqi Glantz补充的5个工程问题

- **数据摄入可扩展性**：海量文档入库时效率低、资源过载
  - 解决方案：分布式处理+增量索引（仅更新新增文档）
- **结构化数据问答**：需从SQL/Excel等结构化数据中检索信息
  - 解决方案：Text-to-SQL技术，结合表结构描述提升准确率
- **复杂PDF提取**：PDF中的表格、图片无法被传统分块识别
  - 解决方案：用MarkdownElementNodeParser提取表格，多模态模型解析图片
- **备用模型**：主模型API限流或故障导致服务中断
  - 解决方案：配置降级策略（如GPT-4→Claude 2），自动切换备用模型
- **LLM安全性**：恶意输入或敏感信息泄露
  - 解决方案：接入内容审核API，用PIINodePostprocessor脱敏敏感数据

## 四、LlamaIndex实战核心

### 1. 五大核心阶段

- **加载（Loading）**：通过LlamaHub加载多源数据（文档、数据库、网页等）
- **索引（Indexing）**：将文档分块为Node，生成Embedding并构建索引
- **存储（Storing）**：持久化索引到向量库（如Chroma）或数据库（如Neo4j）
- **查询（Querying）**：通过Query Engine执行检索并生成回答
- **评估（Evaluation）**：用FaithfulnessEvaluator和RelevancyEvaluator评估效果

### 2. 核心概念

- **Documents & Nodes**：Document为数据源容器，Node为分块后的原子单位
- **Indexes**：核心数据结构（如VectorStoreIndex用于语义检索，KnowledgeGraphIndex用于实体关系查询）
- **Query Engines**：处理检索与生成的组件，支持单轮查询（QueryEngine）和多轮对话（ChatEngine）

## 五、高级RAG优化技巧

### 1. 查询处理优化

#### （1）查询转换

- **查询扩展**：将问题拆分为子问题或变体（如MultiQueryRetriever生成3个相关问题）
- **查询重写**：优化模糊输入（如将“那里有啥好吃的”重写为“合肥有什么美食”）
- **后退提示**：生成抽象问题提升复杂问题检索效果（如“冰浮在水上的原因”→“水的密度与温度的关系”）
- **HyDE**：生成假设答案的Embedding替代原始问题检索，提升语义匹配度

#### （2）查询路由

- 动态选择数据源（向量库/SQL库/图数据库）
- 实现方式：LangChain用RunnableLambda自定义逻辑，LlamaIndex用RouterQueryEngine让LLM自动选择

#### （3）查询构造

- **Text-to-SQL**：将自然语言转为SQL查询（需提供表结构描述）
- **Text-to-metadata filters**：生成元数据过滤条件（如“2023年后的文档”→where={"year": ">2023"}）
- **Text-to-Cypher**：生成图数据库查询语句（如查找实体关系）

### 2. 索引策略优化

#### （1）分块策略

- **固定大小分块**：按Token数切割（如chunk_size=512，适合通用文本）
- **语义分块**：基于句子Embedding相似度拆分（适合技术文档）
- **结构化分块**：按文档格式（标题、表格）拆分（适合Markdown、PDF）

#### （2）嵌入策略

- 模型选择：动态嵌入模型（如text-embedding-3-large）优于静态模型
- 领域微调：垂直领域（如医疗）可微调嵌入模型提升术语匹配精度

### 3. 检索策略优化

- **父文档检索**：先检索小分块（高精准），再返回完整父文档（保完整上下文）
- **混合检索**：结合BM25（关键词）和Embedding（语义），用RRF算法合并结果
- **层级检索**：先检索文档摘要（粗筛），再在命中文档中检索细节（精筛）

### 4. 后处理优化

- **过滤冗余Node**：移除低相关（相似度<0.7）或重复内容
- **重排序**：用CohereRerank或SentenceTransformerRerank提升结果相关性
- **句子窗口检索**：扩展目标句子前后3句作为上下文，补充语义
- **敏感信息处理**：脱敏身份证、手机号等PII数据

## 六、行业应用案例

- **智能客服**：整合产品手册+工单，问答准确率从40%→83%（哈啰出行案例）
- **金融投研**：整合研报+财报，分析效率提升40%（平安壹钱包案例）
- **医疗辅助诊疗**：整合指南+病例，诊断准确率提升25%（某三甲医院案例）

## 七、技术选型建议

- **框架**：快速开发选LlamaIndex，多模态/Agent场景选LangChain
- **向量数据库**：小规模用Chroma，大规模用Pinecone/Milvus
- **嵌入模型**：通用场景用text-embedding-3-large，垂直领域用微调后的bge-large
- **LLM**：复杂推理用GPT-4，成本敏感场景用LLaMA 2-70B

## 八、未来趋势

- 模块化与自适应：动态组合组件，强化学习优化策略
- 多模态融合：支持图文、视频混合检索
- 知识图谱深度集成：结合实体关系支持复杂推理
- 鲁棒性增强：抵御数据投毒和对抗性攻击
