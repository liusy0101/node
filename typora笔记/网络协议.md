# 网络协议

[toc]



## 一、通信协议综述



![img](typora-user-images/5985d6d430e1b1d3f165bf0f916ed954.jpg)



### 1、网络分层的真实含义

#### （1）网络为何要分层？

因为复杂的程序都要分层，这是程序设计的要求，比如一个系统有数据库层、缓存层、Dao层、Service层，Controller层



#### （2）程序是如何工作的？

![img](typora-user-images/5c00f6e610f533d17fb4ad7decacc776.jpg)



**收到网络数据报的处理流程：**

当一个网络包从一个网口经过的时候，首先看看要不要进行处理。有些网口配置了混杂模式，凡是经过的，全部都需要进行处理。

拿到网络数据包之后，先从buffer中摘掉二层的头（也即是MAC）。

如果MAC地址和当前MAC相符，说明是发给本机的，于是摘掉三层的头（IP），看看到底是发给本机的还是希望从本机转发出去的。

如果IP地址不是本机，就应该转发出去。如果IP地址是本机的，就是发给自己的。

根据IP头里面的标示，拿掉三层的头，进行下一层的处理，判断到底是TCP还是UDP。

假设是TCP，此时Buffer里面没有三层的头，需要查看四层的头，判断是发起还是应答，又或是一个正常的数据报，然后分别处理不同的逻辑。如果是发起或应答，就可能要发送一个回复包；如果是一个正常的数据包，就需要较给上层应用处理。

交给哪个应用？在四层的头里有端口号，不同的应用监听不同的端口号。如果发现浏览器应用在监听此端口，那就发给浏览器。



类似于离职流程。





**发送网络数据包的流程：**

发起一个Http请求，Buffer里面的Http请求的内容，会在TCP层添加TCP头，记录源端口号和目的端口号

流转到IP层，添加了一个IP头，记录下源IP地址和目的IP地址。

然后就是链路层，添加MAC头，记录源MAC地址和目的MAC地址。



类似于一个资源批复流程





**只要在网络上跑的包，都是完整的，可以有下层没上层，绝对不能有上层没下层**

__所以，对TCP协议来说，三次握手、重试这些操作，只要想发出去包，就要有IP层和MAC层，不然是发不出去的。__



一个HTTP协议的包经过一个二层设备，二层设备收进去的是整个网络包，这里面HTTP、TCP、IP、MAC都有。

**二层设备：**

只把MAC头摘下来，看是丢弃、转发，还是自留

**三层设备：**

把MAC头摘下来后再把IP头摘下来，看到底是丢弃、转发，还是自留。





### 2、ifconfig

```shell
root@test:~# ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff
    inet 10.100.122.2/24 brd 10.100.122.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::f816:3eff:fec7:7975/64 scope link 
       valid_lft forever preferred_lft forever
```

IP地址是一个网卡在网络世界的通讯地址，相当于门牌号码

![img](typora-user-images/fa9a00346b8a83a84f4c00de948a5b5e.jpg)

![img](typora-user-images/6de9d39a68520c8e3b75aa919fadb24c.jpg)



#### 无类型域间选路（CIDR）

将32位的IP地址一分为二，前面是网络号，后面是主机号。

例如一个IP地址 10.100.122.2/24，后面有一个斜杠，斜杠后面有个数字24，这种地址表示形式，就是CIDR。

后面24的意思就是在32位的IP地址中，前24位是网络号，后8位是主机号。



伴随着CIDR存在的，一个是**广播地址**，10.100.122.255，如果发送这个地址，所有10.100.122网络里的机器都可以收到，另一个是子网掩码，255.255.255.0。

**将子网掩码和IP地址按位进行AND计算，就是网络号**

例如，IP是10.100.122.2，子网掩码是255.255.255.0，那么网络号就是10.100.122.0。

![image-20210228163128229](typora-user-images/image-20210228163128229.png)



**公有IP地址和私有IP地址**

![img](typora-user-images/df90239efec6e35880b9abe55089ffa9.jpg)

私有IP地址允许组织内部的人员自行管理、分配，并且可以重复，比如学校A的某个私有IP地址和学校B的某个私有IP地址是可以一样的

比如家用的Wi-Fi地址一般是192.168.0.x，/24基本够用。

此时192.168.0即为网络号，后面是主机号，而一般192.168.0.1是私有网络的出口地址。192.168.0.255是广播地址。



例如对16.158.165.91/22求网络的第一个地址，子网掩码和广播地址。

![image-20210228164712050](typora-user-images/image-20210228164712050.png)

这五类地址中，还有一类 D 类是组播地址。使用这一类地址，属于某个组的机器都能收到。这有点类似在公司里面大家都加入了一个邮件组。

在 IP 地址的后面有个 scope，对于 eth0 这张网卡来讲，是 global，说明这张网卡是可以对外的，可以接收来自各个地方的包。对于 lo 来讲，是 host，说明这张网卡仅仅可以供本机相互通信。

lo 全称是 loopback，又称环回接口，往往会被分配到 127.0.0.1 这个地址。这个地址用于本机通信，经过内核处理后直接返回，不会在任何网络中出现。



**MAC地址**

在 IP 地址的上一行是 link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff，这个被称为 MAC 地址，是一个网卡的物理地址，用十六进制，6 个 byte 表示。

一个网络包要从一个地方传到另一个地方，除了要有确定的地址，还需要又定位功能，而有门牌号码属性的IP地址，才有远程定位功能。

MAC地址更像是一个身份证，而IP地址就是门牌号。

比如可以根据IP查找到主机在哪一栋楼，用MAC可以在用IP找到的楼中查找到对应的主机。

MAC地址有一定的定位功能，不过范围非常有限，只能局限在一个子网里面。



**网络设备的状态标识**

<BROADCAST,MULTICAST,UP,LOWER_UP>是干什么的？这个叫做 net_device flags，网络设备的状态标识。

UP 表示网卡处于启动的状态；

BROADCAST 表示这个网卡有广播地址，可以发送广播包；

MULTICAST 表示网卡可以发送多播包；

LOWER_UP 表示 L1 是启动的，也即网线插着呢。





qdisc pfifo_fast 是什么意思呢？

qdisc 全称是 queueing discipline，中文叫排队规则。内核如果需要通过某个网络接口发送数据包，它都需要按照为这个接口配置的 qdisc（排队规则）把数据包加入队列。

最简单的 qdisc 是 pfifo，它不对进入的数据包做任何的处理，数据包采用先入先出的方式通过队列。pfifo_fast 稍微复杂一些，它的队列包括三个波段（band）。在每个波段里面，使用先进先出规则。

三个波段（band）的优先级也不相同。band 0 的优先级最高，band 2 的最低。如果 band 0 里面有数据包，系统就不会处理 band 1 里面的数据包，band 1 和 band 2 之间也是一样。

数据包是按照服务类型（Type of Service，TOS）被分配到三个波段（band）里面的。TOS 是 IP 头里面的一个字段，代表了当前的包是高优先级的，还是低优先级的。





### 3、DHCP与PXE：IP是如何来的，又是怎么没的

**如何配置IP地址：**

使用net-tools：

```
$ sudo ifconfig eth1 10.0.0.1/24
$ sudo ifconfig eth1 up
```

使用iproute2：

```
$ sudo ip addr add 10.0.0.1/24 dev eth1
$ sudo ip link set up eth1
```

Linux上跨网段的调用个流程是，不会直接将包发送到网络上，而是企图将包发送到网关。

比如将机器IP配置位16.157.23.4，需发送数据包到192.168.1.5，是发不出去的。

因为除了源IP和目标IP，还需要MAC，那么目标192.168.1.5的MAC如何获取？

首先Linux会判断目标IP是否是同一网段的，如果是，才会发送ARP请求获取目标主机的MAC地址。

如果不是，就会将包发送到网关。



如果没配置网关的话，那么包根本就发不出去。

如果想要将网关配置成192.168.1.5，是不会配成功的，因为网关要和当前的网络至少一个网卡是同一网段的。



#### **动态主机配置协议DHCP**

当需要对网络随连随用，不需要手动配置静态IP时，就需要这个DHCP。

只需配置一段共享的IP地址，每台新接入的机器都通过DHCP协议，向这个共享的IP地址里申请，然后自动配置好就可以了。用完即还，就相当于是一个IP池，能重复使用。



如果是数据中心里面的服务器，IP一旦配置好，基本不会变化，相当于买断了，而DHCP的方式就是租赁，都是配置好的，即租即用，用完退租即可。



**DHCP的工作方式**

（1）当一台机器新加入一个网络时，只知道自身MAC地址，就会发一个广播数据包，这一步称为**DHCP Discover**

新机器使用IP地址0.0.0.0发送一个广播包，目的IP是255.255.255.255，广播包封装了UDP，UDP封装了BOOTP。

其实DHCP是BOOTP的增强版，抓包可能看到的名称还是BOOTP协议。

<img src="typora-user-images/90b4d41ee38e891031705d987d5d8481.jpg" alt="img" style="zoom: 33%;" />

（2）如果配置了DHCP Server（相当于IP管理员），收到广播包会立刻知道来了一个新机器

只有 MAC 唯一，IP 管理员才能知道这是一个新人，需要租给它一个 IP 地址，这个过程我们称为**DHCP Offer**。同时，DHCP Server 为此客户保留为它提供的 IP 地址，从而不会为其他 DHCP 客户分配此 IP 地址。

<img src="typora-user-images/a52c8c87b925b52059febe9dfcd6be6b.jpg" alt="img" style="zoom: 33%;" />

DHCP Server仍然使用广播地址作为目的地址，因为此时新机器还没有IP。服务器还发送了子网掩码、网关和IP地址租用期等信息。

（3）如果新机器收到多个DHCP Offer，一般会选择最先收到的哪个，并向网络发送一个**DHCP Request**广播数据包，包含客户端的MAC地址、接受的IP地址、对应的DHCP Server地址等，并告诉所有DHCP Server它将接受哪台服务器提供的IP地址，请求撤销他们提供的IP地址。

<img src="typora-user-images/cdbcaad24e1a4d24dd724e38f6f043fa.jpg" alt="img" style="zoom: 33%;" />

此时，由于还没有得到 DHCP Server 的最后确认，客户端仍然使用 0.0.0.0 为源 IP 地址、255.255.255.255 为目标地址进行广播。在 BOOTP 里面，接受某个 DHCP Server 的分配的 IP。



当 DHCP Server 接收到客户机的 DHCP request 之后，会广播返回给客户机一个 DHCP ACK 消息包，表明已经接受客户机的选择，并将这一 IP 地址的合法租用信息和其他的配置信息都放入该广播包，发给客户机，欢迎它加入网络大家庭。

<img src="typora-user-images/cca8b0baa4749bb359e453b1b482e1a9.jpg" alt="img" style="zoom:33%;" />



**IP地址的收回和续租：**

客户机会在租期过去 50% 的时候，直接向为其提供 IP 地址的 DHCP Server 发送 DHCP request 消息包。客户机接收到该服务器回应的 DHCP ACK 消息包，会根据包中所提供的新的租期以及其他已经更新的 TCP/IP 参数，更新自己的配置。这样，IP 租用更新就完成了。



#### 预启动执行环境（PXE）

<img src="typora-user-images/bbc2b660bba0ad00b5d1179db158498e.jpg" alt="img" style="zoom:33%;" />



## 二、链路层和网络层



### 1、从物理层到MAC层



**数据链路层**

1. 这个包是发给谁的？谁应该接收？
2. 大家都在发，会不会产生混乱？有没有谁先发、谁后发的规则？
3. 如果发送的时候出现了错误，怎么办？

MAC的全程是Medium Access Control，即媒体访问控制。控制在往媒体上发数据的时候，谁先发，谁后发的问题。防止发生混乱。解决第二个问题，此问题中的规则，学名叫多路访问。

有三种方式解决此问题：

（1）分多车道，每辆车一车道，各走各的，这在计算机网络里叫做信道划分。

（2）限号出行协议，在计网中叫做轮流协议。

（3）先出门，发现很堵，返回，错峰出行，叫随机接入协议。以太网用的就是这种方式。



【发给谁，谁接收？】

此时用到一个物理地址，叫做链路层地址。但是因为第二层主要解决媒体接入控制的问题，所以常被称为MAC地址



第二层的网络包格式。

![img](typora-user-images/8072e4885b0cbc6cb5384ea84d487e41.jpg)

类型：大部分类型是IP数据包，然后IP里面包含TCP、UDP以及HTTP等。



对于以太网，第二层最后面是CRC，也就是循环冗余检测，通过XOR异或的算法，来计算整个包是否在发送的过程中出现了错误，主要解决第三个问题。



**ARP协议**

已知IP地址，求MAC地址的协议。

<img src="typora-user-images/561324a275460a4abbc15e73a476e037.jpg" alt="img" style="zoom: 25%;" />

<img src="typora-user-images/485b5902066131de547acbcf3579c4ad.jpg" alt="img" style="zoom:25%;" />

发送一个广播数据包，询问某个IP是哪台机器的。

![img](typora-user-images/1f7cfe6046c5df606cfbb6bb6c7f899b.jpg)

机器本地会有ARP高速缓存，避免每次都是用ARP请求。



**局域网**

需要有一个能把MAC头拿下来，检查一下目标MAC地址，然后根据策略转发的设备，此设备是个二层设备，称为**交换机**



交换机如何知道每个口的电脑的MAC地址？

一个数据包从A发送到B，当交换机收到这个包时，交换机也不知道B在哪，所以只能转发到除源端口的其它所有的口，此时，交换机就会记住MAC_A是A主机的。之后有包的目的地址是MAC_A的，就直接发送到这个口。



在经过多次的数据交换后，交换机就知道了每个口对应的MAC地址，之后就可以进行准确转发了。

每个机器的IP地址会变，所在的口也会变，因而交换机上的学习的结果，称为转发表，是由一个过期时间的。





**重点：**

（1）MAC层是用来解决多路访问的堵车问题的。

（2）ARP通过广播的方式寻找目标MAC地址的，然后会将结果缓存下来。

（3）交换机是有MAC地址学习能力的，学完之后能做到准确转发。



### 2、交换机与VLAN

**拓扑结果是怎么形成的？**

当一个交换机不够用的时候，需要多台交换机，交换机之间连接起来，就形成了一个拓扑结构。



<img src="typora-user-images/0867321c36cc52bd3dd4d7622583fa29.jpg" alt="img" style="zoom: 25%;" />

例如两台交换机连着三个局域网，每台局域网上都有多台机器

如果机器1知道机器4的IP但不知道MAC地址，此时机器1发起广播，机器2收到，但IP信息不符，所以不管。交换机A收到广播后，广播到所有其它网口，所以机器3跟机器2一样。

此时交换机B也会收到，也是广播到所有网口，这时机器4发生了应答，于是一个ARP请求就成功完成了。

上述过程中，交换机A和B都知道机器1是左边的网口。当机器2访问机器1时，在不知道机器1的MAC地址时，也会发送ARP请求，此时交换机A知道根据MAC地址知道机器1是在左边的，也就不会进行广播。



**如何解决常见的环路问题？**

![img](https://static001.geekbang.org/resource/image/1f/ea/1f909508a8253d4842ffe962883421ea.jpg)

当机器1访问机器2的时候，一开始不知道机器2的MAC地址，所以发起一个ARP请求的广播，广播到达机器2，机器2返回MAC地址。

但是问题来了，这两个交换机还是都能够收到广播包的。交换机 A 一开始是不知道机器 2 在哪个局域网的，所以它会把广播消息放到局域网二，在局域网二广播的时候，交换机 B 右边这个网口也是能够收到广播消息的。交换机 B 会将这个广播信息发送到局域网一。局域网一的这个广播消息，又会到达交换机 A 左边的这个接口。交换机 A 这个时候还是不知道机器 2 在哪个局域网，于是将广播包又转发到局域网二。左转左转左转，好像是个圈哦。

当机器1的广播到达A、B时，A和B都存了机器1在左边的情况，如果交换机A转发到局域网2，此时交换机B收到局域网2的转发，交换机B又认为机器1是在右边，此时便造成了混乱。

这就是环路问题。





### 3、ICMP与PING

PING是基于ICMP协议工作的。

ICMP全称是Intenet control message protocol，就是互联网控制报文协议。

类似于侦察兵

 ![img](typora-user-images/201589bb205c5b00ad42e0081aa46fe2.jpg) 



ICMP报文是封装在IP报文里面的，因为传输指令的时候，肯定是要带上源地址和目的地址，携带信息有限，作为侦察兵要轻装上阵。

ICMP报文有多种类型，不同类型有不同的代码。

最常用的类型是主动请求是8，主动请求的应答是0。



**查询报文类型：**

主动探查敌情，对应的是ICMP的查询报文类型

PING就是查询报文，是一种主动请求，并且获得主动应答的ICMP协议。PING发出的包是符合ICMP协议格式的，不过PING在后面追加了专属的格式。

对PING的主动请求，进行网络抓包，称为**ICMP ECHO REQUEST**，同理主动请求的应答称为**ICMP ECHO REPLY**。

比起原生的ICMP报文，多了两个字段

**标识符**，标识用处，比如派出一小队做敌情侦查，派出另一小队做水源查找

**序号**，派出去的侦察兵进行编号，派10回10，战况良好，派10回1，战况惨烈。

在选项数据中，PING还会存放发起请求的时间，用来计算往返时间。



**差错报文类型：**

由于某种原因导致报文出错，就称为差错报文。

例如：

终点不可达 为 3

源抑制 为 4

超时 为 11

重定向 为 5



**终点不可达：** 小兵：报告，传送粮草到张将军处，结果没送到

原因如下： 网络不可达代码为 0，主机不可达代码为 1，协议不可达代码为 2，端口不可达代码为 3，需要进行分片但设置了不分片位代码为 4。 

网络不可达：没找到地方

主机不可达：找到地方没找到人

协议不可达：到地儿找到人，暗号对不上

需分片单设置了不分片：粮车到半路了，道路狭窄无法通过，无法送达



**源站抑制：** 让源站放慢发送速度。物资太多，消耗不了。



**超时：** 超过设定的时间还未送达



**重定向：** 地址发错了，



 差错报文的结构相对复杂一些。除了前面还是 IP，ICMP 的前 8 字节不变，后面则跟上出错的那个 IP 包的 IP 头和 IP 正文的前 8 个字节。 





**PING：查询报文类型的使用**

![img](typora-user-images/57a77fb89bc4a5653842276c70c0d621.jpg)

1、ping命令执行的时候，源主机首先回构建一个ICMP请求数据包，ICMP数据包内包含多个字段，最重要的有两个。

第一个是类型字段，对于请求数据包来说是 8 ，另一个是顺序号，主要用于区分连续piong的时候发出的多个数据包。

每发出一个请求数据包，顺序号会自动加1，为了能够计算往返时间RTT，会在报文的数据部分插入发送时间。

2、然后，由ICMP协议将此数据包连同源IP地址和目的IP地址一起交至IP层，加上其它信息，构建一个IP数据包。

3、然后，加入MAC头。获取MAC地址后，由数据链路层构建一个数据帧，目的地址是IP层传过来的MAC地址。源地址则是本机的MAC地址还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。

4、主机 B 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。

5、主机B会构建一个ICMP应答包，应答数据包的类型字段为0，顺序号为接收到的请求数据包中的顺序号，然后在发送给主机B。

6、在规定的时间内，源主机如果没有接到ICMP的应答包，则说明目标主机不可达；如果接收到了ICMP应答包，则说明目标主机可达。此时，源主机会检查，用当前时间减去数据包最初从源主机上发出的时间，就是ICMP数据包的时间延迟。

7、如果跨网段，会涉及到网关的转发、路由器的转发等。但是对于 ICMP 的头来讲，是没什么影响的。会影响的是根据目标 IP 地址，选择路由的下一跳，还有每经过一个路由器到达一个新的局域网，需要换 MAC 头里面的 MAC 地址。



PING是使用了ICMP里面的ECHO REQUEST和ECHO REPLY类型的。



**Traceroute：差错报文类型的使用**

Traceroute的第一个作用就是能设置特殊的TTL，来追踪去往目的地时沿途经过的路由器。

Traceroute的参数指向某个目的IP地址，会发送一个UDP的数据包，将TTL设置成1，一旦遇到一个路由器或一个关卡，请求就结束，返回给源主机。

如果中间的路由器不止一个，遇到第一个就结束，于是，返回一个ICMP包，也就是网络差错包，类型是时间超时。

接下来，将 TTL 设置为 2。第一关过了，第二关就“牺牲”了，那我就知道第二关有多远。如此反复，直到到达目的主机。这样，Traceroute 就拿到了所有的路由器 IP。当然，有的路由器压根不会回这个 ICMP。这也是 Traceroute 一个公网的地址，看不到中间路由的原因。

1、如何知道UDP有没有到达目的主机？

Traceroute会发送一份UDP数据包给目的主机，但它会选择一个不可能的值作为UDP端口号（大于3000）。当数据包到达时，目的主机的UDP模块产生一份“端口不可达”错误ICMP报文。如果数据包没有到达，则可能时超时。



**Traceroute还有一个作用是故意设置不分片，从而确定路径的MTU。**

要做的工作首先是发送分组，并设置“不分片”标志。发送的第一个分组的长度正好与出口 MTU 相等。如果中间遇到窄的关口会被卡住，会发送 ICMP 网络差错包，类型为“需要进行分片但设置了不分片位”。其实，这是人家故意的好吧，每次收到 ICMP“不能分片”差错时就减小分组的长度，直到到达目标主机。



### 4、网关和路由

一旦配置了IP地址和网关，往往就能指定目标地址进行访问了，由于在跨网关访问的时候，牵扯到MAC地址和IP'地址的变化。

<img src="typora-user-images/825e54560a6de08a32e4cab4e0f59f65.jpg" alt="img" style="zoom:25%;" />

在任何一台机器上，当要访问另一个IP地址时候，会先判断目标IP地址和当前IP地址是否在同一个网段。



**如何判断是否处于同一网段？**

需要CIDR和子网掩码



如果是同一网段，不需要用到网关，直接将源地址和目标地址放入IP头中，然后通过ARP获得MAC地址，将源MAC和目的MAC放入MAC头中，发送出去即可。

如果不是同一网段，需要发往默认网关Gateway。网关的地址一定是和源IP地址处于同一网段，往往不是第一个就是第二个，例如192.168.1.0/24这个网段，Gateway一般会是192.168.1.1/24或者192.168.1.2/24





**如何发往默认网关？**

由于是在同一网段，所以只需要在交换机上进行通信即可，也即是使用ARP获取MAC地址，然后封装源IP、目的IP、源MAC、目的MAC发送出去。

网关往往是一个路由器，是一个三层转发的设备。

三层设备就是把MAC和IP头取下来，根据里面的内容，看看数据包具体是往哪里发的。 



路由器是一台设备，有五个网口或网卡，相当于有五只手，分别连着五个局域网，每只手的IP地址都和局域网的IP地址是相同的网段，每只手都是它握住的哪个局域网的网关。

任何一个想发往其它局域网的包，都会到达其中一只手，拿进来后拿下MAC和IP头，然后根据路由算法，选择另一只手，加上IP头和MAC头，发出去。



那么该如何选择哪一只手呢？



**静态路由是什么？**

静态路由，其实就是在路由器上，配置一条一条的规则。按照规则进行出口匹配，也就是选择哪一只手

每当要选择哪个出口时，就一条一条规则匹配，找到符合的规则，就按规则中设置的出口发出去，找下一跳IPX。



**IP头和MAC头是否需要改变？**

MAC地址是一个局域网内才有效的地址，所以，MAC地址只要过了网关，就一定会改变，因为已经换了局域网。

两者主要区别在于IP地址是否改变？不改变IP地址的网关称为**转发网关**；改变IP地址的网关，称为**NAT网关**。



**转发网关：**

![img](typora-user-images/1d604f88456096a73e40437d8f9e458c.jpg)

![image-20210306230443519](typora-user-images/image-20210306230443519.png)

在此过程中，每到一个新的局域网，MAC地址都是变化的，但是IP地址都不变，在IP头里面，不会保存任何网关的IP地址。

IP地址在三个局域网内都是可见的，所以网段不会冲突，IP头不改变。

所谓的下一跳就是某个IP要将这个IP地址转换为MAC放入MAC头。



**NAT网关：**

IP地址在局域网内不可见，会发生IP冲突，比如局域网A的192.168.1.101发往局域网B的192.168.1.101，IP是一样的。

类似于是快递地址，首先是广东省，比如外省发往深圳，首先要经过广东省的集散中心。

比如服务器B有一个全国通用IP，定为192.168.56.2，在网关B上，192.168.56.2对应的是192.168.1.101，凡是要访问192.168.56.2的，都转成192.168.1.101

![image-20210306233753503](typora-user-images/image-20210306233753503.png)



### 5、路由协议：动态路由

**如何配置路由：**

路由器就是一台网络设备，有多张网卡，当一个入口的网络包送到路由器时，会根据一个本地的转发信息库，决定如何正确的转发流量。这个转发信息库通常就被称为路由表。

一张路由表中会有多条路由规则，每一条规则至少包含这三项信息：

- 目的网络：这个包想去哪儿？
- 出口设备：将包从哪个口发出
- 下一跳网关：下一个路由器的地址

通过route命令和ip route命令都可以进行查询或配置。

via：经由

例如：添加路由规则，要去10.176.48.0/20 这个目标网络，要从 eth0 端口出去，经过 10.173.32.1。

```shell
ip route add 10.176.48.0/20 via 10.173.32.1 dev eth0
```

按照上述三项配置信息进行配置的路由策略，有一个核心思想就是：根据目的IP地址来配置路由。



**如何配置路由策略：**

除了根据IP地址进行配置，还可以根据多个参数来配置路由，这就称为策略路由。

可配置多个路由表，可根据源IP地址、入口设备、TOS等选择路由表，然后在路由表中查询路由，可使得来自不同来源的包走不同的路由。

例如，设置从192.168.1.0/24这个网段来的，使用table 10中的路由表。

```shell
ip rule add from 192.168.1.0/24 table 10
```

在一条路由规则中，也可以走多条路径

比如：下一跳有两个地方，分别是100.100.100.1和200.200.200.1，权重比是1:2

```shell
ip route add default scope global nexthop via 100.100.100.1 weight 1 nexthop via 200.200.200.1 weight 2
```

例如：

从两个运营商都拉了网线，一条带宽大，一条带宽小，此时需要可接两个外网的路由器。

家用网络的网段就是192.168.1.x/24，有俩租户，分别把线联到路由器上，IP地址为192.168.1.101/24和192.168.1.102/24，网关都是192.168.1.1/24，网关在路由器上。

此时出去的数据包需要经过NAT网关转成公网IP地址，路由器就是一个NAT网关。

两个运营商都要为这个网关配置一个公网IP地址，像下图：

<img src="typora-user-images/c3f476eb7ce8f185befb6c7a2b1752db.jpg" alt="img"  />

运营商里面也有一个IP地址，在运营商网络里面的网关，不同的运营商方法不一样，有的是/32的，也即是一对一连接。

如上图：运营商1给路由器分配的地址是183.134.189.34/32，运营商1网络的网关是183.134.188.1/32，有的是/30的，也即是分了一个特别小的网段。运营商2给路由器分配的地址是60.190.27.190/30，运营商2网络里面的网关是 60.190.27.189/30。

根据此网络拓扑图，可将路由配置如下：

60.190.27.190/30，运营商网络里面的网关是 60.190.27.189/30。

```shell
$ ip route list table main 
60.190.27.189/30 dev eth3  proto kernel  scope link  src 60.190.27.190
183.134.188.1 dev eth2  proto kernel  scope link  src 183.134.189.34
192.168.1.0/24 dev eth1  proto kernel  scope link  src 192.168.1.1
127.0.0.0/8 dev lo  scope link
default via 183.134.188.1 dev eth2
```

此时规则如下：

- 去运营商2，走eth3
- 去运营商1，走eth2
- 访问内网，走eth1
- 如果所有规则都匹配不上，默认走运营商1，走快网

那如果有一个大爷只想简单上上网看看新闻，不想付一样的钱，可以添加一个table

```shell
$ echo 200 chao >> /eth/iproute2/rt_tables
```

添加一条规则：从192.168.1.101来的包都查看chao这个新的路由表

```shell
# ip rule add from 192.168.1.101 table chao
# ip rule ls
0:  from all lookup local 
32765:  from 192.168.1.101 lookup chao
32766:  from all lookup main 
32767:  from all lookup default
```

此时在chao路由表中添加规则：默认为慢的网络

```shell
# ip route add default via 60.190.27.189 dev eth3 table chao
# ip route flush cache
```

上述都是静态的路由，在网络环境较为简单时，可用，但在网络环境复杂并多变的时候，如果总是用静态路由，一旦网络结构发生变化，手工修改路由会非常复杂，所以需要动态路由。

**动态路由算法**

使用动态路由路由器，可根据路由协议算法生成动态路由表，随网络运行状况的变化而变化。

无论是一个国家内部，还是国家之间，我们都可以将复杂的路径，抽象为一种叫作图的数据结构。至于唐僧西行取经，肯定想走的路越少越好，道路越短越好，因而这就转化成为如何在途中找到最短路径的问题。

求最短路径常用的有两种方法，一种是 Bellman-Ford 算法，一种是 Dijkstra 算法。



**1、距离矢量路由算法**

距离矢量路由（distance vector routing）。它是基于 Bellman-Ford 算法的。

此种算法，每个路由器都保存一个路由表，包含多行，每行对应网络中的一个路由器，每一行包含两部分信息，一个是目标路由器，另一个是到目标路由器的距离。

每个路由器都知道全局信息

- 信息如何更新？

  每个路由器都知道自身和邻居之间的距离，每过几秒，每个路由器都将自身所知的到达所有路由器的距离告知邻居，每个路由器也能从邻居那里得到相似的信息。

每个路由器根据新收集的信息，计算和其他路由器的距离，比如自己的一个邻居距离目标路由器的距离是 M，而自己距离邻居是 x，则自己距离目标路由器是 x+M。

此算法较为简单，有几个缺点：

- 第一个就是好消息传得快，坏消息传得慢

  如果有个路由器加入了这个网络，它的邻居就能很快发现它，然后将消息广播出去。要不了多久，整个网络就都知道了。但是一旦一个路由器挂了，挂的消息是没有广播的。当每个路由器发现原来的道路到不了这个路由器的时候，感觉不到它已经挂了，而是试图通过其他的路径访问，直到试过了所有的路径，才发现这个路由器是真的挂了。

![img](typora-user-images/e9642f901c1d9c470c539ccc395e7879.jpg)



- 第二个就是每次发送时，要发送整个全局路由表

  网络一大，延迟就大，最早的路由协议 RIP 就是这个算法。它适用于小型网络（小于 15 跳）。当网络规模都小的时候，没有问题。现在一个数据中心内部路由器数目就很多，因而不适用了。



**2、链路状态路由算法**

链路状态路由（link state routing），基于 Dijkstra 算法。

此种算法中，当一个路由器启动时，首先是发现邻居，向邻居say hello，邻居都回复，然后计算与邻居的距离，发送一个echo，要求马上返回，除以2就是距离。然后将自身和邻居之间的链路状态包广播出去，发送到整个网络的每个路由器，这样每个路由器都能收到它和邻居之间关系的信息，因此，每个路由器都能在本地构建一个完整的图，然后针对此图使用Dijkstra算法，找到两点之间的最短路径。

链路状态路由协议只广播更新或改变的网络拓扑，使得更新信息更小，节省了带宽和CPU利用率，而且一旦一个路由器挂了，他的邻居都会广播这个消息。



**动态路由协议**

- 1、基于链路状态路由算法的OSPF

  OSPF（Open Shortest Path First，开放式最短路径优先）就是这样一个基于链路状态路由协议，广泛应用在数据中心中的协议。由于主要用在数据中心内部，用于路由决策，因而称为内部网关协议（Interior Gateway Protocol，简称 IGP）。

内部网关协议的重点就是找到最短的路径。在一个组织内部，路径最短往往最优。当然有时候 OSPF 可以发现多个最短的路径，可以在这多个路径中进行负载均衡，这常常被称为等价路由。

![img](typora-user-images/2eb5f4722689adf9926fded5005e02db.jpg)

有了等价路由，到一个地方去可以有相同的两个路线，可以分摊流量，还可以当一条路不通的时候，走另外一条路。这个在后面我们讲数据中心的网络的时候，一般应用的接入层会有负载均衡 LVS。它可以和 OSPF 一起，实现高吞吐量的接入层设计。

- 2、基于距离矢量路由算法的BGP

  但是外网的路由协议，也即国家之间的，又有所不同。我们称为外网路由协议（Border Gateway Protocol，简称 BGP）。

在一个国家内部，有路当然选近的走。但是国家之间，不光远近的问题，还有政策的问题。

对于网络包同样，每个数据中心都设置自己的 Policy。例如，哪些外部的 IP 可以让内部知晓，哪些内部的 IP 可以让外部知晓，哪些可以通过，哪些不能通过。这就好比，虽然从我家里到目的地最近，但是不能谁都能从我家走啊！

在网络世界，这一个个国家成为自治系统 AS（Autonomous System）。

自治系统分几种类型。

1. Stub AS：对外只有一个连接。这类 AS 不会传输其他 AS 的包。例如，个人或者小公司的网络。
2. Multihomed AS：可能有多个连接连到其他的 AS，但是大多拒绝帮其他的 AS 传输包。例如一些大公司的网络。
3. Transit AS：有多个连接连到其他的 AS，并且可以帮助其他的 AS 传输包。例如主干网。

每个自治系统都有边界路由器，通过它和外面的世界建立联系。

![img](typora-user-images/698e368848fdbf1eb8e270983e18143d.jpg)

BGP 又分为两类，eBGP 和 iBGP。自治系统间，边界路由器之间使用 eBGP 广播路由。内部网络也需要访问其他的自治系统。边界路由器如何将 BGP 学习到的路由导入到内部网络呢？就是通过运行 iBGP，使得内部的路由器能够找到到达外网目的地的最好的边界路由器。

BGP 协议使用的算法是路径矢量路由协议（path-vector protocol）。它是距离矢量路由协议的升级版。





路由分静态路由和动态路由，静态路由可以配置复杂的策略路由，控制转发策略；

动态路由主流算法有两种，距离矢量算法和链路状态算法。基于两种算法产生两种协议，BGP 协议和 OSPF 协议。



## 三、传输层

### 1、UDP协议

**TCP和UDP有哪些区别？**

TCP是面向连接的，UDP是面向无连接的。

- 什么是面向连接？

  面向连接的协议会先建立连接，例如，TCP会进行三次握手，UDP不会。

所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性。

- TCP提供可靠交互，通过TCP连接传输的数据，无差错、不丢失、不重复、按序到达。

​        而UDP继承了IP包的特性，不保证不丢失，不保证按顺序到达。

- TCP是面向字节流的，而UDP继承了IP的特性，基于数据包的，一个一个发，一个一个收。

- TCP有拥塞控制，根据接收方的吞吐量控制发送速度，但UDP没有。
- TCP是有状态的服务，UDP是无状态服务。



如果MAC层定义了本地局域网的传输行为，IP层定义了整个网络端到端的传输行为，这两层基本定义了这样的现象：网络传输是以包为单位的，二层叫帧，网络层叫包，传输层叫段。包单独传输，自行选路，在不同的设备封装解封装，不保证到达。



**UDP包头**

机器接收到数据包后，取下MAC和IP头，IP头里面有个8位的协议，存放数据是TCP还是UDP。

处理完传输层的事情，内核的事情基本就完了，里面的数据应该较给应用层处理。

无论是TCP还是UDP，都要监听一个端口。利用这个端口区分应用程序。

![img](typora-user-images/2c9a109f3be308dea901004a5a3b4c84.jpg)



**UDP特点**

- 沟通简单
- 随意传输，谁都可以传输数据到相应端口上
- 不会根据网络情况进行改变



**三大使用场景**

- 需要资源少，在网络情况较好的内网，或者对于丢包不敏感的应用。

- 不需要建立连接，而是可以广播的应用

  DHCP就是一种广播的形式，基于UDP协议。

  多播，D类地址，也即组播地址。使用此地址可将包组播给一批机器。

- 需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也不改变发送速度。



### 2、TCP协议

![img](typora-user-images/642947c94d6682a042ad981bfba39fbf.jpg)

- 序号是为了解决乱序的问题，

- 确认序号，发出去的包应该有确认，如果没有收到应该重新发送，直至到达。解决不丢包的问题

- 状态位，SYN是发起一个连接，ACK是回复，FIN是结束一个连接，RST是重新连接等。

  TCP是面向连接的，因而要维护双方连接的状态，这些带状态位的包的发送，回引起双方的状态变更

- 窗口大小，TCP有拥塞控制，流量控制，通信双方各声明一个窗口，标识当前的处理能力，发送速度要适中。



对TCP协议，应重点关注以下几点：

	1. 顺序问题，稳重不乱
 	2. 丢包问题，承诺靠谱
 	3. 连接维护，有始有终
 	4. 流量控制，把握分寸
 	5. 拥塞控制，知进退



**TCP的三次握手**

![img](typora-user-images/c067fe62f49e8152368c7be9d91adc08.jpg)

TCP的可靠性是靠seq（序号）和确认序号ack来达成的。



**TCP为什么不是两次握手或者四次握手？**

两次握手中服务端收不到客户端的反馈，不知道客户端是否正常

三次握手已经能让双方都能确认对方已连接，所以无需四次握手。



- 一般建立连接后，就会立马进行数据通信，所以即使A发送的应答包丢了，A也会马上发送数据，让B知晓可以建立连接。
- 即使连接后也不通信，可以开启keepalive机制，定时发送探活包，保证连接不断开。



**TCP的四次挥手**

![img](typora-user-images/bf1254f85d527c77cc4088a35ac11d13.jpg)

A在TIME_WAIT状态还需停留一段时间，因为直接跑路的话，如果B没收到A最后一个ACK的回馈，那么B就是重复发FIN结束连接的包，相当于B就一直占着端口不会暂停。A会等到B的重新发FIN请求，再发一个ACK并且足够时间到达B。

等待的时间设为2MSL，MSL是Maximum Segment Lifetime，报文最大生存时间，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 域，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。协议规定 MSL 为 2 分钟，实际应用中常用的是 30 秒，1 分钟和 2 分钟等。

还有一种异常情况就是：

B超过了2MSL的时间还没收到ACK，此时B重发FIN，此时A收到这个包之后，A直接发送RST，B就知道A早就跑路了。



**TCP状态机**

![img](typora-user-images/fd45f9ad6ed575ea6bfdaafeb3bfb62a.jpg)





**如何实现一个靠谱的协议？**

为了保证顺序性，每一个包都有一个ID，在建立连接的时候，会商定起始的ID是什么，然后按照ID一个个发送，为了保证不丢包，对于发送的包都要进行应答，但这个应答也不是一个一个来，而是会应答某个之前的ID，表示都收到了，这种模式称为**累计确认**或者**累计应答**



为了记录所有发送的包和接收的包，TCP也需要发送端和接收端分别都有缓存来保存这些记录，发送端的缓存里是按照包的ID一个个排列，按照处理情况分成四个部分。

1. 发送并已确认
2. 发送但未确认
3. 没发送但等发送
4. 没发送但暂不发送

区分3和4是因为要做**流量控制**。

在TCP里面，接收端会给发送端报一个窗口的大小，叫滑动窗口（Advertised window），此窗口的大小应该等于第二部分加上第三部分，超过这个窗口的，接收端做不过来，就不能发送了。

发送端需保持以下数据结构：

![img](typora-user-images/dd67ba62279a3849c11ffc1deea25d44.jpg)



- LastByteAcked：第一和第二部分的分界线
- LastByteSent：第二和第三部分的分界线
- LastByteAcked + AdvertisedWindow：第三和第四部分的分界线     ???????



对接收端来说，缓存里记录内容如下：

1. 接收并已确认
2. 没接收但马上能接收的，也即能接收的最大的量
3. 没接收也没法接收的，超过最大量的

![img](typora-user-images/9d597af268016f67caa14178627188be.jpg)



- MaxRcvBuffer：最大缓存的量；
- LastByteRead 之后是已经接收了，但是还没被应用层读取的；
- NextByteExpected 是第一部分和第二部分的分界线。



第二部分窗口大小：

NextByteExpected 和 LastByteRead 的差其实是还没被应用层读取的部分占用掉的 MaxRcvBuffer 的量，我们定义为 A

此时AdvertisedWindow 其实是 MaxRcvBuffer 减去 A。

也就是：AdvertisedWindow=MaxRcvBuffer-((NextByteExpected-1)-LastByteRead)。



那第二部分和第三部分的分界线在哪里呢？

NextByteExpected 加 AdvertisedWindow 就是第二部分和第三部分的分界线，其实也就是 LastByteRead 加上 MaxRcvBuffer。



其中第二部分里卖弄，由于收到的包可能不是顺序的，会出现空挡，只有和第一部分连续的可以马上进行回复，中间空着的部分需要等待，哪怕后面的已经来了。



**顺序问题与丢包问题**

![img](typora-user-images/dd67ba62279a3849c11ffc1deea25d44.jpg)



![img](typora-user-images/9d597af268016f67caa14178627188be.jpg)

发送端、接收端情况如上图

状态如下：

- 1、2、3 没有问题，双方达成了一致。
- 4、5 接收方说 ACK 了，但是发送方还没收到，有可能丢了，有可能在路上。
- 6、7、8、9 肯定都发了，但是 8、9 已经到了，但是 6、7 没到，出现了乱序，缓存着但是没办法 ACK。



确认和重发机制：

**（1）超时重传**

对每一个发送了但是没有ACK的包，都设定一个定时器，超过定时，就重新尝试，

超时时间不宜过短，必须大于往返时间RTT，否则会有不必要的重传

估计往返时间，需要TCP通过采样RTT的时间，然后进行加权平均，算出一个值，而且这个值是不断变化的，因为网络状况在不断的变化，除了采用RTT，还要采用RTT的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，称为自适应重传算法。

TCP的策略是超时间隔加倍，每当遇到依次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍，两次超时，说明网络环境差，不宜频繁反复发送。



超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？

有一个可以快速重传的机制，当接收方收到一个序号大于下一个所期望的报文段时，就会检测到数据流中的一个间隔，于是它就会发送冗余的 ACK，仍然 ACK 的是期望接收的报文段。而当客户端收到三个冗余的 ACK 后，就会在定时器过期之前，重传丢失的报文段。

例如，接收方发现 6 收到了，8 也收到了，但是 7 还没来，那肯定是丢了，于是发送 6 的 ACK，要求下一个是 7。接下来，收到后续的包，仍然发送 6 的 ACK，要求下一个是 7。当客户端收到 3 个重复 ACK，就会发现 7 的确丢了，不等超时，马上重发。



**（2）Selective Acknowledgment （SACK）**

这种方式需要在TCP头里加一个SACK的东西，可将缓存的地图发送给发送方。

例如可以发送 ACK6、SACK8、SACK9，有了地图，发送方一下子就能看出来是 7 丢了。



**流量控制问题**

在对包的确认中，同时会携带一个窗口的大小

发送端发送的每一个数据包，服务端都要给一个确认包（ACK），确认它收到了。

服务端给发送端发送的确认包（ACK包）中，同时会携带一个窗口的大小，

此窗口大小就代表目前服务器端的处理能力（接收端最大缓存量 - 接收端已确认但未被应用层读取的部分）

此窗口大小也是时刻变化的，可能接收方在发送数据包4的ACK时候，窗口大小为9，此时应用层程序已经读取确认了缓存4个数据的，接收方再发送数据包5的ACK的时候，窗口的大小就变为14



例如：窗口不变，始终为9

ACK4来的时候，右移一个，此时第13个包也可以发送了

![img](typora-user-images/af16ecdfabf97f696d8133a20818fd87.jpg)

此时，发送端发送较快，将第三部分的10、11、12、14全部发送，之后停止发送，未发送可发送部分为0

![img](typora-user-images/e011cb0e56f43bae942f0b7ab7407b35.jpg)

当ACK5到达的时候，会滑动一格，此时14可以发送

![img](typora-user-images/f5a4fcc035d1bb2d7e11c38391d768c2.jpg)

如果接收方处理速度比不上发送方发送速度，导致缓存中没有空间，可通过确认信息修改窗口大小，甚至可设置为0，则发送方将暂时停止发送

假设接收方应用一直不读取缓存中数据，当ACK6到达发送方后，此时携带的窗口大小变成了8

![img](typora-user-images/953e6706cfb5083e1f25b267505f5c9d.jpg)



此时发送方仅仅是将左面的边右移了，窗口大小从9改为了8

![img](typora-user-images/0a9265c63d5e0fb08c442ea0a7cffa1f.jpg)



接收端应用一直不读取数据，那么就会一直发送ACK，知道窗口大小为0.

![img](typora-user-images/c24c414c31bd5deb346f98417ecdb74a.jpg)

当ACK14到达的时候，窗口为0，停止发送

![img](typora-user-images/89fe7b73e40363182b13e3d9c9aa2acb.jpg)

如果这样的话，发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。



这就是**流量控制**





**拥塞控制**

拥塞控制也是通过窗口的大小控制的，流量控制的滑动窗口rwnd是怕发送方把接收方缓存塞满，而拥塞窗口cwnd，是怕把网络塞满

- rwnd：receiver window，接收方滑动窗口，用于防止接收方缓存占满
- cwnd：congestion window，拥塞窗口，用于控制将带宽占满

有一个公式 LastByteSent - LastByteAcked <= min {cwnd, rwnd} ，是拥塞窗口和滑动窗口共同控制发送的速度。



- 发送方怎么判断网络是不是慢？

  对于TCP协议来说，他不知道整个网络路径都会经历什么，TCP发送包常被比喻为往一个水管里面灌水，而TCP的拥塞控制就是在不堵塞、不丢包的情况下，尽量发挥带宽。

网络有带宽，端到端有时延，通道的容量= 带宽 * 往返延迟

如果设置发送窗口，使得发送但未确认的包为通道的容量，就能撑满整个管道。

![img](typora-user-images/db8510541662281175803c7f9d1fcae6.jpg)

假设往返时间为8s，去4s，回4s，每秒发送一个包，每个包1024byte。8s后8个包全发出去了，其中前4个包已经到达接收端，但是ACK还没返回，不算发送成功给，5-8个包还在路上没被接收，此时整个管道正好撑满，在发送端，已发送未确认的有8个包，正好等于带宽，也即是每秒发送一个包，乘于往返时间8s。



如果在此基础上调大窗口，单位时间可发送更多的包，那么单位时间内，会有更多的包到达中间设备，但设备在单位时间的处理速度跟不上，多出来的包就会被丢弃。

此时，可以在中间设备上添加缓存，此时包不会丢失，但是会增加时延，如果时延到达一定成都，会进行超时重传。

所以TCP的**拥塞控制**主要避免两种现象：包丢失和超时重传。

出现这两个现象就说明发送速度过快，需要慢一点。

如果发送速度从慢开始，发现可以加快速度的发，这叫慢启动。类似于车的加速。

一条TCP连接开始，cwnd设置为1个报文段，一次只能发1个，当收到这一个确认时候，cwnd加1，此时可以一次发2个，当这两个确认到来时，每确认一个，cwnd加1，此时cwnd为4，可以发4个。这是指数型增长。

直到cwnd达到ssthresh=65535个字节的时候，就需要慢下来。

此时每收到一个确认后，cwnd增加1/cwnd，一次发送8个，8个确认一共是8*（1/8）=1，于是此时可以发送9个，变成了线性增长。



拥塞的一种表现形式是丢包，需要超时重传，此时，将sshresh设为cwnd/2，将cwnd设为1，重新开始慢启动，此时传输速度就会立马慢下来，造成网络卡顿。

**快速重传算法**。当接收端发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，cwnd 减半为 cwnd/2，然后 sshthresh = cwnd，当三个包返回的时候，cwnd = sshthresh + 3，也就是没有一夜回到解放前，而是还在比较高的值，呈线性增长。

例如，此时cwnd为6，有一个包迟迟没返回ACK，此时cwnd变成3，ssthresh=cwnd，当收到三个请求发送这个包的ACK时，cwnd = ssthresh + 3 = 6

这样就不会一下导致网络卡顿。



TCP 的拥塞控制主要来避免的两个现象都是有问题的

- 第一个问题是丢包并不代表着通道满了，也可能是管子本来就漏水。例如公网上带宽不满也会丢包，这个时候就认为拥塞了，退缩了，其实是不对的。
- 第二个问题是 TCP 的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经晚了。其实 TCP 只要填满管道就可以了，不应该接着填，直到连缓存也填满。

为了优化这两个问题，后来有了 TCP BBR 拥塞算法。它企图找到一个平衡点，就是通过不断地加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以很好的达到高带宽和低时延的平衡。

![img](typora-user-images/a2b3a5df5eca52e302b75824e4bbbd4c.jpg)



顺序问题、丢包问题、流量控制都是通过滑动窗口来解决的.

拥塞控制是通过拥塞窗口来解决的，相当于往管道里面倒水，快了容易溢出，慢了浪费带宽，要摸着石头过河，找到最优值。



### 3、套接字Socket

**基于TCP协议的Socket程序函数调用过程**

![img](typora-user-images/78d145a72f9473fc1fyy0847d9b8212d.jpg)



TCP 的 Socket 就是一个文件流，是非常准确的。因为，Socket 在 Linux 中就是以文件的形式存在的。除此之外，还存在文件描述符。写入和读出，也是通过文件描述符。

在内核中，Socket 是一个文件，那对应就有文件描述符。每一个进程都有一个数据结构 task_struct，里面指向一个文件描述符数组，来列出这个进程打开的所有文件的文件描述符。文件描述符是一个整数，是这个数组的下标。

这个数组中的内容是一个指针，指向内核中所有打开的文件的列表。既然是一个文件，就会有一个 inode，只不过 Socket 对应的 inode 不像真正的文件系统一样，保存在硬盘上的，而是在内存中的。在这个 inode 中，指向了 Socket 在内核中的 Socket 结构。

在这个结构里面，主要的是两个队列，一个是发送队列，一个是接收队列。在这两个队列里面保存的是一个缓存 sk_buff。这个缓存里面能够看到完整的包的结构。

![img](https://static001.geekbang.org/resource/image/60/13/604f4cb37576990b3f836cb5d7527b13.jpg)



**基于UDP协议的Socket程序函数调用过程**

UDP 是没有维护连接状态的，因而不需要每对连接建立一组 Socket，而是只要有一个 Socket，就能够和多个客户端通信。也正是因为没有连接状态，每次通信的时候，都调用 sendto 和 recvfrom，都可以传入 IP 地址和端口。

![img](typora-user-images/6bbe12c264f5e76a81523eb8787f3931.jpg)



**服务端如何处理更多连接**

最大连接数，系统会用一个四元组来标识一个 TCP 连接。

```
{本机IP, 本机端口, 对端IP, 对端端口}
```

服务器通常固定在某个本地端口上监听，等待客户端的连接请求。因此，服务端端 TCP 连接四元组中只有对端 IP, 也就是客户端的 IP 和对端的端口，也即客户端的端口是可变的，因此，最大 TCP 连接数 = 客户端 IP 数×客户端端口数。对 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最大 TCP 连接数，约为 2 的 48 次方。

当然，服务端最大并发 TCP 连接数远不能达到理论上限。首先主要是文件描述符限制，按照上面的原理，Socket 都是文件，所以首先要通过 ulimit 配置文件描述符的数目；另一个限制是内存，按上面的数据结构，每个 TCP 连接都要占用一定内存，操作系统是有限的。



**多进程方式**

相当于你是一个代理，在那里监听来的请求。一旦建立了一个连接，就会有一个已连接 Socket，这时候你可以创建一个子进程，然后将基于已连接 Socket 的交互交给这个新的子进程来做

如何创建子公司，并如何将项目移交给子公司呢？

在 Linux 下，创建子进程使用 fork 函数。通过名字可以看出，这是在父进程的基础上完全拷贝一个子进程。在 Linux 内核中，会复制文件描述符的列表，也会复制内存空间，还会复制一条记录当前执行到了哪一行程序的进程。显然，复制的时候在调用 fork，复制完毕之后，父进程和子进程都会记录当前刚刚执行完 fork。这两个进程刚复制完的时候，几乎一模一样，只是根据 fork 的返回值来区分到底是父进程，还是子进程。如果返回值是 0，则是子进程；如果返回值是其他的整数，就是父进程。

![img](typora-user-images/18070c00ff5d0082yy1fbc32b84e73d0.jpg)

因为复制了文件描述符列表，而文件描述符都是指向整个内核统一的打开文件列表的，因而父进程刚才因为 accept 创建的已连接 Socket 也是一个文件描述符，同样也会被子进程获得。

接下来，子进程就可以通过这个已连接 Socket 和客户端进行互通了，当通信完毕之后，就可以退出进程，那父进程如何知道子进程干完了项目，要退出呢？还记得 fork 返回的时候，如果是整数就是父进程吗？这个整数就是子进程的 ID，父进程可以通过这个 ID 查看子进程是否完成项目，是否需要退出。



**多线程方式**

相比于进程来讲，这样要轻量级的多。

在 Linux 下，通过 pthread_create 创建一个线程，也是调用 do_fork。不同的是，虽然新的线程在 task 列表会新创建一项，但是很多资源，例如文件描述符列表、进程空间，还是共享的，只不过多了一个引用而已。

![img](typora-user-images/a36537201678e08ac83e5410562d5f64.jpg)

新的线程也可以通过已连接 Socket 处理请求，从而达到并发处理的目的。



上面基于进程或者线程模型的，其实还是有问题的。新到来一个 TCP 连接，就需要分配一个进程或者线程。一台机器无法创建很多进程或者线程。有个 C10K，它的意思是一台机器要维护 1 万个连接，就要创建 1 万个进程或者线程，那么操作系统是无法承受的。如果维持 1 亿用户在线需要 10 万台服务器，成本也太高了。



**IO多路复用，一个线程维护多个Socket**

由于 Socket 是文件描述符，因而某个线程盯的所有的 Socket，都放在一个文件描述符集合 fd_set 中，这就是项目进度墙，然后调用 select 函数来监听文件描述符集合是否有变化。一旦有变化，就会依次查看每个文件描述符。那些发生变化的文件描述符在 fd_set 对应的位都设为 1，表示 Socket 可读或者可写，从而可以进行读写操作，然后再调用 select，接着盯着下一轮的变化。



**IO多路复用，从轮询到回调**

上面 select 函数还是有问题的，因为每次 Socket 所在的文件描述符集合中有 Socket 发生变化的时候，都需要通过轮询的方式，也就是需要将全部项目都过一遍的方式来查看进度，这大大影响了一个项目组能够支撑的最大的项目数量。因而使用 select，能够同时盯的项目数量由 FD_SETSIZE 限制。

如果改成事件通知的方式，情况就会好很多，项目组不需要通过轮询挨个盯着这些项目，而是当项目进度发生变化的时候，主动通知项目组，然后项目组再根据项目进展情况做相应的操作。

能完成这件事情的函数叫 epoll，它在内核中的实现不是通过轮询的方式，而是通过注册 callback 函数的方式，当某个文件描述符发送变化的时候，就会主动通知。

![img](typora-user-images/d6efc5c5ee8e48dae0323de380dcf6b1.jpg)

如图所示，假设进程打开了 Socket m, n, x 等多个文件描述符，现在需要通过 epoll 来监听是否这些 Socket 都有事件发生。其中 epoll_create 创建一个 epoll 对象，也是一个文件，也对应一个文件描述符，同样也对应着打开文件列表中的一项。在这项里面有一个红黑树，在红黑树里，要保存这个 epoll 要监听的所有 Socket。

当 epoll_ctl 添加一个 Socket 的时候，其实是加入这个红黑树，同时红黑树里面的节点指向一个结构，将这个结构挂在被监听的 Socket 的事件列表中。当一个 Socket 来了一个事件的时候，可以从这个列表中得到 epoll 对象，并调用 call back 通知它。

这种通知方式使得监听的 Socket 数据增加的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了。上限就为系统定义的、进程打开的最大文件描述符个数。因而，epoll 被称为解决 C10K 问题的利器。





## 四、应用层

### 1、HTTP协议

浏览器上访问的URL，比如：http://www.baidu.com，叫做统一资源定位符。

其中www.baidu.com是一个域名，表示互联网上的一个位置



#### **HTTP请求的准备**

浏览器会将域名发送给DNS服务器，解析成IP地址。

HTTP是基于TCP协议的，先要建立TCP连接。

目前使用的HTTP协议大部分都是1.1，在1.1的协议里面，默认开启了Keep-Alive的，这样建立的TCP连接，可以在多次请求中复用。



#### **HTTP请求的构建**

![img](typora-user-images/85ebb0396cbaa45ce00b505229e523c1.jpeg)

HTTP报文分为三大部分，分别是请求行，首部和请求的正文实体

**请求行**

URL就是http://www.baidu.com，版本就是HTTP1.1

方法有GET、POST、PUT、DELETE



**首部字段**

首部是KV格式，通过冒号分隔，保存一些header信息

例如：Accept-Charset，表示客户端可接受的字符集。

Content-Type指的是正文的格式，例如是JSON



其中重点是缓存，因为一个页面中很多静态资源是不变的，如果没有缓存会重新请求服务端，造成压力，例如图片，css，js等文件。

架构如下：nginx有一个开启缓存的选项。

![img](typora-user-images/caec3ba1086557cbf694c621e7e01e1d.jpeg)



对于静态资源，有Nginx的 Vanish 缓存层。当缓存过期的时候，才会访问真正的 Tomcat 应用集群。



在HTTP头里面，Cache-control是用来控制缓存的，当客户端发送的请求中包含max-age指令时候，如果判断缓存层中，资源的缓存时间数值比指定时间的数值小，那么客户端可以接收缓存的资源，当指定max-age值为0，那么缓存层通常需要将请求转发给应用集群。

另外，If-Modified-Since 也是一个关于缓存的。也就是说，如果服务器的资源在某个时间之后更新了，那么客户端就应该下载最新的资源；如果没有更新，服务端会返回“304 Not Modified”的响应，那客户端就不用下载了，也会节省带宽。



**HTTP请求的发送**

HTTP 协议是基于 TCP 协议的，所以它使用面向连接的方式发送请求，通过 stream 二进制流的方式传给对方。当然，到了 TCP 层，它会把二进制流变成一个个报文段发送给服务器。

在发送给每个报文段的时候，都需要对方有一个回应 ACK，来保证报文可靠地到达了对方。如果没有回应，那么 TCP 这一层会进行重新传输，直到可以到达。同一个包有可能被传了好多次，但是 HTTP 这一层不需要知道这一点，因为是 TCP 这一层在埋头苦干。

TCP 层发送每一个报文的时候，都需要加上自己的地址（即源地址）和它想要去的地方（即目标地址），将这两个信息放到 IP 头里面，交给 IP 层进行传输。

IP 层需要查看目标地址和自己是否是在同一个局域网。如果是，就发送 ARP 协议来请求这个目标地址对应的 MAC 地址，然后将源 MAC 和目标 MAC 放入 MAC 头，发送出去即可；如果不在同一个局域网，就需要发送到网关，还要需要发送 ARP 协议，来获取网关的 MAC 地址，然后将源 MAC 和网关 MAC 放入 MAC 头，发送出去。

网关收到包发现 MAC 符合，取出目标 IP 地址，根据路由协议找到下一跳的路由器，获取下一跳路由器的 MAC 地址，将包发给下一跳路由器。

这样路由器一跳一跳终于到达目标的局域网。这个时候，最后一跳的路由器能够发现，目标地址就在自己的某一个出口的局域网上。于是，在这个局域网上发送 ARP，获得这个目标地址的 MAC 地址，将包发出去。

目标的机器发现 MAC 地址符合，就将包收起来；发现 IP 地址符合，根据 IP 头中协议项，知道自己上一层是 TCP 协议，于是解析 TCP 的头，里面有序列号，需要看一看这个序列包是不是我要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。

TCP 头里面还有端口号，HTTP 的服务器正在监听这个端口号。于是，目标机器自然知道是 HTTP 服务器这个进程想要这个包，于是将包发给 HTTP 服务器。HTTP 服务器的进程看到，原来这个请求是要访问一个网页，于是就把这个网页发给客户端。



**HTTP返回的构建**

基于HTTP1.1

![img](typora-user-images/6bc37ddcb4e7a61ca3275790820f2263.jpeg)

状态码有几种，1xx、2xx、3xx、4xx、5xx

首部中，Retry-After 表示，告诉客户端应该在多长时间以后再次尝试一下。“503 错误”是说“服务暂时不再和这个值配合使用”。

Content-Type，表示返回的是 HTML，还是 JSON。

构造好了返回的 HTTP 报文，接下来就是把这个报文发送出去。还是交给 Socket 去发送，还是交给 TCP 层，让 TCP 层将返回的 HTML，也分成一个个小的段，并且保证每个段都可靠到达。

这些段加上 TCP 头后会交给 IP 层，然后把刚才的发送过程反向走一遍。虽然两次不一定走相同的路径，但是逻辑过程是一样的，一直到达客户端。

客户端发现 MAC 地址符合、IP 地址符合，于是就会交给 TCP 层。根据序列号看是不是自己要的报文段，如果是，则会根据 TCP 头中的端口号，发给相应的进程。这个进程就是浏览器，浏览器作为客户端也在监听某个端口。

当浏览器拿到了 HTTP 的报文。发现返回“200”，一切正常，于是就从正文中将 HTML 拿出来。HTML 是一个标准的网页格式。浏览器只要根据这个格式，展示出一个绚丽多彩的网页。

这就是一个正常的 HTTP 请求和返回的完整过程。





#### HTTP2.0

**HTTP1的缺点：**

纯文本通信，每次通信都要带上完整的HTTP头部，如果不考虑http1.1的pipeline特性。TCP长连接复用是：一个请求响应完毕后，下一个请求才能发送，如果请求阻塞了，后面的请求都会受影响。（请求-响应、请求-响应 串行方式使用TCP长连接）。考虑pipeline的TCP长连接复用是：一个请求发送完毕后，无需等待响应便可发送下一个请求，但是服务端响应的时候只能按照客户端发送请求的顺序进行响应，如果第一个请求处理特别慢，后面的请求即使处理完毕，也需要等着，这就是著名的线头阻塞问题。

（请求1-请求2-请求3，响应1-响应2-响应3，半并行化使用TCP长连接，如果响应1阻塞，响应2、3即使完成了，也不能在TCP连接上传输，需等待响应1完成，响应2、3才能开始传输，这就是pipeline特性的线头阻塞问题。）

HTTP1.0每有一个请求建立一个TCP连接，三次握手耗时，TCP慢启动耗时，HTTP1.0的实时性可见一般，更别说并发性了，HTTP1.1可建立TCP长连接复用，实时性比HTTP1.0有索提高，但仍然会出现前一个请求阻塞，后一个请求无法使用TCP连接的情况，如果使用1.1的pipeline，则会出现线头阻塞问题，两个问题都会导致实时性、并发性的问题。



HTTP2.0会对HTTP的头进行一定的压缩，将原来每次都要携带的大量KV在两端建立一个索引表，对相同的头只发送索引表中的索引。

HTTP2.0协议将一个TCP中的连接，切分成多个流，每个流都有自身的ID，而且流可以是客户端发往服务端，也可以是服务端发往客户端，其实只是一个虚拟的通道，流是有优先级的。

HTTP2.0还将所有的传输信息分割成更小的消息和帧，并对他们采用二进制格式编码。常见的帧还有Header帧，用于传输Header内容，并会开启一个新的流。还有就是Data帧，用来传输正文实体，多个Data帧属于同一个流。

通过这两种机制，HTTP2.0的客户端可以将多个请求分到不同的流中，然后将请求内容拆成帧，进行二进制传输，这些帧可以打散乱序发送，然后根据每个帧首部的流标识符重新组装，并可以根据优先级，决定优先处理哪个流的数据。



例如下图，左边是HTTP1.1，串行发送，右边是HTTP2.0，可并行发送，而且不用按照顺序一一对应。

![img](typora-user-images/9a54f97931377dyy2fde0de93f4ecf1a.jpeg)

HTTP2.0其实是将三个请求变成三个流，将数据分成帧，乱序发送到一个TCP连接中。

![img](typora-user-images/3da001fac5701949b94e51caaee887d3.jpeg)

HTTP2.0成功解决了HTTP1.1的队首阻塞问题，同时，也不需要通过HTTP1.x的pipeline机制用多条TCP连接来实现并行请求与响应；减少了TCP连接数对服务器性能的影响，同时将页面的多个数据通过一个数据链接进行传输，能够加快页面组件的传输速度。





#### QUIC协议

HTTP2.0基于TCP协议，TCP协议在处理包时会有严格顺序要求，当其中一个数据包遇到问题，TCP链接需等待这个包完成重传之后才能继续进行，虽然HTTP2.0通过多个stream，使得逻辑上一个TCP连接上的并行内容，进行多路数据的传输，然后这中间并没有关联的数据，一前一后，前面stream2的帧没有收到，后面stream1的帧也会因此阻塞。



QUIC协议，是Google内部的一个UDP协议。



**机制一：自定义连接机制**

TCP由一个四元组确认一个连接，发生变化就得重连。移动互联网下，网络不稳定会再次重连，导致时延。

基于UDP，不再以四元组为标识，而是以一个64为的随机数作为ID来标识，而且UDP是无连接的，所以当IP或者端口变化的时候，只要ID不变，就不需要重新建立连接。



**机制二：自定义重传机制**

TCP超时重传是通过自适应重传算法，通过采用往返时间RTT不断调整。

QUIC 也有个序列号，是递增的。任何一个序列号的包只发送一次，下次就要加一了。例如，发送一个包，序号是 100，发现没有返回；再次发送的时候，序号就是 101 了；如果返回的 ACK 100，就是对第一个包的响应。如果返回 ACK 101 就是对第二个包的响应，RTT 计算相对准确。

QUIC 定义了一个 offset 概念。QUIC 既然是面向连接的，也就像 TCP 一样，是一个数据流，发送的数据在这个数据流里面有个偏移量 offset，可以通过 offset 查看数据发送到了哪里，这样只要这个 offset 的包没有来，就要重发；如果来了，按照 offset 拼接，还是能够拼成一个流。

![img](typora-user-images/805aa4261yyb30a2a0e5a2f06ce5162c.jpeg)



**机制三：无阻塞的多路复用**

同 HTTP 2.0 一样，同一条 QUIC 连接上可以创建多个 stream，来发送多个 HTTP 请求。但是，QUIC 是基于 UDP 的，一个连接上的多个 stream 之间没有依赖。这样，假如 stream2 丢了一个 UDP 包，后面跟着 stream3 的一个 UDP 包，虽然 stream2 的那个包需要重传，但是 stream3 的包无需等待，就可以发给用户。



**机制四：自定义流量控制**

TCP 的流量控制是通过滑动窗口协议。QUIC 的流量控制也是通过 window_update，来告诉对端它可以接受的字节数。但是 QUIC 的窗口是适应自己的多路复用机制的，不但在一个连接上控制窗口，还在一个连接中的每个 stream 控制窗口。

在 TCP 协议中，接收端的窗口的起始点是下一个要接收并且 ACK 的包，即便后来的包都到了，放在缓存里面，窗口也不能右移，因为 TCP 的 ACK 机制是基于序列号的累计应答，一旦 ACK 了一个序列号，就说明前面的都到了，所以只要前面的没到，后面的到了也不能 ACK，就会导致后面的到了，也有可能超时重传，浪费带宽。

QUIC 的 ACK 是基于 offset 的，每个 offset 的包来了，进了缓存，就可以应答，应答后就不会重发，中间的空档会等待到来或者重发即可，而窗口的起始位置为当前收到的最大 offset，从这个 offset 到当前的 stream 所能容纳的最大缓存，是真正的窗口大小。显然，这样更加准确。

![img](typora-user-images/a66563b46906e7708cc69a02d43afb22.jpg)





**http1.0的队首阻塞**

对于同一个tcp连接，所有的http1.0请求放入队列中，只有前一个请求的响应收到了，然后才能发送下一个请求。

可见，http1.0的队首组塞发生在客户端。

**http1.1的队首阻塞**

对于同一个tcp连接，http1.1允许一次发送多个http1.1请求，也就是说，不必等前一个响应收到，就可以发送下一个请求，这样就解决了http1.0的客户端的队首阻塞。但是，http1.1规定，服务器端的响应的发送要根据请求被接收的顺序排队，也就是说，先接收到的请求的响应也要先发送。这样造成的问题是，如果最先收到的请求的处理时间长的话，响应生成也慢，就会阻塞已经生成了的响应的发送。也会造成队首阻塞。

可见，http1.1的队首阻塞发生在服务器端。

**http2是怎样解决队首阻塞的**

http2无论在客户端还是在服务器端都不需要排队，在同一个tcp连接上，有多个stream，由各个stream发送和接收http请求，各个steam相互独立，互不阻塞。

只要tcp没有人在用那么就可以发送已经生成的requst或者reponse的数据，在两端都不用等，从而彻底解决了http协议层面的队首阻塞问题。





### 2、HTTPS协议

加密的方式有两种，一种是对称加密，一种是非对称加密

**对称加密**

加解密使用密钥是相同的

约定一个密钥进行加密。





**非对称加密**

加解密使用过的密钥不同，一个是公开的公钥，一个是私有的私钥，公钥加密的信息，只要私钥才能解密，私钥加密的信息，只有公钥才能解密。

客户端发送，使用服务端公钥加密，服务端发送，使用客户端公钥加密。





**数字证书**

证书由权威机构CA发布，证书里有公钥、证书所有者、证书发布机构和证书有效期。

CA会用一个签名算法给证书签名，用只掌握在权威机构手里的东西签名了才行，这就是CA的私钥。

签名算法大概是这样工作的：一般是对信息做一个 Hash 计算，得到一个 Hash 值，这个过程是不可逆的，也就是说无法通过 Hash 值得出原来的信息内容。在把信息发送出去时，把这个 Hash 值加密后，作为一个签名和信息一起发出去

此时请求会得到一个证书，证书有个发布机构CA，只要获取此CA的公钥，去解密证书的签名，解密成功并Hash也对的上，就说明这个公钥没有问题。

请求的时候将证书（证书也是通过CA私钥加密的）发给服务端，服务端获取到相应机构的公钥，用来解密证书，解密后，校验Hash值，如果校验成功，说明公钥没问题，此时就会获取到客户端的公钥。



如何确定CA的公钥就是正确的？

CA 的公钥也需要更牛的 CA 给它签名，然后形成 CA 的证书。要想知道某个 CA 的证书是否可靠，要看 CA 的上级证书的公钥，能不能解开这个 CA 的签名。这样层层上去，直到全球皆知的几个著名大 CA，称为 root CA，做最后的背书。通过这种层层授信背书的方式，从而保证了非对称加密模式的正常运转。



**HTTPS的工作模式**

![img](typora-user-images/df1685dd308cef1db97e91493f911ab4.jpg)

首先，服务端需要向证书颁发机构申请一个自己的证书，这个证书里面会包含此该站点的基本信息，个人啊，公司啊，组织什么呢，我记得CA证书好像分三类的，然后还有该证书的 签名 以及 hash 值用于在通信中客户端鉴别此证书是否合法。



https 通信分为四个步骤：

\1. c->s,客户端发起加密通信请求，这个请求通常叫做 ClientHello请求，告知自己支持的协议版本号，加密算法，压缩算法，以及一个用于生成后续通信密钥的随机数；
\2. s->c,服务端响应，也叫作 ServerHello，确认加密通信协议，加密算法，以及一个用于生成后续通信密钥的随机数，还有网站证书；
\3. c->s,客户端在收到上一步服务端的响应之后，首先会检查证书的颁发者是否可信任，是否过期，域名是否一致，并且从操作系统的证书链中找出该证书的上一级证书，并拿出服务端证书的公钥，然后验证签名和hash，如果验证失败，就会显示警告，我们经常在Chrome里面看到，“此网站有风险，是否继续什么的”。如果验证通过，客户端会向服务端发送一个称作 “pre-master-key” 的随机数，该随机数使用证书的公钥加密，以及编码改变通知（以后咋们就用协商的密钥堆成加密通信了），客户端完成握手。
\4. 服务端在收到上一步客户端请求之后，也会确认我以后发给你的信息可就加密了哦，并且完成握手。

此时，客户端有第一步自己生成的随机数，第二步收到服务端的随机数，第三步的 pre-master-key，服务端也是如此，他们就可以用这三个随机数使用约定的算法生成同一个密钥来加密以后的通信数据了。





**重放与篡改**

有了加密和解密，黑客截获了包也打不开了，但是它可以发送 N 次。这个往往通过 Timestamp 和 Nonce 随机数联合起来，然后做一个不可逆的签名来保证。

Nonce 随机数保证唯一，或者 Timestamp 和 Nonce 合起来保证唯一，同样的，请求只接受一次，于是服务器多次收到相同的 Timestamp 和 Nonce，则视为无效即可。

如果有人想篡改 Timestamp 和 Nonce，还有签名保证不可篡改性，如果改了用签名算法解出来，就对不上了，可以丢弃了。

Nonce是由服务器生成的一个随机数，在客户端第一次请求页面时将其发回客户端；客户端拿到这个Nonce，将其与用户密码串联在一起并进行非可逆加密（MD5、SHA1等等），然后将这个加密后的字符串和用户名、Nonce、加密算法名称一起发回服务器；服务器使用接收到的用户名到数据库搜索密码，然后跟客户端使用同样的算法对其进行加密，接着将其与客户端提交上来的加密字符串进行比较，如果两个字符串一致就表示用户身份有效。这样就解决了用户密码明文被窃取的问题，攻击者就算知道了算法名和nonce也无法解密出密码。

 

每个nonce只能供一个用户使用一次，这样就可以防止攻击者使用重放攻击，因为该Http报文已经无效。可选的实现方式是把每一次请求的Nonce保存到数据库，客户端再一次提交请求时将请求头中得Nonce与数据库中得数据作比较，如果已存在该Nonce，则证明该请求有可能是恶意的。然而这种解决方案也有个问题，很有可能在两次正常的资源请求中，产生的随机数是一样的，这样就造成正常的请求也被当成了攻击，随着数据库中保存的随机数不断增多，这个问题就会变得很明显。所以，还需要加上另外一个参数Timestamp（时间戳）。

 

Timestamp是根据服务器当前时间生成的一个字符串，与nonce放在一起，可以表示服务器在某个时间点生成的随机数。这样就算生成的随机数相同，但因为它们生成的时间点不一样，所以也算有效的随机数



## 五、数据中心

### 1、DNS协议

#### （1）DNS服务器

DNS服务器可根据域名解析成相应的IP地址。

DNS服务器，一定是高可用、高并发和分布式的。

![img](typora-user-images/890ff98fde625c6a60fb71yy22d8184d.jpg)

- 根DNS服务器：返回顶级域DNS服务器的IP地址
- 顶级域DNS服务器：返回权威DNS服务器的IP地址
- 权威DNS服务器：返回相应主机的IP地址



#### （2）DNS解析流程

<img src="typora-user-images/718e3a1a1a7927302b6a0f836409e8e8.jpg" alt="img" style="zoom: 50%;" />

为了提高DNS的解析性能，很多网络都会就近部署DNS缓存服务器。

1. 浏览器访问www.baidu.com，发一个DNS请求，询问对应的IP是啥，并发给本地域名服务器（本地DNS）。

   **何为本地NDS？** 如果通过DHCP配置，本地DNS由网络服务商（ISP），如电信、移动等自动分配，通常就在网络服务商的某个机房。

2. 本地DNS收到请求，本地DNS缓存着一张域名和IP对应的表，如果找到则直接返回IP地址。如果没有，本地DNS会去询问根域名服务器对应的IP地址是啥，根域名服务器是最高层次的，不直接用于域名解析，当能说明可去哪解析。

3. 根DNS收到本地DNS请求后，发现后缀是.com，返回顶级域名服务器的地址

4. 本地DNS随即请求顶级域名服务器查询对应的IP，顶级域名服务器管理者二级域名，比如baidu.com，所以它返回权威DNS服务器的地址。

5. 本地DNS拿到权威DNS服务器地址，请求获取对应的IP，权威DNS服务器查询后将对应的IP地址返回给本地DNS

6. 本地DNS再将IP地址返回客户端，客户端和目标建立连接。



#### （3）负载均衡

根据域名查询IP是一次DNS递归查询过程。本地DNS全权处理。在此过程中，DNS除了可以通过名称映射IP地址，还可以做另一件事，就是负载均衡。

DNS可以做内部负载均衡，域名和IP具有一对多的关系，配置域名比直接配置IP更具有灵活性。

DNS可以做全局负载均衡，高可用、就近访问



例如：DNS 访问数据中心中对象存储上的静态资源

假设全国有多个数据中心，托管在多个运营商，每个数据中心三个可用区（Available Zone）。对象存储通过跨可用区部署，实现高可用性。在每个数据中心中，都至少部署两个内部负载均衡器，内部负载均衡器后面对接多个对象存储的前置服务器（Proxy-server）。

![img](typora-user-images/0b241afef775a1c942c5728364b302b6.jpg)

对于复杂的应用、跨地域跨运营商的大型应用，则需要更加复杂的全局负载均衡机制，这就是全局负载均衡器（GSLB，Global Server Load Balance）。

权威DNS服务器中，一般通过配置CNAME的方式，给域名起一个别名，例如：www.vip.baidu.com，然后告诉本地DNS服务器，让它请求GSLB解析这个域名，GSLB就可以在解析这个域名的过程中，通过自身策略实现负载均衡。

图中画了两层的 GSLB，是因为分运营商和地域。我们希望不同运营商的客户，可以访问相同运营商机房中的资源，这样不跨运营商访问，有利于提高吞吐量，减少时延。



1. 第一层 GSLB，通过查看请求它的本地 DNS 服务器所在的运营商，就知道用户所在的运营商。假设是移动，通过 CNAME 的方式，通过另一个别名 object.yd.yourcompany.com，告诉本地 DNS 服务器去请求第二层的 GSLB。
2. 第二层 GSLB，通过查看请求它的本地 DNS 服务器所在的地址，就知道用户所在的地理位置，然后将距离用户位置比较近的 Region 里面，六个内部负载均衡（SLB，Server Load Balancer）的地址，返回给本地 DNS 服务器。
3. 本地 DNS 服务器将结果返回给本地 DNS 解析器。
4. 本地 DNS 解析器将结果缓存后，返回给客户端。
5. 客户端开始访问属于相同运营商的距离较近的 Region 1 中的对象存储，当然客户端得到了六个 IP 地址，它可以通过负载均衡的方式，随机或者轮询选择一个可用区进行访问。对象存储一般会有三个备份，从而可以实现对存储读写的负载均衡。



### 2、HttpDNS

#### （1）传统DNS存在问题？

1、域名缓存问题

DNS会有本地缓存，如果服务器有变化而缓存没更新，就会请求失败。

本地缓存往往使得全局负载均衡失败，因为上次的缓存地址不一定是最近的。

2、域名转发问题

缓存问题还是说本地域名解析服务，依然会去权威DNS服务器中查找，只不过不是每次都查找

3、出口NAT问题

在有NAT网关的时候，会使从这个网关出去的包，换成新的IP地址。做了转换之后，权威DNS服务器就没法通过这个地址判断客户到底是来自哪个运营商，会导致跨运营商的访问

4、域名更新问题

在服务出问题时往往需要修改权威DNS，将域名执行新的IP地址，如果本地缓存更新太慢，会出现访问异常

5、解析延迟问题

DNS查询过程需要递归遍历多个DNS服务器，才能获取最终的解析结果，这个过程会有一个的时延。



#### （2）HttpDNS的工作模式

HttpDNS就是不走传统的DNS解析，而是自己搭建基于HTTP协议的DNS服务器集群，分布在多个地点和多个运营商。当客户端需要DNS解析的时候，直接通过HTTP协议进行请求这个服务器集群，得到就近的地址。

通常是手机应用需要走HttpDNS

**HttpDNS的工作模式**

在客户端的SDK里动态请求服务端，获取HttpDNS服务器的IP列表，缓存到本地，随着不断解析域名，SDK也会在本地缓存DNS域名解析的结果。

当手机应用需要访问一个地址时，先查看是否有本地缓存，有则返回，无则请求HttpDNS的服务器，在本地HttpDNS服务器的IP列表中，选择一个发出HTTP的请求，会返回一个要访问的网站的IP列表。

![img](typora-user-images/aa45cf8a07b563ccea376f712b2e8975.jpg)

当HttpDNS无法提供服务时，可切换到传统的本地DNS去解析。

两大问题：

- 解析速度和更新速度的平衡问题
- 只能调度的问题

对应解决方案是HttpDNS的缓存设计和调度设计



**HttpDNS的缓存设计**

一方面，解析的过程，不需要本地DNS服务递归的调用，一个HTTP请求直接搞定，可实时更新

另一方面为了提高解析速度，本地也有缓存，缓存是在客户SDK维护的，过期时间、更新时间都可控制

HttpDNS的缓存设计策略也遵循应用架构中常用的缓存设计模式，分为客户端、缓存、数据源三层

![img](typora-user-images/9e0141a2939e7c194689e990859ed456.jpg)

解析可以同步进行，直接调用HttpDNS的接口，返回最新记录，更新缓存

![img](typora-user-images/346a1bf30fb56ef918d708f422dc3bb4.jpg)



也可以异步进行，添加一个解析任务到后台，由后台任务调用HttpDNS的接口。

优点是可将多个请求发现过期的情况合并成一个对于HttpDNS的请求任务，只执行一次。同时可在即将过期的时候，创建一个任务进行预加载，防止过期之后再刷新，这就是预加载

缺点是拿到过期数据时候，如果客户端允许使用过期数据并请求失败的情况，只能等下次缓存更新后，才能请求成功。

![img](typora-user-images/df65059e9b66c32bbbca6febf6ecb298.jpg)



**HttpDNS的调度设计**

- 客户端：HttpDNS可根据客户端提供的消息选择最佳的服务节点访问
- 服务端：通过调用HttpDNS的管理接口，配置不同服务质量的优先级、权重。HttpDNS会根据这些策略综合地址位置和线路状况算出一个排序、优先访问当前哪些优质的、时延低的IP地址。

![img](typora-user-images/3b368yy7a4f2319bd6491bc4e66e55ae.jpg)

HttpDNS 通过智能调度之后返回的结果，也会缓存在客户端。为了不让缓存使得调度失真，客户端可以根据不同的移动网络运营商 WIFI 的 SSID 来分维度缓存。不同的运营商或者 WIFI 解析出来的结果会不同。



### 3、CDN

**CDN 和电商系统的分布式仓储系统一样，分为中心节点、区域节点、边缘节点，而数据缓存在离用户最近的位置。**

在数据中心部署一个用于缓存的集群来缓存部分数据，当访问数据时，就可以进行就近访问。

分布在各个地方的各个数据中心的节点，称为边缘节点

由于边缘节点数目较多，但每个集群规模较小，不可能缓存所有东西，所以可能无法命中，所以在边缘节点之上由区域系欸但，规模较大，缓存数据更多，命中概率更大，区域节点之上时中心节点，规模更大，缓存数据更多。如果还无法命中，只好回源网站访问。

**CＤＮ分发系统的架构**

![img](typora-user-images/5fbe602d9b85966d9a1748d2e6aa6425.jpeg)

**客户端如何找到相应的边缘节点进行访问呢？**

![img](typora-user-images/c4d826188e664605d6f8dfb82e348824.jpeg)

在没有CDN的情况下，会访问本地DNS，然后递归根DNS至权威DNS服务器获取IP地址。

有CND后，会在web.com权威DNS服务器上，这是一个CNAME别名，指向另一个域名www.web.cdn.com，返回给本地DNS服务器

当本地 DNS 服务器拿到这个新的域名时，需要继续解析这个新的域名。这个时候，再访问的就不是 web.com 的权威 DNS 服务器了，而是 web.cdn.com 的权威 DNS 服务器，这是 CDN 自己的权威 DNS 服务器。在这个服务器上，还是会设置一个 CNAME，指向另外一个域名，也即 CDN 网络的全局负载均衡器。

接下来，本地 DNS 服务器去请求 CDN 的全局负载均衡器解析域名，全局负载均衡器会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：

- 根据用户 IP 地址，判断哪一台服务器距用户最近；
- 用户所处的运营商；
- 根据用户所请求的 URL 中携带的内容名称，判断哪一台服务器上有用户所需的内容；
- 查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。

基于以上这些条件，进行综合分析之后，全局负载均衡器会返回一台缓存服务器的 IP 地址。







**CDN 最擅长的是缓存静态数据，除此之外还可以缓存流媒体数据，这时候要注意使用防盗链。它也支持动态数据的缓存，一种是边缘计算的生鲜超市模式，另一种是链路优化的冷链运输模式。**

![img](typora-user-images/caec3ba1086557cbf694c621e7e01eaa1d.jpeg)





### 4、数据中心

数据中心的服务器被放在叫做**机架（Rack）**的架子上，数据中心的出入口也是路由器，称为**边界路由器**

一个机架上面的机器通过交换机进行互通，叫做**接入层交换机**

A机架上面的机器和B机架上面的机器也是通过交换机进行互通，叫做**汇聚层交换机**

![img](typora-user-images/8fdfb8d4e1cd5a9a086f99b98a7555f8.jpg)



一台服务器需要多张网卡，形成高可用，多张网卡聚合成一张网卡（这种协议称为LACP协议），这就是**网卡绑定**

交换机可需要进行高可用配置，当形成环路后，可用STP协议解决，此时只有一条路可通。

![img](typora-user-images/116a168c0eb55fabd7786fca728bd850.jpg)

交换机有一种技术叫**堆叠**，将多个交换机形成一个逻辑上的交换机，服务器通过多跟线连到接入层交换机，而接入层交换机也可以通过多跟线连到汇聚层交换机，通过堆叠的私有协议，形成双活的连接方式。

![img](typora-user-images/10aa7eac3fd38dfc2a09d6475ff4d93a.jpg)

汇聚层将大量的计算节点进行互连，形成一个集群，此集群中服务器之间通过二层互通，这个区域常被称为一个POD，也称为一个可用区



当节点数目到了一个可用区能容纳的最多的数之后，需将多个可用区连在一起，连接多个可用区的交换机称为**核心交换机**

![img](typora-user-images/080ce3bbe673de38e196b5b741a86313.jpg)

当三层存在环路的情况下，可使用动态路由协议OSPF选择最佳的路径即可。

![img](typora-user-images/be86f9a94002cf8d849a229ce5993cyy.jpeg)



当集群规模非常大而且都要求在一个二层网络里面，这就需要二层互联从汇聚层上升到核心层，也即是核心以下，全都是二层互连，全在一个广播域里面，这就是常说的**大二层**

![img](typora-user-images/2aa3787c31c52defc7614c53f0a71d2c.jpg)







三层网络结构：接入层、汇聚层、核心层，流量都是从上到下，从下到上，称为南北流量

![img](typora-user-images/dd39a95064b2132d78e3a2efb0723bb3.jpg)

而对于需要节点之间互拷数据的，称为东西流量，此时出现了**叶脊网络**

- **叶子交换机（leaf）**：直连物理服务器，L2/L3网络的分界点在叶子交换机上，叶子交换机之上是三层网络。
- **脊交换机（spine switch）**：相当于核心交换机，叶脊之间通过 ECMP 动态选择多条路径。脊交换机现在只是为叶子交换机提供一个弹性的 L3 路由网络。南北流量可以不用直接从脊交换机发出，而是通过与 leaf 交换机并行的交换机，再接到边界路由器出去。



![img](typora-user-images/99f86d113a629d81bb52786d80ca5c92.jpg)







**小结**

- 数据中心分为三层。服务器连接到接入层，然后是汇聚层，再然后是核心层，最外面是边界路由器和安全设备。
- 数据中心的所有链路都需要高可用性。服务器需要绑定网卡，交换机需要堆叠，三层设备可以通过等价路由，二层设备可以通过 TRILL 协议。
- 随着云和大数据的发展，东西流量相对于南北流量越来越重要，因而演化为叶脊网络结构。





### 5、VPN

VPN可以将一个机构的多个数据中心通过隧道的方式连接起来，让机构感觉在一个数据中心里面。

完全基于软件的IPsec VPN可以保证私密性、完整性、真实性、简单便宜，但性能稍微差。

MPLS-VPN综合了IP转发模式和ATM的标签转发模式的又是，性能较好，但需要从运营商处购买。



**IPsec VPN**，基于IP协议的安全隧道协议。

为保证在公网上面信息的安全，才需一定的机制保证安全性。

- 私密性，防止信息泄露给未经授权的个人，通过加密把数据从明文变成无法读懂的密文，从而确保数据的私密性。
  - 采用对称加密
- 完整性，数据没有被非法篡改，通过对数据进行hash运算，产生类似于指纹的数据摘要，保证数据完整性
- 真实性，数据确实是由特定的对端发出，通过身份认证可保证数据的真实性

![img](typora-user-images/e43f13e5c68c9a5455b3793fb530a4c2.jpeg)



![img](typora-user-images/24c89b7703ffcb7ce966f9d259b06eea.jpeg)





## 六、云计算网络

### 1、网络模式

数据中心里，有一种开源技术qemu-kvm，能在物理机中搭建一台台小的虚拟机。

用软件模拟硬件方式，emu就是Emulator模拟器的意思，主要会模拟CPU、内存、网络、硬盘，让虚拟机觉得像是在使用独立的设备。

例如：多个虚拟机轮流使用物理CPU，内存也是使用虚拟内存映射的方式，最终映射到物理内存上。硬盘在一块大的文件系统上创建一个N个G的文件，作为虚拟机的硬盘。

#### （1）虚拟网卡的原理

https://static001.geekbang.org/resource/image/93/ca/93ec56f83d51c17f788c715a45c6bfca.jpeg

![img](typora-user-images/93ec56f83d51c17f788c715a45c6bfca.jpeg)



首先，虚拟机要有一张网卡，对于qemu-kvm来说，是通过Linux上的一种TUN/TAP技术来实现的。

虚拟机时物理机上跑着的一个软件，可以打开一个称为TUN/TAP的Char Dev（字符设备文件）。打开了这个文件之后，在物理机上就能看到一张虚拟TAP网卡。

虚拟出网卡之后，虚拟机里的应用就会把所有的网络包都发往这个网卡。

网络包回到虚拟化软件这里，会将网络包转换成文件流，写入字符设备，就像写一个文件一样，内核中TUN/TAP字符设备驱动会收到这个写入的文件流，较给TUN/TAP的虚拟网卡驱动，此驱动将文件流再次转成网络包，较给TCP/IP协议栈，最终从虚拟TAP网卡发出，成为标准的网络包。



#### （2）虚拟网卡练到数据中心网络中

重点关注：

- 共享：多个虚拟网卡如何共享同一个出口？
- 隔离：分两个方面，一个是安全隔离，两个虚拟机可能属于两个用户，那怎么保证一个用户的数据不被另一个用户窃听？一个是流量隔离，两个虚拟机，如果有一个疯狂下片，会不会导致另外一个上不了网？
- 互通：分两个方面，一个是如果同一台机器上的两个虚拟机，属于同一个用户的话，这两个如何相互通信？另一个是如果不同物理机上的两个虚拟机，属于同一个用户的话，这两个如何相互通信？
- 灵活：虚拟机和物理不同，会经常创建、删除，从一个机器漂移到另一台机器，有的互通、有的不通等等，灵活性比物理网络要好得多，需要能够灵活配置。



**共享与互通**

（1）两台虚拟机如何互连？

在物理机上，应该有一个虚拟的交换机，Linux上用 brctl 可以创建虚拟网桥 brctl addbr br0 ，创建出来后，将两个虚拟机的虚拟网卡，都连接到虚拟网桥 brctl addif br0 tap0 上，这样将两个虚拟机配置相同的子网网段，两台虚拟机就能够互相通信了。

![img](typora-user-images/793469d10d57b4845d5678c266a9a6f1.jpeg)



（2）如何连接外网？

有两种方式，分别是桥接和NAT。

**桥接：**

![img](typora-user-images/64d80d328f318b90d8d83a584138ffd4.jpeg)



每个虚拟机都会有虚拟网卡，在主机上会发现多了几个网卡，其实是虚拟交换机。这个虚拟交换机将虚拟机连接在一起。在桥接模式下，物理网卡也连接到这个虚拟交换机上，物理网卡在桌面虚拟化软件上，在“界面名称”那里选定。

相当于将物理机和虚拟机放在同一个网桥上，相当于这个网桥上有三台机器，是一个网段的

![img](typora-user-images/f90500a85292a466df2dd4e6cab1e2e3.jpeg)



数据中心的网络也是类似：

![img](typora-user-images/44d70c3de1258337af8b352c767bb044.jpeg)

![img](typora-user-images/03e8e31978040de9ffcb21413bb0f830.jpeg)

都在一个二层网络里，彼此用相同网段访问即可，当规模很大时，会存在问题。

在一个二层网络里面，最大的问题是广播。一个数据中心的物理机已经很多了，广播已经非常严重，需要通过 VLAN 进行划分。如果使用了虚拟机，假设一台物理机里面创建 10 台虚拟机，全部在一个二层网络里面，那广播就会很严重，所以除非是你的桌面虚拟机或者数据中心规模非常小，才可以使用这种相对简单的方式。



**NAT：**

![img](typora-user-images/2e959deab0e3e3a5c183033bf108eb41.jpeg)

此时虚拟机的IP跟物理机的网段是不同的，虚拟机想要访问物理机的时候，需要将地址NAT转换成物理机的地址。

还会内置一个DHCP服务器，为虚拟机动态分配IP地址，因为虚拟机的网络自称体系，需要进行IP管理。

桥接网络的IP地址由物理网络的DHCP服务器分配。

![img](typora-user-images/a37a80a624d8acee6f2cd8e41571972a.jpeg)





**隔离**

一台机器上的两个虚拟机不属于同一个用户？

brctl创建的网桥也是支持VLAN功能的，可设置两个虚拟机的tag，这样在两个虚拟网桥上，两个虚拟机是不互通的。



如何跨物理机互通，并且实现 VLAN 的隔离呢？

有一个命令 vconfig，可以基于物理网卡 eth0 创建带 VLAN 的虚拟网卡，所有从这个虚拟网卡出去的包，都带这个 VLAN，如果这样，跨物理机的互通和隔离就可以通过这个网卡来实现。

![img](typora-user-images/4b6aa2b970ac285be94c3af082153912.jpg)

首先为每个用户分配不同的 VLAN，例如有一个用户 VLAN 10，一个用户 VLAN 20。在一台物理机上，基于物理网卡，为每个用户用 vconfig 创建一个带 VLAN 的网卡。不同的用户使用不同的虚拟网桥，带 VLAN 的虚拟网卡也连接到虚拟网桥上。

这样是否能保证两个用户的隔离性呢？不同的用户由于网桥不通，不能相互通信，一旦出了网桥，由于 VLAN 不同，也不会将包转发到另一个网桥上。另外，出了物理机，也是带着 VLAN ID 的。只要物理交换机也是支持 VLAN 的，到达另一台物理机的时候，VLAN ID 依然在，它只会将包转发给相同 VLAN 的网卡和网桥，所以跨物理机，不同的 VLAN 也不会相互通信。







**小结：**

- 云计算的关键技术是虚拟化，这里我们重点关注的是，虚拟网卡通过打开 TUN/TAP 字符设备的方式，将虚拟机内外连接起来；

- 云中的网络重点关注四个方面，共享、隔离、互通、灵活。其中共享和互通有两种常用的方式，分别是桥接和 NAT，隔离可以通过 VLAN 的方式。





### 2、软件定义网络（SDN）

![img](typora-user-images/346fe3b3dbe1024e7119ec4ffa9377f9.jpg)

有三个特点：

- **控制与转发分离：**
  - 转发平面就是一个个虚拟或者物理的网络设备，就像小区里面的一条条路。控制平面就是统一的控制中心，就像小区物业的监控室。它们原来是一起的，物业管理员要从监控室出来，到路上去管理设备，现在是分离的，路就是走人的，控制都在监控室。
- **控制平面与转发平面之间的开放接口：**
  - 制器向上提供接口，被应用层调用，就像总控室提供按钮，让物业管理员使用。控制器向下调用接口，来控制网络设备，就像总控室会远程控制电梯的速度。这里经常使用两个名词，前面这个接口称为北向接口，后面这个接口称为南向接口，上北下南嘛。
- **逻辑上的集中控制：**
  - 逻辑上集中的控制平面可以控制多个转发面设备，也就是控制整个物理网络，因而可以获得全局的网络状态视图，并根据该全局网络状态视图实现对网络的优化控制，就像物业管理员在监控室能够看到整个小区的情况，并根据情况优化出入方案。



####  （1）OpenFlow和OpenSwitch

OpenFlow 是 SDN 控制器和网络设备之间互通的南向接口协议，

OpenvSwitch 用于创建软件的虚拟交换机。

OpenvSwitch 是支持 OpenFlow 协议的，当然也有一些硬件交换机也支持 OpenFlow 协议

。它们都可以被统一的 SDN 控制器管理，从而实现物理机和虚拟机的网络连通。

![img](typora-user-images/220b53c0f027763yy54c1a08yy2e5a15.jpg)



**SDN 控制器是如何通过 OpenFlow 协议控制网络的呢？**

![img](typora-user-images/1c739b9ecc23e9b7c246136782fcd078.jpg)

在 OpenvSwitch 里面，有一个流表规则，任何通过这个交换机的包，都会经过这些规则进行处理，从而接收、转发、放弃。

那流表长啥样呢？其实就是一个个表格，每个表格好多行，每行都是一条规则。每条规则都有优先级，先看高优先级的规则，再看低优先级的规则。

![img](typora-user-images/314c82553a164444437b25b215fa012f.jpg)

对于每一条规则，要看是否满足匹配条件。这些条件包括，从哪个端口进来的，网络包头里面有什么等等。满足了条件的网络包，就要执行一个动作，对这个网络包进行处理。可以修改包头里的内容，可以跳到任何一个表格，可以转发到某个网口出去，也可以丢弃。

通过这些表格，可以对收到的网络包随意处理。

<img src="typora-user-images/8e8751005253a47a823f08d6ac6cfc1a.jpg" alt="img" style="zoom: 200%;" />

具体都能做什么处理呢？通过上面的表格可以看出，简直是想怎么处理怎么处理，可以覆盖 TCP/IP 协议栈的四层。



对于物理层：

- 匹配规则包括从哪个口进来
- 执行动作包括从哪个口出去

对于MAC层：

- 匹配规则包括：源MAC是多少？（dl_src）,目标 MAC 是多少？（dl_dst），所属 vlan 是多少？（dl_vlan）；
- 执行动作包括：修改源 MAC（mod_dl_src），修改目标 MAC（mod_dl_dst），修改 VLAN（mod_vlan_vid），删除 VLAN（strip_vlan），MAC 地址学习（learn）。

对于网络层：

- 匹配规则包括：源 IP 地址是多少？(nw_src)，目标 IP 是多少？（nw_dst）。
- 执行规则包括：修改源 IP 地址（mod_nw_src），修改目标 IP 地址（mod_nw_dst）。

对于传输层：

- 匹配规则包括：源端口是多少？（tp_src），目标端口是多少？（tp_dst）
- 执行动作包括：修改源端口（mod_tp_src），修改目标端口（mod_tp_dst）。

对于 OpenvSwitch 来讲，网络包到了我手里，就是一个 Buffer，我想怎么改怎么改，想发到哪个端口就发送到哪个端口。



**用OpenvSwitch实现VLAN的功能**

在OpenvSwitch中端口port分两种

第一类是 access port：

- 这个端口配置 tag，从这个端口进来的包会被打上这个 tag；
- 如果网络包本身带有的 VLAN ID 等于 tag，则会从这个 port 发出；
- 从 access port 发出的包不带 VLAN ID。

第二类是trunk port：

- 这个 port 不配置 tag，配置 trunks；
- 如果 trunks 为空，则所有的 VLAN 都 trunk，也就意味着对于所有 VLAN 的包，本身带什么 VLAN ID，就是携带着什么 VLAN ID，如果没有设置 VLAN，就属于 VLAN 0，全部允许通过；
- 如果 trunks 不为空，则仅仅带着这些 VLAN ID 的包通过。



**OpenvSwitch还能模拟网卡绑定，连接交换机**

在 OpenvSwitch 里面，有个 bond_mode，可以设置为以下三个值：

- active-backup：一个连接是 active，其他的是 backup，当 active 失效的时候，backup 顶上；
- balance-slb：流量安装源 MAC 和 output VLAN 进行负载均衡；
- balance-tcp：必须在支持 LACP 协议的情况下才可以，可根据 L2, L3, L4 进行负载均衡。





**如何在云计算中使用OpenvSwitch？**

![img](typora-user-images/102a3c46c36047498139d8bcbd7551e5.jpg)









**总结：**

- 用 SDN 控制整个云里面的网络，就像小区保安从总控室管理整个物业是一样的，将控制面和数据面进行了分离；
- 一种开源的虚拟交换机的实现 OpenvSwitch，它能对经过自己的包做任意修改，从而使得云对网络的控制十分灵活；
- 将 OpenvSwitch 引入了云之后，可以使得配置简单而灵活，并且可以解耦物理网络和虚拟网络。





由于 OpenvSwitch 本身就是支持 VLAN 的，所有的虚拟机都可以放在一个网桥 br0 上，通过不同的用户配置不同的 tag，就能够实现隔离。



### 3、iptables

对于公有云上的虚拟机，仅仅开放需要的端口，而将其它端口一概关闭，此时，只要通过安全措施守护好这个唯一的入口就可以了

采用的方式是**ACL（Access Control List 访问控制列表）**来控制IP和端口



设置好这些规则，只有指定的IP段能访问指定的开放接口，这些规则的集合称为**安全组**



当一个网络包进入一台机器的时候，会做什么事情？

首先取下MAC查看是否是本机的，如果是，则取下IP头，得到目标IP后，就开始进行路由判断，判断之前，这个节点称为PREROUTING，如果发现IP是本机的，就发给传输层，这个节点叫做INPUT，如果IP不是本机的，就需要转发出去，称为FORWARD，上层处理完后，会将处理结果发出去，称为OUTPUT，无论是FORWARD还是OUTPUT，都是路由判断之后发生的，最后一个节点是POSTROUTING

![img](typora-user-images/a924ccda5d54bcad6f67fdebe0a6c1fc.jpg)

**为什么要格外关注这五个节点呢？**

是因为在 Linux 内核中，有一个框架叫 Netfilter。它可以在这些节点插入 hook 函数。这些函数可以截获数据包，对数据包进行干预。例如做一定的修改，然后决策是否接着交给 TCP/IP 协议栈处理；或者可以交回给协议栈，那就是 ACCEPT；或者过滤掉，不再传输，就是 DROP；还有就是 QUEUE，发送给某个用户态进程处理。

一个著名的实现，就是内核模块 ip_tables。它在这五个节点上埋下函数，从而可以根据规则进行包的处理。按功能可分为四大类：连接跟踪（conntrack）、数据包的过滤（filter）、网络地址转换（nat）和数据包的修改（mangle）。其中连接跟踪是基础功能，被其他功能所依赖。其他三个可以实现包的过滤、修改和网络地址转换。

在用户态，还有一个你肯定知道的客户端程序 iptables，用命令行来干预内核的规则。内核的功能对应 iptables 的命令行来讲，就是表和链的概念。

![img](typora-user-images/897618c5f5b65e8c35ef5f20a731cdfd.jpg)

iptables 的表分为四种：raw–>mangle–>nat–>filter。这四个优先级依次降低，raw 不常用，所以主要功能都在其他三种表里实现。每个表可以设置多个链。

filter 表处理过滤功能，主要包含三个链：

- INPUT 链：过滤所有目标地址是本机的数据包；
- FORWARD 链：过滤所有路过本机的数据包；
- OUTPUT 链：过滤所有由本机产生的数据包。

nat 表主要是处理网络地址转换，可以进行 Snat（改变数据包的源地址）、Dnat（改变数据包的目标地址），包含三个链：

- PREROUTING 链：可以在数据包到达防火墙时改变目标地址；
- OUTPUT 链：可以改变本地产生的数据包的目标地址；
- POSTROUTING 链：在数据包离开防火墙时改变数据包的源地址。

mangle 表主要是修改数据包，包含：

- PREROUTING 链；
- INPUT 链；
- FORWARD 链；
- OUTPUT 链；
- POSTROUTING 链。

![img](typora-user-images/1a0ba797b9a0f0e32c9e561b97955917.jpg)

1. 数据包进入的时候，先进 mangle 表的 PREROUTING 链。在这里可以根据需要，改变数据包头内容之后，进入 nat 表的 PREROUTING 链，在这里可以根据需要做 Dnat，也就是目标地址转换。
2. 进入路由判断，要判断是进入本地的还是转发的。
3. 如果是进入本地的，就进入 INPUT 链，之后按条件过滤限制进入。
4. 之后进入本机，再进入 OUTPUT 链，按条件过滤限制出去，离开本地。
5. 如果是转发就进入 FORWARD 链，根据条件过滤限制转发。
6. 之后进入 POSTROUTING 链，这里可以做 Snat，离开网络接口。

有了 iptables 命令，我们就可以在云中实现一定的安全策略。例如我们可以处理前面的偷窥事件。首先我们将所有的门都关闭。

```shell
iptables -t filter -A INPUT -s 0.0.0.0/0.0.0.0 -d X.X.X.X -j DROP
```

-s 表示源 IP 地址段，-d 表示目标地址段，DROP 表示丢弃，也即无论从哪里来的，要想访问我这台机器，全部拒绝，谁也黑不进来。

但是你发现坏了，ssh 也进不来了，都不能远程运维了，可以打开一下。

```shell
iptables -I INPUT -s 0.0.0.0/0.0.0.0 -d X.X.X.X -p tcp --dport 22 -j ACCEPT
```

在云平台上，一般允许一个或者多个虚拟机属于某个安全组，而属于不同安全组的虚拟机之间的访问以及外网访问虚拟机，都需要通过安全组进行过滤

![img](typora-user-images/93aa707cb55c47023ae958d6cadde8a3.jpg)

这些安全组规则都可以自动下发到每个在安全组里面的虚拟机上，从而控制一大批虚拟机的安全策略。这种批量下发是怎么做到的呢？你还记得这幅图吗？

![img](typora-user-images/246db57c915d9ccf6e0d66182de0fe24.jpg)

两个 VM 都通过 tap 网卡连接到一个网桥上，但是网桥是二层的，两个 VM 之间是可以随意互通的，因而需要有一个地方统一配置这些 iptables 规则。

可以多加一个网桥，在这个网桥上配置 iptables 规则，将在用户在界面上配置的规则，放到这个网桥上。然后在每台机器上跑一个 Agent，将用户配置的安全组变成 iptables 规则，配置在这个网桥上。

虚拟机毕竟还是要通过物理网和外界通信的，因而需要在出物理网的时候，做一次网络地址转换，也即 nat，这个就可以用 iptables 来做。

IP 头里面包含源 IP 地址和目标 IP 地址，这两种 IP 地址都可以转换成其他地址。转换源 IP 地址的，我们称为 Snat；转换目标 IP 地址的，我们称为 Dnat。

所以当你从你家里访问 163 网站的时候，在你路由器的出口，会做 Snat 的，运营商的出口也可能做 Snat，将你的私网 IP 地址，最终转换为公网 IP 地址，然后 163 网站就可以通过这个公网 IP 地址返回结果，然后再 nat 回来，直到到达你的笔记本电脑。

云平台里面的虚拟机也是这样子的，它只有私网 IP 地址，到达外网网口要做一次 Snat，转换成为机房网 IP，然后出数据中心的时候，再转换为公网 IP。

![img](typora-user-images/1a5d299c2eb5480eda93a8f8e3b3ca1a.jpg)

在外网网口上做 Snat 的时候，是全部转换成一个机房网 IP 呢，还是每个虚拟机都对应一个机房网 IP，最终对应一个公网 IP 呢？前面也说过了，公网 IP 非常贵，虚拟机也很多，当然不能每个都有单独的机房网和公网 IP 了，因此这种 Snat 是一种特殊的 Snat，MASQUERADE（地址伪装）。

这种方式下，所有的虚拟机共享一个机房网和公网的 IP 地址，所有从外网网口出去的，都转换成为这个 IP 地址。那又一个问题来了，都变成一个公网 IP 了，当 163 网站返回结果的时候，给谁呢，再 nat 成为哪个私网的 IP 呢？

这就是 Netfilter 的连接跟踪（conntrack）功能了。对于 TCP 协议来讲，肯定是上来先建立一个连接，可以用“源 / 目的 IP+ 源 / 目的端口”唯一标识一条连接，这个连接会放在 conntrack 表里面。当时是这台机器去请求 163 网站的，虽然源地址已经 Snat 成公网 IP 地址了，但是 conntrack 表里面还是有这个连接的记录的。当 163 网站返回数据的时候，会找到记录，从而找到正确的私网 IP 地址。

这是虚拟机做客户端的情况，如果虚拟机做服务器呢？也就是说，如果虚拟机里面部署的就是 163 网站呢？

这个时候就需要给这个网站配置固定的物理网的 IP 地址和公网 IP 地址了。这时候就需要详细配置 Snat 规则和 Dnat 规则了。

当外部访问进来的时候，外网网口会通过 Dnat 规则将公网 IP 地址转换为私网 IP 地址，到达虚拟机，虚拟机里面是 163 网站，返回结果，外网网口会通过 Snat 规则，将私网 IP 地址转换为那个分配给它的固定的公网 IP 地址。





类似的规则如下：

- 源地址转换 (Snat)：iptables -t nat -A -s 私网 IP -j Snat --to-source 外网 IP
- 目的地址转换 (Dnat)：iptables -t nat -A -PREROUTING -d 外网 IP -j Dnat --to-destination 私网 IP





k8s的kube-proxy 就是利用的iptables 做流量转发和负载均衡的，service 利用nat 将相应的流量转发到对应的pod中，另外iptables 有一个probability特性，可以设置probability的百分比是多少，从而实现负载均衡



对表和链比较迷糊的同学，结合这个博客的内容看起来可能更容易理解，http://www.zsythink.net/archives/1199

 ![img](typora-user-images/021217_0051_6.png) 

 ![img](typora-user-images/021217_0051_7.png) 

### 4、云中网络流量控制

- 云中的流量控制主要通过队列进行的，队列分为两大类：无类别队列规则和基于类别的队列规则。
- 在云中网络 Openvswitch 中，主要使用的是分层令牌桶规则（HTB），将总的带宽在一棵树上按照配置的比例进行分配，并且在一个分支不用的时候，可以借给另外的分支，从而增强带宽利用率。



流量控制技术，QoS（Quality of Service）

对于控制一台机器的网络的QoS，分两个方向，一个是入方向、一个是出方向

![img](typora-user-images/e7eda457d064071bcfa92219e6aefaa6.jpg)

其实能控制的只有出方向，通过 Shaping，将出的流量控制成自己想要的模样。而进入的方向是无法控制的，只能通过 Policy 将包丢弃。



### 5、Overlay网络

Overlay网络，基于物理网络的虚拟化网络实现。

#### （1）GRE

GRE，全称是Generic Routing Encapsulation，是一种IP-over-IP的隧道技术，将IP包封装在GRE包，外面加上IP头，在隧道的一段封装数据包，并在通路上进行传输，到另外一段的时候解封装。

可认为Tunnel是一个虚拟的、点对点的连接。

![img](typora-user-images/b189df0a6ee4b0462818bf2f154c9531.jpg)

在GRE中，前32位是一定有的，后买你都是可选项。

前4位的标识位里，有标识后面到底有没有可选项。

key字段是一个32位的字段，存放的往往就是用于区分用户的Tunnel ID。

格式类型专门用于网络虚拟化的GRE包头格式，称为**NVGRE**

使用GRE隧道，传输过程如下，

![](typora-user-images/76298ce51d349bc9805fbf317312e4ce.jpg)

有两个网段、两个路由器、中间要通过GRE隧道进行通信，当隧道建立之后，会多出两个Tunnel端口，用于封包、解封包。

1. 主机A在左边的网络，IP地址位192.168.1.102，想要访问主机B，主机B在右边的网络，IP地址位192.168.2.115.于是发送一个包，源地址位192.168.1.102，目标地址是192.168.2.115，因为要跨网段访问，于是根据默认的default路由表规则，要发给默认的网关192.168.1.1
2. 根据路由表，从左边的路由器，区192.168.2.0/24这个网段，应该走一条GRE的隧道，从隧道一段的网卡Tunnel0进入隧道。
3. 在Tunnel隧道的端点进行包的封装，在内部的IP头之外加上GRE头，对于NVGRE来说，是在MAC头之外加上GRE头，然后加上外部的IP地址，也即是路由器的外网IP地址。源IP地址位172.17.10.10，目标IP地址位172.16.11.10，然后从E1的物理网卡发送到公共网络里。
4. 在公共网络里面，沿着路由器一跳一跳的走，全部都按照外部的公网IP地址进行。
5. 当网络包到达对端路由器的时候，也要到达对端的Tunnel0，然后开始解封装，将外层的IP头取下来，然后根据里面的网络包，根据路由表，从E3口转发出去到达服务器B。



问题：

- Tunnel的数量问题，GRE是一种点对点隧道，需要在每两个网络之间建立一条隧道，如果网络数目增多，这样隧道的数目会很大。

  

  ![img](typora-user-images/006cc8a4bf7a13fea0f456905c263afe.jpg)

- GRE不支持组播，因此一个网络中的一个虚拟机发出一个广播帧后，GRE会将器广播到所有与该节点有隧道连接的节点。



#### （2）VXLAN

第二种 Overlay 的技术称为 VXLAN。和三层外面再套三层的 GRE 不同，VXLAN 则是从二层外面就套了一个 VXLAN 的头，这里面包含的 VXLAN ID 为 24 位，也够用了。在 VXLAN 头外面还封装了 UDP、IP，以及外层的 MAC 头。

![img](typora-user-images/3b02d54c9093e3de6d1a847dd0eb060f.jpg)

VXLAN 作为扩展性协议，也需要一个地方对 VXLAN 的包进行封装和解封装，实现这个功能的点称为 VTEP（VXLAN Tunnel Endpoint）。

VTEP 相当于虚拟机网络的管家。每台物理机上都可以有一个 VTEP。每个虚拟机启动的时候，都需要向这个 VTEP 管家注册，每个 VTEP 都知道自己上面注册了多少个虚拟机。当虚拟机要跨 VTEP 进行通信的时候，需要通过 VTEP 代理进行，由 VTEP 进行包的封装和解封装。

和 GRE 端到端的隧道不同，VXLAN 不是点对点的，而是支持通过组播的来定位目标机器的，而非一定是这一端发出，另一端接收。

当一个 VTEP 启动的时候，它们都需要通过 IGMP 协议。加入一个组播组，就像加入一个邮件列表，或者加入一个微信群一样，所有发到这个邮件列表里面的邮件，或者发送到微信群里面的消息，大家都能收到。而当每个物理机上的虚拟机启动之后，VTEP 就知道，有一个新的 VM 上线了，它归我管。

![img](typora-user-images/e4541dfd1571aab11694343520970a77.jpg)

如图，虚拟机 1、2、3 属于云中同一个用户的虚拟机，因而需要分配相同的 VXLAN ID=101。在云的界面上，就可以知道它们的 IP 地址，于是可以在虚拟机 1 上 ping 虚拟机 2。

虚拟机 1 发现，它不知道虚拟机 2 的 MAC 地址，因而包没办法发出去，于是要发送 ARP 广播。

![img](typora-user-images/27b0f23c0e94c10bac63d2ec6401e079.jpg)

ARP 请求到达 VTEP1 的时候，VTEP1 知道，此时VTEP1不知道虚拟机2的MAC地址，所以将ARP请求封装在VXLAN里面，然后进行组播。

此时VTEP2和VTEP3都收到了消息，因而都会解开VXLAN包看，里面是一个ARP。

VTEP3在本地进行广播，但虚拟机2不归他管

VTEP2 在本地广播，虚拟机 2 回了，说虚拟机 2 归我管，MAC 地址是这个。通过这次通信，VTEP2 也学到了，虚拟机 1 归 VTEP1 管，以后要找虚拟机 1，去找 VTEP1 就可以了。

![img](typora-user-images/377070660f2474b90489b0f10f8f686c.jpg)

VTEP2 将 ARP 的回复封装在 VXLAN 里面，这次不用组播了，直接发回给 VTEP1。

VTEP1 解开 VXLAN 的包，发现是 ARP 的回复，于是发给虚拟机 1。通过这次通信，VTEP1 也学到了，虚拟机 2 归 VTEP2 管，以后找虚拟机 2，去找 VTEP2 就可以了。

虚拟机 1 的 ARP 得到了回复，知道了虚拟机 2 的 MAC 地址，于是就可以发送包了。

![img](typora-user-images/5ba8f197a682de2539594ef5d7e7d56e.jpg)

虚拟机 1 发给虚拟机 2 的包到达 VTEP1，它当然记得刚才学的东西，要找虚拟机 2，就去 VTEP2，于是将包封装在 VXLAN 里面，外层加上 VTEP1 和 VTEP2 的 IP 地址，发送出去。

网络包到达 VTEP2 之后，VTEP2 解开 VXLAN 封装，将包转发给虚拟机 2。

虚拟机 2 回复的包，到达 VTEP2 的时候，它当然也记得刚才学的东西，要找虚拟机 1，就去 VTEP1，于是将包封装在 VXLAN 里面，外层加上 VTEP1 和 VTEP2 的 IP 地址，也发送出去。

网络包到达 VTEP1 之后，VTEP1 解开 VXLAN 封装，将包转发给虚拟机 1。

![img](typora-user-images/b4d39cfc833be380be67eeee8019d319.jpg)





#### （3）如何将GRE和VXLAN运用至云平台

![img](typora-user-images/8fc4b26b9e42c37adb87db81e36cc64c.jpg)

虚拟机是你的电脑，路由器和 DHCP Server 相当于家用路由器或者寝室长的电脑，外网网口访问互联网，所有的电脑都通过内网网口连接到一个交换机 br0 上，虚拟机要想访问互联网，需要通过 br0 连到路由器上，然后通过路由器将请求 NAT 后转发到公网。



如果三台电脑都在不同的房间，这个时候就可以用GRE或者VXLAN

![img](typora-user-images/184a02e0ee2404b46409cbf3d34837cb.jpg)

用网线通过隧道将三个宿舍的两个 br0 连接起来，让其他室友的电脑和你寝室长的电脑，看起来还是连到同一个 br0 上，其实中间是通过你隧道中的网线做了转发。

为什么要多一个 br1 这个虚拟交换机呢？主要通过 br1 这一层将虚拟机之间的互联和物理机机之间的互联分成两层来设计，中间隧道可以有各种挖法，GRE、VXLAN 都可以。



使用了 OpenvSwitch 之后，br0 可以使用 OpenvSwitch 的 Tunnel 功能和 Flow 功能

OpenvSwitch 支持三类隧道：GRE、VXLAN、IPsec_GRE。在使用 OpenvSwitch 的时候，虚拟交换机就相当于 GRE 和 VXLAN 封装的端点。

![img](typora-user-images/fca6857aaca4f3549b02445ffce71f49.jpg)

三台物理机，每台上都有两台虚拟机，分别属于两个不同的用户，因而 VLAN tag 都得打地不一样，这样才不能相互通信。但是不同物理机上的相同用户，是可以通过隧道相互通信的，因而通过 GRE 隧道可以连接到一起。

接下来，所有的 Flow Table 规则都设置在 br1 上，每个 br1 都有三个网卡，其中网卡 1 是对内的，网卡 2 和 3 是对外的。

具体来看 Flow Table 的设计。

![img](typora-user-images/8888426b42555043c3e05ec26fe47f69.png)

1.Table 0 是所有流量的入口，所有进入 br1 的流量，分为两种流量，一个是进入物理机的流量，一个是从物理机发出的流量。

从 port 1 进来的，都是发出去的流量，全部由 Table 1 处理。

从 port 2、3 进来的，都是进入物理机的流量，全部由 Table 3 处理。

如果都没匹配上，就默认丢弃。

2.Table 1 用于处理所有出去的网络包，分为两种情况，一种是单播，一种是多播。

对于单播，由 Table 20 处理。

对于多播，由 Table 21 处理。

3.Table 2 是紧接着 Table1 的，如果既不是单播，也不是多播，就默认丢弃。

4.Table 3 用于处理所有进来的网络包，需要将隧道 Tunnel ID 转换为 VLAN ID。

如果匹配不上 Tunnel ID，就默认丢弃。

如果匹配上了 Tunnel ID，就转换为相应的 VLAN ID，然后跳到 Table 10。

5. 对于进来的包，Table 10 会进行 MAC 地址学习。这是一个二层交换机应该做的事情，学习完了之后，再从 port 1 发出去。

Table 10 是用来学习 MAC 地址的，学习的结果放在 Table 20 里面。Table20 被称为 MAC learning table。

NXM_OF_VLAN_TCI 是 VLAN tag。在 MAC learning table 中，每一个 entry 都仅仅是针对某一个 VLAN 来说的，不同 VLAN 的 learning table 是分开的。在学习结果的 entry 中，会标出这个 entry 是针对哪个 VLAN 的。NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[]表示，当前包里面的 MAC Source Address 会被放在学习结果的 entry 里的 dl_dst 里。这是因为每个交换机都是通过进入的网络包来学习的。某个 MAC 从某个 port 进来，交换机就应该记住，以后发往这个 MAC 的包都要从这个 port 出去，因而源 MAC 地址就被放在了目标 MAC 地址里面，因为这是为了发送才这么做的。load:0->NXM_OF_VLAN_TCI[]是说，在 Table20 中，将包从物理机发送出去的时候，VLAN tag 设为 0，所以学习完了之后，Table 20 中会有 actions=strip_vlan。load:NXM_NX_TUN_ID[]->NXM_NX_TUN_ID[]的意思是，在 Table 20 中，将包从物理机发出去的时候，设置 Tunnel ID，进来的时候是多少，发送的时候就是多少，所以学习完了之后，Table 20 中会有 set_tunnel。output:NXM_OF_IN_PORT[]是发送给哪个 port。例如是从 port 2 进来的，那学习完了之后，Table 20 中会有 output:2。

![img](typora-user-images/4dc0fe34819ee02a53a97c89811747dd.jpg)

如图所示，通过左边的 MAC 地址学习规则，学习到的结果就像右边的一样，这个结果会被放在 Table 20 里面。

6.Table 20 是 MAC Address Learning Table。如果不为空，就按照规则处理；如果为空，就说明没有进行过 MAC 地址学习，只好进行广播了，因而要交给 Table 21 处理。

7.Table 21 用于处理多播的包。

如果匹配不上 VLAN ID，就默认丢弃。

如果匹配上了 VLAN ID，就将 VLAN ID 转换为 Tunnel ID，从两个网卡 port 2 和 port 3 都发出去，进行多播。





#### （4）总结

- 要对不同用户的网络进行隔离，解决 VLAN 数目有限的问题，需要通过 Overlay 的方式，常用的有 GRE 和 VXLAN。
- GRE 是一种点对点的隧道模式，VXLAN 支持组播的隧道模式，它们都要在某个 Tunnel Endpoint 进行封装和解封装，来实现跨物理机的互通。
- OpenvSwitch 可以作为 Tunnel Endpoint，通过设置流表的规则，将虚拟机网络和物理机网络进行隔离、转换。



## 七、容器网络



### 1、容器网络

容器就是 Container，而 Container 的另一个意思是集装箱。其实容器的思想就是要变成软件交付的集装箱。集装箱的特点，一是打包，二是标准。

![img](typora-user-images/a50157f1084c946b9e27f3b328b8d2dc.jpg)

封闭的环境主要使用了两种技术，一种是看起来是隔离的技术，称为**namespace**，也即每个namespace中的而英勇刚看到的是不同给的IP地址、用户空间、进程号等。另一种是用起来是隔离的技术，称为**cgroup**，也即是整台机器有很多的CPU、内存，而一个应用只能用其中的一部分。



#### （1）命名空间（namespace）

网络的 namespace 由 ip netns 命令操作。它可以创建、删除、查询 namespace。

创建一个routerns，一个独立的网络空间

```
ip netns add routerns
```

既然是路由器，需要转发功能，所以forward开关要打开

```
ip netns exec routerns sysctl -w net.ipv4.ip_forward=1
```

然后初始化iptables，配置NAT规则

```
ip netns exec routerns iptables-save -c
ip netns exec routerns iptables-restore -c
```

路由器需要一张网卡连到br0上，创建一个网卡

```shell
ovs-vsctl -- add-port br0 taprouter --set Interface taprouter type=internal -- set iInterface taprouter external-ids:iface-status=active -- set Interface taprouter external-ids:attached-mac=fa:16:3e:84:6e:cc
```

网络创建完，但是是在namespace外面，如何进去

```
ip link set taprouter netns routerns
```

要给这个网卡配置一个 IP 地址，当然应该是虚拟机网络的网关地址。例如虚拟机私网网段为 192.168.1.0/24，网关的地址往往为 192.168.1.1

```
ip netns exec routerns ip -4 addr add 192.168.1.1/24 brd 192.168.1.255 scope global dev taprouter
```

为了访问外网，还需要另一个网卡连在外网网桥 br-ex 上，并且塞在 namespace 里面。

```shell
ovs-vsctl -- add-port br-ex taprouterex -- set Interface taprouterex type=internal -- set Interface taprouterex external-ids:iface-status=active -- set Interface taprouterex external-ids:attached-mac=fa:16:3e:68:12:c0
```

```
ip link set taprouterex netns routerns
```

还需要为这个网卡分配一个地址，这个地址应该和物理外网网络在一个网段。假设物理外网为 16.158.1.0/24，可以分配一个外网地址 16.158.1.100/24。

```
ip netns exec routerns ip -4 addr add 16.158.1.100/24 brd 16.158.1.255 scope global dev taprouterex
```

既然是路由器，就需要配置路由表，路由表是这样的：

```

ip netns exec routerns route -n
Kernel IP routing table
Destination   Gateway     Genmask     Flags Metric Ref  Use Iface
0.0.0.0     16.158.1.1  0.0.0.0     UG  0   0    0 taprouterex
192.168.1.0    0.0.0.0     255.255.255.0  U   0   0    0 taprouter
16.158.1.0  0.0.0.0     255.255.255.0  U   0   0    0 taprouterex
```

路由表中的默认路由是去物理外网的，去 192.168.1.0/24 也即虚拟机私网，走下面的网卡，去 16.158.1.0/24 也即物理外网，走上面的网卡。

如果要在虚拟机里面提供服务，提供给外网的客户端访问，客户端需要访问外网 IP3，会在外网网口 NAT 称为虚拟机私网 IP。这个 NAT 规则要在这个 namespace 里面配置。

```

ip netns exec routerns iptables -t nat -nvL
Chain PREROUTING
target  prot opt  in  out  source  destination
DNAT  all  --  *  *  0.0.0.0/0 16.158.1.103 to:192.168.1.3
Chain POSTROUTING
target  prot opt  in  out  source   destination
SNAT  all  --  *  *  192.168.1.3  0.0.0.0/0 to:16.158.1.103
```

这里面有两个规则，一个是 SNAT，将虚拟机的私网 IP 192.168.1.3 NAT 成物理外网 IP 16.158.1.103。一个是 DNAT，将物理外网 IP 16.158.1.103 NAT 成虚拟机私网 IP 192.168.1.3。

至此为止，基于网络 namespace 的路由器实现完毕。



#### （2）机制网络（cgroup）

cgroup 全称 control groups，是 Linux 内核提供的一种可以限制、隔离进程使用的资源机制。

cgroup 能控制哪些资源呢？它有很多子系统：

- CPU 子系统使用调度程序为进程控制 CPU 的访问；
- cpuset，如果是多核心的 CPU，这个子系统会为进程分配单独的 CPU 和内存；
- memory 子系统，设置进程的内存限制以及产生内存资源报告；
- blkio 子系统，设置限制每个块设备的输入输出控制；
- net_cls，这个子系统使用等级识别符（classid）标记网络数据包，可允许 Linux 流量控制程序（tc）识别从具体 cgroup 中生成的数据包。

cgroup 提供了一个虚拟文件系统，作为进行分组管理和各子系统设置的用户接口。要使用 cgroup，必须挂载 cgroup 文件系统，一般情况下都是挂载到 /sys/fs/cgroup 目录下

首先我们要挂载一个 net_cls 的文件系统。

```

mkdir /sys/fs/cgroup/net_cls
mount -t cgroup -onet_cls net_cls /sys/fs/cgroup/net_cls
```

接下来要配置 TC 了。

![img](typora-user-images/9a1b8a7c0c5403a2b4b3c277545991b5.jpg)

通过这个命令设定了规则：从 1.2.3.4 来的，发送给 port 80 的包，从 1:10 走；其他从 1.2.3.4 发送来的包从 1:11 走；其他的走默认。

```shell
tc filter add dev eth0 protocol ip parent 1:0 prio 1 u32 match ip src 1.2.3.4 match ip dport 80 0xffff flowid 1:10
tc filter add dev eth0 protocol ip parent 1:0 prio 1 u32 match ip src 1.2.3.4 flowid 1:11
```

这里是根据源 IP 来设定的，现在有了 cgroup，我们按照 cgroup 再来设定规则。

```shell

tc filter add dev eth0 protocol ip parent 1:0 prio 1 handle 1: cgroup
```

假设我们有两个用户 a 和 b，要对它们进行带宽限制。

首先，我们要创建两个 net_cls。

```

mkdir /sys/fs/cgroup/net_cls/a   
mkdir /sys/fs/cgroup/net_cls/b
```

假设用户 a 启动的进程 ID 为 12345，把它放在 net_cls/a/tasks 文件中。同样假设用户 b 启动的进程 ID 为 12346，把它放在 net_cls/b/tasks 文件中。

net_cls/a 目录下面，还有一个文件 net_cls.classid，我们放 flowid 1:10。net_cls/b 目录下面，也创建一个文件 net_cls.classid，我们放 flowid 1:11。

这个数字怎么放呢？要转换成一个 0xAAAABBBB 的值，AAAA 对应 class 中冒号前面的数字，而 BBBB 对应后面的数字。

```

echo 0x00010010 > /sys/fs/cgroup/net_cls/a/net_cls.classid    
echo 0x00010011 > /sys/fs/cgroup/net_cls/b/net_cls.classid
```

这样用户 a 的进程发的包，会打上 1:10 这个标签；用户 b 的进程发的包，会打上 1:11 这个标签。然后 TC 根据这两个标签，让用户 a 的进程的包走左边的分支，用户 b 的进程的包走右边的分支。



#### （3）容器网络中如何融入物理网络？

![img](typora-user-images/20e87bc215b9d049a4a504d775d26dd2.jpg)

容器里面有张网卡，容器外有张网卡，容器外的网卡连到 docker0 网桥，通过这个网桥，容器直接实现相互访问。

在 Linux 下，可以创建一对 veth pair 的网卡，从一边发送包，另一边就能收到。

首先通过这个命令创建这么一对。

```
ip link add name veth1 mtu 1500 type veth peer name veth2 mtu 1500
```

其中一边可以打到 docker0 网桥上。

```

ip link set veth1 master testbr    
ip link set veth1 up
```

那另一端如何放到容器里呢？

一个容器的启动会对应一个 namespace，我们要先找到这个 namespace。对于 docker 来讲，pid 就是 namespace 的名字，可以通过这个命令获取。

```

docker inspect '--format={{ .State.Pid }}' test
```

假设结果为 12065，这个就是 namespace 名字。

默认 Docker 创建的网络 namespace 不在默认路径下 ，ip netns 看不到，所以需要 ln 软链接一下。链接完毕以后，我们就可以通过 ip netns 命令操作了。

```

rm -f /var/run/netns/12065    
ln -s /proc/12065/ns/net /var/run/netns/12065
```

然后，我们就可以将另一端 veth2 塞到 namespace 里面。

```

ip link set veth2 netns 12065
```

然后，将容器内的网卡重命名。

```

ip netns exec 12065 ip link set veth2 name eth0
```

然后，给容器内网卡设置 ip 地址。

```

ip netns exec 12065 ip addr add 172.17.0.2/16 dev eth0    
ip netns exec 12065 ip link set eth0 up
```

一台机器内部容器的互相访问没有问题了，那如何访问外网呢？

就是虚拟机里面的桥接模式和 NAT 模式。Docker 默认使用 NAT 模式。NAT 模式分为 SNAT 和 DNAT，如果是容器内部访问外部，就需要通过 SNAT。

![img](typora-user-images/5452971c96e8fea33c3f873860e25c93.jpg)

在宿主机上，有这么一条 iptables 规则：

```

-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
```

所有从容器内部发出来的包，都要做地址伪装，将源 IP 地址，转换为物理网卡的 IP 地址。如果有多个容器，所有的容器共享一个外网的 IP 地址，但是在 conntrack 表中，记录下这个出去的连接。

当服务器返回结果的时候，到达物理机，会根据 conntrack 表中的规则，取出原来的私网 IP，通过 DNAT 将地址转换为私网 IP 地址，通过网桥 docker0 实现对内的访问。

例如容器内部监听 80 端口，可以通 Docker run 命令中的参数 -p 10080:80，将物理机上的 10080 端口和容器的 80 端口映射起来， 当外部的客户端访问这个网站的时候，通过访问物理机的 10080 端口，就能访问到容器内的 80 端口了。

![img](typora-user-images/49bb6b2a30fe76b124182980da935ebb.jpg)

Docker 有两种方式，一种是通过一个进程 docker-proxy 的方式，监听 10080，转换为 80 端口。

```

/usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 10080 -container-ip 172.17.0.2 -container-port 80
```

另外一种方式是通过 DNAT 方式，在 -A PREROUTING 阶段加一个规则，将到端口 10080 的 DNAT 称为容器的私有网络。

```

-A DOCKER -p tcp -m tcp --dport 10080 -j DNAT --to-destination 172.17.0.2:80
```

如此就可以实现容器和物理网络之间的互通了。



#### （4）总结

容器是一种比虚拟机更加轻量级的隔离方式，主要通过 namespace 和 cgroup 技术进行资源的隔离，namespace 用于负责看起来隔离，cgroup 用于负责用起来隔离

容器网络连接到物理网络的方式和虚拟机很像，通过桥接的方式实现一台物理机上的容器进行相互访问，如果要访问外网，最简单的方式还是通过 NAT。







### 2、Flannel

**A容器如何实时获取B容器的IP等信息？**

容器相关信息往往是通过一个称为注册中心的地方统一管理的，当容器启动的时候，会将自己所在环境的IP地址和端口，注册到注册中心。

当容器挂了或者更换IP等信息的时候，会重新进行注册。

![img](../../../../笔记/git_node/typora-user-images/a0763d50fc4e8dcec37ae25a2f6cc60d.jpeg)



**A、B容器之间如何互相通信？**

在NAT模式多个主机的场景下，是会存在问题的，比如A机器上的A容器的IP地址和B机器上的B容器的IP地址是一样的，当都注册到注册中心的时候，就是下图

![img](../../../../笔记/git_node/typora-user-images/e20596506dd34122e302a7cfc8bb85dd.jpg)



解决方案：

不注册容器内的IP地址，注册所在物理机的IP地址，端口也是物理机上映射的端口。

![img](../../../../笔记/git_node/typora-user-images/8fabf1de2a7d346856a032dbf2417b18.jpg)

但物理机的端口数量是有限的。



#### （1）Flannel使用UDP实现Overlay网络

![img](../../../../笔记/git_node/typora-user-images/07217a9ee64e1970ac04de9080505871.jpeg)

在物理机A上的容器A里面，能看到的容器的IP地址是172.17.8.2/24，里面设置了默认的路由规则default via 172.17.8.1 的v eth0

如果容器A要访问172.17.9.2，就会发往这个默认的网关172.17.8.1，也就是物理机上面docker0网桥的IP地址，这台物理机上的所有容器都是连接到这个网桥的。

在物理机上面，查看路由策略，会有这样一条 172.17.0.0/24 via 172.17.0.0 dev flannel.1，也就是说发往 172.17.9.2 的网络包会被转发到 flannel.1 这个网卡。

**这个网卡是怎么出来的呢？**

在每台物理机上，都会跑一个 flanneld 进程，这个进程打开一个 /dev/net/tun 字符设备的时候，就出现了这个网卡。

物理机 A 上的 flanneld 会将网络包封装在 UDP 包里面，然后外层加上物理机 A 和物理机 B 的 IP 地址，发送给物理机 B 上的 flanneld。

**为什么是 UDP 呢？**

因为不想在 flanneld 之间建立两两连接，而 UDP 没有连接的概念，任何一台机器都能发给另一台。

物理机 B 上的 flanneld 收到包之后，解开 UDP 的包，将里面的网络包拿出来，从物理机 B 的 flannel.1 网卡发出去。

在物理机 B 上，有路由规则 172.17.9.0/24 dev docker0 proto kernel scope link src 172.17.9.1。

将包发给 docker0，docker0 将包转给容器 B。通信成功。

上面的过程连通性没有问题，但是由于全部在用户态，所以性能差了一些。

跨物理机的连通性问题，在虚拟机那里有成熟的方案，就是 VXLAN，

Flannel也是可以使用VXLAN的，此时不需要打开一个TUN设备，而是要建立一个VXLAN的VTEP。

可通过netlink通知内核建立一个VTEP的网卡flannel.1，netlink是一种用户态和内核态通信的机制。

当网络包从物理机 A 上的容器 A 发送给物理机 B 上的容器 B，在容器 A 里面通过默认路由到达物理机 A 上的 docker0 网卡，然后根据路由规则，在物理机 A 上，将包转发给 flannel.1。这个时候 flannel.1 就是一个 VXLAN 的 VTEP 了，它将网络包进行封装。

内部的 MAC 地址这样写：源为物理机 A 的 flannel.1 的 MAC 地址，目标为物理机 B 的 flannel.1 的 MAC 地址，在外面加上 VXLAN 的头。

外层的 IP 地址这样写：源为物理机 A 的 IP 地址，目标为物理机 B 的 IP 地址，外面加上物理机的 MAC 地址。

这样就能通过 VXLAN 将包转发到另一台机器，从物理机 B 的 flannel.1 上解包，变成内部的网络包，通过物理机 B 上的路由转发到 docker0，然后转发到容器 B 里面。通信成功。

![img](../../../../笔记/git_node/typora-user-images/01f86f6049eef051d48e2e235fa43d79.jpeg)





**总结：**

- 基于 NAT 的容器网络模型在微服务架构下有两个问题，一个是 IP 重叠，一个是端口冲突，需要通过 Overlay 网络的机制保持跨节点的连通性。
- Flannel 是跨节点容器网络方案之一，它提供的 Overlay 方案主要有两种方式，一种是 UDP 在用户态封装，一种是 VXLAN 在内核态封装，而 VXLAN 的性能更好一些。





### 3、Calico

#### （1）设计思路

![img](../../../../笔记/git_node/typora-user-images/1957b75dd689127c4621b5460c356137.jpg)

图中两台物理机的物理网卡是在同一个二层网络里面的，由于两台物理机的容器网段不同，完全可以将两台物理机配置成为路由器，并按照容器的网段配置路由表。

例如，在物理机 A 中，我们可以这样配置：要想访问网段 172.17.9.0/24，下一跳是 192.168.100.101，也即到物理机 B 上去。

这样在容器 A 中访问容器 B，当包到达物理机 A 的时候，就能够匹配到这条路由规则，并将包发给下一跳的路由器，也即发给物理机 B。在物理机 B 上也有路由规则，要访问 172.17.9.0/24，从 docker0 的网卡进去即可。

当容器 B 返回结果的时候，在物理机 B 上，可以做类似的配置：要想访问网段 172.17.8.0/24，下一跳是 192.168.100.100，也即到物理机 A 上去。

当包到达物理机 B 的时候，能够匹配到这条路由规则，将包发给下一跳的路由器，也即发给物理机 A。在物理机 A 上也有路由规则，要访问 172.17.8.0/24，从 docker0 的网卡进去即可。

**这就是Calico网络的大概思路，即不走Overlay网络，不引入另外的网络性能损耗，而是将转发全部用三层网络的路由转发来实现。**

首先，如果全部走三层的路由规则，没必要每台机器都用一个 docker0，从而浪费了一个 IP 地址，而是可以直接用路由转发到 veth pair 在物理机这一端的网卡。同样，在容器内，路由规则也可以这样设定：把容器外面的 veth pair 网卡算作默认网关，下一跳就是外面的物理机。

所以，整个拓扑结构就如下图

![img](../../../../笔记/git_node/typora-user-images/f4fab81e3f981827577aa7790b78dc58.jpg)



#### （2）Calico的架构

**路由配置组件Felix**

如果只有两台机器，每台机器只有两个容器，而且保持不变。我手动配置一下，倒也没啥问题。但是如果容器不断地创建、删除，节点不断地加入、退出，情况就会变得非常复杂

![img](../../../../笔记/git_node/typora-user-images/f29027cca71f3dfbba8c2f1a35c29331.jpg)

这还是在物理机之间，一台物理机上，每创建一个容器，也需要多配置一条指向这个容器的路由。如此复杂，肯定不能手动配置，需要每台物理机上有一个 agent，当创建和删除容器的时候，自动做这件事情。这个 agent 在 Calico 中称为 Felix。



**路由广播组件BGP Speaker**

如何将路由信息，也即将“如何到达我这个节点，访问我这个节点上的容器”这些信息，广播出去。

这其实就是路由协议啊！路由协议就是将“我能到哪里，如何能到我”的信息广播给全网传出去，从而客户端可以一跳一跳地访问目标地址的。路由协议有很多种，Calico 使用的是 BGP 协议。

在 Calico 中，每个 Node 上运行一个软件 BIRD，作为 BGP 的客户端，或者叫作 BGP Speaker，将“如何到达我这个 Node，访问我这个 Node 上的容器”的路由信息广播出去。所有 Node 上的 BGP Speaker 都互相建立连接，就形成了全互连的情况，这样每当路由有所变化的时候，所有节点就都能够收到了。



**安全策略组件**

Calico 中还实现了灵活配置网络策略 Network Policy，可以灵活配置两个容器通或者不通。这个怎么实现呢？

![img](../../../../笔记/git_node/typora-user-images/ddae28956780cc3e45fde76ae96701f2.jpg)

虚拟机中的安全组，是用 iptables 实现的。Calico 中也是用 iptables 实现的。这个图里的内容是 iptables 在内核处理网络包的过程中可以嵌入的处理点。Calico 也是在这些点上设置相应的规则。

![img](../../../../笔记/git_node/typora-user-images/8f2be6638615fc5501c460d1206bff3f.jpg)

当网络包进入物理机上的时候，进入 PREOUTING 规则，这里面有一个规则是 cali-fip-dnat，这是实现浮动 IP（Floating IP）的场景，主要将外网的 IP 地址 dnat 作为容器内的 IP 地址。在虚拟机场景下，路由器的网络 namespace 里面有一个外网网卡上，也设置过这样一个 DNAT 规则。

接下来可以根据路由判断，是到本地的，还是要转发出去的。

如果是本地的，走 INPUT 规则，里面有个规则是 cali-wl-to-host，wl 的意思是 workload，也即容器，也即这是用来判断从容器发到物理机的网络包是否符合规则的。这里面内嵌一个规则 cali-from-wl-dispatch，也是匹配从容器来的包。如果有两个容器，则会有两个容器网卡，这里面内嵌有详细的规则“cali-fw-cali 网卡 1”和“cali-fw-cali 网卡 2”，fw 就是 from workload，也就是匹配从容器 1 来的网络包和从容器 2 来的网络包。

如果是转发出去的，走 FORWARD 规则，里面有个规则 cali-FORWARD。这里面分两种情况，一种是从容器里面发出来，转发到外面的；另一种是从外面发进来，转发到容器里面的。

第一种情况匹配的规则仍然是 cali-from-wl-dispatch，也即 from workload。第二种情况匹配的规则是 cali-to-wl-dispatch，也即 to workload。如果有两个容器，则会有两个容器网卡，在这里面内嵌有详细的规则“cali-tw-cali 网卡 1”和“cali-tw-cali 网卡 2”，tw 就是 to workload，也就是匹配发往容器 1 的网络包和发送到容器 2 的网络包。

接下来是匹配 OUTPUT 规则，里面有 cali-OUTPUT。接下来是 POSTROUTING 规则，里面有一个规则是 cali-fip-snat，也即发出去的时候，将容器网络 IP 转换为浮动 IP 地址。在虚拟机场景下，路由器的网络 namespace 里面有一个外网网卡上，也设置过这样一个 SNAT 规则。

![img](../../../../笔记/git_node/typora-user-images/71f22fd9e8336c7e10c8ff7bd276af07.jpg)



**全连接复杂性与规模问题**

刚才的例子里只有六个节点，BGP 的互连已经如此复杂，如果节点数据再多，这种全互连的模式肯定不行，到时候都成蜘蛛网了。于是多出了一个组件 BGP Route Reflector，它也是用 BIRD 实现的。有了它，BGP Speaker 就不用全互连了，而是都直连它，它负责将全网的路由信息广播出去。

不能让一个 BGP Router Reflector 管理所有的路由分发，而是应该有多个 BGP Router Reflector，每个 BGP Router Reflector 管一部分。

一个机架就像一个数据中心，可以把它设置为一个 AS，而 BGP Router Reflector 有点儿像数据中心的边界路由器。在一个 AS 内部，也即服务器和 BGP Router Reflector 之间使用的是数据中心内部的路由协议 iBGP，BGP Router Reflector 之间使用的是数据中心之间的路由协议 eBGP。

![img](../../../../笔记/git_node/typora-user-images/474cb05d5536f11d75baeb6332d788a0.jpg)

一个机架上有多台机器，每台机器上面启动多个容器，每台机器上都有可以到达这些容器的路由。每台机器上都启动一个 BGP Speaker，然后将这些路由规则上报到这个 Rack 上接入交换机的 BGP Route Reflector，将这些路由通过 iBGP 协议告知到接入交换机的三层路由功能。

在接入交换机之间也建立 BGP 连接，相互告知路由，因而一个 Rack 里面的路由可以告知另一个 Rack。有多个核心或者汇聚交换机将接入交换机连接起来，如果核心和汇聚起二层互通的作用，则接入和接入之间之间交换路由即可。如果核心和汇聚交换机起三层路由的作用，则路由需要通过核心或者汇聚交换机进行告知。



**跨网段访问问题**

物理机跨网段。

例如物理机 A 要告诉物理机 B，你要访问 172.17.8.0/24，下一跳是我 192.168.100.100；同理，物理机 B 要告诉物理机 A，你要访问 172.17.9.0/24，下一跳是我 192.168.100.101。

之所以能够这样，是因为物理机 A 和物理机 B 是同一个网段的，是连接在同一个交换机上的。那如果物理机 A 和物理机 B 不是在同一个网段呢？

![img](../../../../笔记/git_node/typora-user-images/58bb1d0965c383b1eaac06946998f089.jpg)

例如，物理机 A 的网段是 192.168.100.100/24，物理机 B 的网段是 192.168.200.101/24，这样两台机器就不能通过二层交换机连接起来了，需要在中间放一台路由器，做一次路由转发，才能跨网段访问

物理机 B 上的容器要访问物理机 A 上的容器，第一跳就是物理机 B，IP 为 192.168.200.101，第二跳是中间的物理路由器右面的网口，IP 为 192.168.200.1，第三跳才是物理机 A，IP 为 192.168.100.100。

关键问题是，在系统中物理机 A 如何告诉物理机 B，怎么让它才能到我这里？物理机 A 根本不可能知道从物理机 B 出来之后的下一跳是谁，况且现在只是中间隔着一个路由器这种简单的情况，如果隔着多个路由器呢？谁能把这一串的路径告诉物理机 B 呢？

第一种方式是，让中间所有的路由器都来适配 Calico。本来它们互相告知路由，只互相告知物理机的，现在还要告知容器的网段。这在大部分情况下，是不可能的。

第二种方式，还是在物理机 A 和物理机 B 之间打一个隧道，这个隧道有两个端点，在端点上进行封装，将容器的 IP 作为乘客协议放在隧道里面，而物理主机的 IP 放在外面作为承载协议。这样不管外层的 IP 通过传统的物理网络，走多少跳到达目标物理机，从隧道两端看起来，物理机 A 的下一跳就是物理机 B，这样前面的逻辑才能成立。

这就是 Calico 的 IPIP 模式。使用了 IPIP 模式之后，在物理机 A 上，我们能看到这样的路由表：

```shell
172.17.8.2 dev veth1 scope link 
172.17.8.3 dev veth2 scope link 
172.17.9.0/24 via 192.168.200.101 dev tun0 proto bird onlink
```

这和原来模式的区别在于，下一跳不再是同一个网段的物理机 B 了，IP 为 192.168.200.101，并且不是从 eth0 跳，而是建立一个隧道的端点 tun0，从这里才是下一跳。

如果我们在容器 A1 里面的 172.17.8.2，去 ping 容器 B1 里面的 172.17.9.2，首先会到物理机 A。在物理机 A 上根据上面的规则，会转发给 tun0，并在这里对包做封装：

- 内层源 IP 为 172.17.8.2；
- 内层目标 IP 为 172.17.9.2；
- 外层源 IP 为 192.168.100.100；
- 外层目标 IP 为 192.168.200.101。

将这个包从 eth0 发出去，在物理网络上会使用外层的 IP 进行路由，最终到达物理机 B。在物理机 B 上，tun0 会解封装，将内层的源 IP 和目标 IP 拿出来，转发给相应的容器。





**总结**

- Calico 推荐使用物理机作为路由器的模式，这种模式没有虚拟化开销，性能比较高。
- Calico 的主要组件包括路由、iptables 的配置组件 Felix、路由广播组件 BGP Speaker，以及大规模场景下的 BGP Route Reflector。
- 为解决跨网段的问题，Calico 还有一种 IPIP 模式，也即通过打隧道的方式，从隧道端点来看，将本来不是邻居的两台机器，变成相邻的机器。

