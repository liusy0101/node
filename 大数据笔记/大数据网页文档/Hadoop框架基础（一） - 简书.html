<!DOCTYPE html>
<!--[if IE 6]><html class="ie lt-ie8"><![endif]-->
<!--[if IE 7]><html class="ie lt-ie8"><![endif]-->
<!--[if IE 8]><html class="ie ie8"><![endif]-->
<!--[if IE 9]><html class="ie ie9"><![endif]-->
<!--[if !IE]><!-->
<html><!--<![endif]--><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0,user-scalable=no">

  <!-- Start of Baidu Transcode -->
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta name="applicable-device" content="pc,mobile">
  <meta name="MobileOptimized" content="width">
  <meta name="HandheldFriendly" content="true">
  <meta name="mobile-agent" content="format=html5;url=http://www.jianshu.com/p/691544a9738f">
  <!-- End of Baidu Transcode -->

    <meta name="description" content="** Hadoop框架基础（一） 学习一个新的东西，传统而言呢，总喜欢漫无目的的扯来扯去，比如扯扯发展史，扯扯作者是谁，而我认为这些东西对于刚开始接触，并以开发为目的学者是没有什么帮助的，反而让人分了心，比如你玩LOL的时候，去玩某个英雄的时候，一般你是不会先看英雄的故事背景介绍的，而是读读技能介绍（技能介绍类似于开发文档），直接上线就是干，扔几个技能，发现，嘿？这英雄有点意思，用的多了，才...">

  <meta name="360-site-verification" content="604a14b53c6b871206001285921e81d8">
  <meta property="wb:webmaster" content="294ec9de89e7fadb">
  <meta property="qc:admins" content="104102651453316562112116375">
  <meta property="qc:admins" content="11635613706305617">
  <meta property="qc:admins" content="1163561616621163056375">
  <meta name="google-site-verification" content="cV4-qkUJZR6gmFeajx_UyPe47GW9vY6cnCrYtCHYNh4">
  <meta name="google-site-verification" content="HF7lfF8YEGs1qtCE-kPml8Z469e2RHhGajy6JPVy5XI">
  <meta http-equiv="mobile-agent" content="format=html5; url=http://www.jianshu.com/p/691544a9738f">

  <!-- Apple -->
  <meta name="apple-mobile-web-app-title" content="简书">

    <!--  Meta for Smart App Banner -->
  <meta name="apple-itunes-app" content="app-id=888237539, app-argument=jianshu://notes/9973710">
  <!-- End -->

  <!--  Meta for Twitter Card -->
  <meta content="summary" property="twitter:card">
  <meta content="@jianshucom" property="twitter:site">
  <meta content="Hadoop框架基础（一）" property="twitter:title">
  <meta content="** Hadoop框架基础（一） 学习一个新的东西，传统而言呢，总喜欢漫无目的的扯来扯去，比如扯扯发展史，扯扯作者是谁，而我认为这些东西对于刚开始接触，并以开发为目的学者是没有什么帮助的，反而让人分了心，比如你玩LOL的时候，去玩某个英雄的时候，一般你是不会先看英雄的故事背景介绍的，而是读读技能介绍（技能介绍类似于开发文档），直接上线就是干，扔几个技能，发现，嘿？这英雄有点意思，用的多了，才会有可能去看看英雄的背景故事。（不排除你是一个纯粹的完美情怀主义者） 好，那么下面我就给大家简单的总结一下业内的开场内容。 学习内容：Hadoop框架 框架源码：Java 框架之父：Doug Cutt..." property="twitter:description">
  <meta content="http://www.jianshu.com/p/691544a9738f" property="twitter:url">
  <!-- End -->

  <!--  Meta for OpenGraph -->
  <meta property="fb:app_id" content="865829053512461">
  <meta property="og:site_name" content="简书">
  <meta property="og:title" content="Hadoop框架基础（一）">
  <meta property="og:type" content="article">
  <meta property="og:url" content="http://www.jianshu.com/p/691544a9738f">
  <meta property="og:description" content="** Hadoop框架基础（一） 学习一个新的东西，传统而言呢，总喜欢漫无目的的扯来扯去，比如扯扯发展史，扯扯作者是谁，而我认为这些东西对于刚开始接触，并以开发为目的学者是没有什么帮助的，反而让...">
  <!-- End -->

  <!--  Meta for Facebook Applinks -->
  <meta property="al:ios:url" content="jianshu://notes/9973710">
  <meta property="al:ios:app_store_id" content="888237539">
  <meta property="al:ios:app_name" content="简书">

  <meta property="al:android:url" content="jianshu://notes/9973710">
  <meta property="al:android:package" content="com.jianshu.haruki">
  <meta property="al:android:app_name" content="简书">
  <!-- End -->


    <title>Hadoop框架基础（一） - 简书</title>

  <meta name="csrf-param" content="authenticity_token">
<meta name="csrf-token" content="JTEDuRRdBOlTpbBfcOY3xzQdL3oPMRQcNgiKipfwhFEIoyFNxDF4Y1KMX3f+qUMt8fOjKn8aFFNp/WIJXMOG5A==">

  <link rel="stylesheet" media="all" href="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/web-60bef14f05f21a4581be.css">
  
  <link rel="stylesheet" media="all" href="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/entry-60bef14f05f21a4581be.css">

  <link href="http://cdn2.jianshu.io/assets/favicons/favicon-783beb88ed621ceab614de960376ac0c.ico" rel="icon">
      <link rel="apple-touch-icon-precomposed" href="http://cdn2.jianshu.io/assets/apple-touch-icons/57-47624b2e2161e8eb144462c85db0a5ff.png" sizes="57x57">
      <link rel="apple-touch-icon-precomposed" href="http://cdn2.jianshu.io/assets/apple-touch-icons/72-c00cde7cf98fc49e50cbb3ee1dcd5804.png" sizes="72x72">
      <link rel="apple-touch-icon-precomposed" href="http://cdn2.jianshu.io/assets/apple-touch-icons/76-e8af0bdeaf1ba31e303b1fde8b5e66c4.png" sizes="76x76">
      <link rel="apple-touch-icon-precomposed" href="http://cdn2.jianshu.io/assets/apple-touch-icons/114-f4c78569bbf1977e8382a5fd90c9237a.png" sizes="114x114">
      <link rel="apple-touch-icon-precomposed" href="http://cdn2.jianshu.io/assets/apple-touch-icons/120-cf10c3711dba269522743729efe66bbc.png" sizes="120x120">
      <link rel="apple-touch-icon-precomposed" href="http://cdn2.jianshu.io/assets/apple-touch-icons/152-7bd60457b5f3ecbf1343f0e6241be4f8.png" sizes="152x152">
<link rel="stylesheet" href="blob:http://www.jianshu.com/55285595-20bc-4764-b566-5e2cff105294"><link rel="stylesheet" href="blob:http://www.jianshu.com/f2318261-5f2c-4f23-8d35-7aab13b0af27"></head>

  <body class="reader-black-font" lang="zh-CN">
    <!-- 全局顶部导航栏 -->
<nav class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="width-limit">
    <!-- 左上方 Logo -->
    <a class="logo" href="http://www.jianshu.com/"><img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/logo-58fd04f6f0de908401aa561cda6a0688.png" alt="Logo"></a>

    <!-- 右上角 -->
      <!-- 未登录显示登录/注册/写文章 -->
      <a class="btn write-btn" target="_blank" href="http://www.jianshu.com/writer#/">
        <i class="iconfont ic-write"></i>写文章
</a>      <a class="btn sign-up" href="http://www.jianshu.com/sign_up">注册</a>
      <a class="btn log-in" href="http://www.jianshu.com/sign_in">登录</a>

    <!-- 如果用户登录，显示下拉菜单 -->

    <div class="style-mode"><a class="style-mode-btn"><i class="iconfont ic-navigation-mode"></i></a> <div class="popover-modal" style="left: 0px; display: none;"><div class="meta"><i class="iconfont ic-navigation-night"></i><span>夜间模式</span></div> <div class="switch day-night-group"><a class="switch-btn">开</a> <a class="switch-btn active">关</a></div> <hr> <div class="switch font-family-group"><a class="switch-btn font-song">宋体</a> <a class="switch-btn font-hei active">黑体</a></div> <div class="switch"><a class="switch-btn active">简</a> <a class="switch-btn">繁</a></div></div></div>
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#menu" aria-expanded="false">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
      </div>
      <div class="collapse navbar-collapse" id="menu">
        <ul class="nav navbar-nav">
            <li class="">
              <a href="http://www.jianshu.com/">
                <span class="menu-text">首页</span><i class="iconfont ic-navigation-discover menu-icon"></i>
</a>            </li>
            <li class="">
              <a class="app-download-btn" href="http://www.jianshu.com/apps"><span class="menu-text">下载App</span><i class="iconfont ic-navigation-download menu-icon"></i></a>
            </li>
          <li class="search">
            <form target="_blank" action="/search" accept-charset="UTF-8" method="get"><input name="utf8" value="✓" type="hidden">
              <input name="q" id="q" placeholder="搜索" class="search-input" type="text">
              <a class="search-btn" href="javascript:void(null)"><i class="iconfont ic-search"></i></a>
              <!-- <div id="navbar-trending-search"></div> -->
</form>          </li>
        </ul>
      </div>
    </div>
  </div>
</nav>

    
<div class="note">
  <div class="post">
    <div class="article">
        <h1 class="title">Hadoop框架基础（一）</h1>

        <!-- 作者区域 -->
        <div class="author">
          <a class="avatar" href="http://www.jianshu.com/u/a39ddf86b31d">
            <img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/b5933287-2239-4028-a7e0-8d87958ac06f.jpg" alt="144">
</a>          <div class="info">
            <span class="tag">作者</span>
            <span class="name"><a href="http://www.jianshu.com/u/a39ddf86b31d">Z尽际</a></span>
            <!-- 关注用户按钮 -->
            <a class="btn btn-success follow"><i class="iconfont ic-follow"></i><span>关注</span></a>
            <!-- 文章数据信息 -->
            <div class="meta">
              <!-- 如果文章更新时间大于发布时间，那么使用 tooltip 显示更新时间 -->
                <span class="publish-time" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="最后编辑于 2017.04.30 22:02">2017.03.12 16:17*</span>
              <span class="wordage">字数 4627</span>
            <span class="views-count">阅读 204</span><span class="comments-count">评论 0</span><span class="likes-count">喜欢 7</span></div>
          </div>
          <!-- 如果是当前作者，加入编辑按钮 -->
        </div>
        <!-- -->

        <!-- 文章内容 -->
        <div data-note-content="" class="show-content">
          <h1>** Hadoop框架基础（一）<br>
</h1><p><br></p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-ef07a685a8952e7d.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-ef07a685a8952e7d.png?imageMogr2/auto-orient/strip" data-image-slug="ef07a685a8952e7d" data-width="310" data-height="107" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>学习一个新的东西，传统而言呢，总喜欢漫无目的的扯来扯去，比如扯扯发展史，扯扯作者是谁，而我认为这些东西对于刚开始接触，并以开发
为目的学者是没有什么帮助的，反而让人分了心，比如你玩LOL的时候，去玩某个英雄的时候，一般你是不会先看英雄的故事背景介绍的，而是读读技能介绍（技
能介绍类似于开发文档），直接上线就是干，扔几个技能，发现，嘿？这英雄有点意思，用的多了，才会有可能去看看英雄的背景故事。（不排除你是一个纯粹的完
美情怀主义者）</p><p>好，那么下面我就给大家简单的总结一下业内的开场内容。</p><h2>学习内容：Hadoop框架</h2><h2>框架源码：Java</h2><h2>框架之父：Doug Cutting</h2><h2>目前维护：Apache基金会</h2><h2>核心用途：HDFS和MapReduce。HDFS为海量的数据提供了存储，MapReduce为海量的数据提供了计算。</h2><p>（不够严谨的简单解释下：把大文件数据分布存储在多个电脑上（因为你一台电脑存不下），然后在多台电脑上进行数据分析（因为你一台电脑计算的慢），最终整合出结果）</p><p><br></p><p>Hadoop产生源于Google的一些论文（大陆请使用VPN代理查阅）：</p><p>GoogleCluster： http://research.google.com/archive/googlecluster.html<br></p><p>Chubby：http://labs.google.com/papers/chubby.html</p><p>GFS：http://labs.google.com/papers/gfs.html</p><p>BigTable：http://labs.google.com/papers/bigtable.html</p><p>MapReduce：http://labs.google.com/papers/mapreduce.html</p><p><br></p><p>随着发展，Apache上就出现了一个类似的解决方案，分别对应：<br></p><p>Chubby--&gt;ZooKeeper</p><p>GFS--&gt;HDFS</p><p>BigTable--&gt;Hbase</p><p>MapReduce--&gt;Hadoop</p><p>以上内容基本就是介绍框架时扯来扯去的核心，作者是非常厉害的（这不废话么）。在学习过程中，如果你慢慢对这些发展历史，作者，故事背景感兴趣了，你可以再查阅相关资料，毕竟学无止境。</p><h1>** 准备工作</h1><h3>相关下载：</h3><p>JDK：链接：http://pan.baidu.com/s/1skOjRE9 密码：2s0p</p><p>Hadoop：链接：http://pan.baidu.com/s/1mhB2Rv6 密码：6qxi</p><p>Eclipse：链接：http://pan.baidu.com/s/1nvc5izR 密码：ezy8</p><p>以上下载你也可以自行下载，通过产品所对应的官网。</p><h3>创建相关目录：</h3><p>在root用户下，进入/opt/目录，在该目录下创建两个文件夹</p><p>mkdir softwares/：该目录用于存放各种软件安装包<br></p><p>mkdir modules/：该目录用于存放软件的安装目录<br></p><h3>改变目录所属：</h3><p>因为softwares和modules这两个目录为root用户所创建，所以所有者/组均为root，而我们一般使用的操作用户是普通用户，所以此时我们需要修改该两个目录的所有者/组，使用命令：</p><p>chown 所有者:所属组 /opt/modules/</p><p>chown 所有者:所属组 /opt/softwares/</p><p>例如,我这里：</p><p>chown z:z /opt/modules/</p><h3>传递下载后的文件到虚拟机系统</h3><p>完成以上步骤后，使用FileZilla Client工具（如果忘记如何连接，请查看前几节知识），连接成功后，如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-cb10ebcf9a255a43.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-cb10ebcf9a255a43.png?imageMogr2/auto-orient/strip" data-image-slug="cb10ebcf9a255a43" data-width="1929" data-height="969" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>此时双击红框部分，如上图所示，找到opt目录，之后你就可以看到两个你创建的目录：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-cd64fb43b771460a.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-cd64fb43b771460a.png?imageMogr2/auto-orient/strip" data-image-slug="cd64fb43b771460a" data-width="470" data-height="155" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>然后，把软件上传到softwares下，直接从windows中拖入即可上传，完成后如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-02ad3741a7dfb1a1.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-02ad3741a7dfb1a1.png?imageMogr2/auto-orient/strip" data-image-slug="02ad3741a7dfb1a1" data-width="850" data-height="215" style="cursor: zoom-in;"><br><div class="image-caption">我这里上传的有其他软件，其实此时只需要框中部分的3个即可</div>
</div><p>现在把这3个部分分别解压到modules中，如图（只需留意红框内的内容）</p><p>解压命令：</p><p>tar -zxf hadoop-2.5.0.tar.gz -C /opt/modules/</p><p>tar -zxf hadoop-2.5.0.tar.gz -C /opt/modules/<br></p><p><br></p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-0f038ea63e4b0983.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-0f038ea63e4b0983.png?imageMogr2/auto-orient/strip" data-image-slug="0f038ea63e4b0983" data-width="715" data-height="40" style="cursor: zoom-in;"><br><div class="image-caption">这3个目录已经解压</div>
</div><h3>配置环境变量</h3><p>配置JDK的环境变量，hadoop的环境变量暂时不需要配了</p><p>编辑profile文件，使用命令：</p><p>vi /etc/profile，添加如图所示内容：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-cbbc550a6f79505a.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-cbbc550a6f79505a.png?imageMogr2/auto-orient/strip" data-image-slug="cbbc550a6f79505a" data-width="1042" data-height="112" style="cursor: zoom-in;"><br><div class="image-caption">$意为引用，冒号为分隔符</div>
</div><h2>** Hadoop宏观认知</h2><p>Hadoop项目主要包括以下四个模块</p><h3>Hadoop Common：</h3><p>为其他的Hadoop模块提供基础设施</p><h3>Hadoop HDFS：</h3><p>分布式文件系统</p><h3>Hadoop MapReduce：</h3><p>分布式离线并行计算框架</p><h3>Hadoop YARN：</h3><p>任务调度与资源管理框架</p><p>这里因为篇幅问题，我们只能做一些基础理解，更深入的挖掘需要读者自行研究（因为往下深究所需篇幅，可以单独再开一个专题）</p><h2>** HDFS架构</h2><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-a92b04eef94e0c86.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-a92b04eef94e0c86.png?imageMogr2/auto-orient/strip" data-image-slug="a92b04eef94e0c86" data-width="973" data-height="592" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><h3>总结：</h3><p>1、一个Namenode节点和多个Datanode节点组成</p><p>2、Namenode是一个中心服务器，负责管理文件系统的namespace和客户端对文件的访问。Datanode在集群中一般是一个节点一个，负责管理节点上它们附带的存储。通俗来讲，datanode就是用来存储某个大文件被拆分后的一个一个的小文件。</p><p>3、一个文件分成一个或多个block（数据块，数据块默认大小128M），这些block存储在Datanode集合里。</p><p>4、一般而言，一台机器跑一个单独的Namenode节点，集群中的其它机器各跑一个Datanode实例（当然也有一个台机器跑多个Datanode）。</p><p>5、Namenode中存放的有元数据（Metadata），比如：映射关系表（哪些数据块block存储在了哪些datanode节点中）</p><h2>** YARN架构</h2><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-456a25e27d344542.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-456a25e27d344542.png?imageMogr2/auto-orient/strip" data-image-slug="456a25e27d344542" data-width="993" data-height="489" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><h3>总结：</h3><p>yarn主要负责任务调度和资源管理的，比如，集群中，哪些机器还剩余多少CPU多少内存可用，集群中，还有哪些机器可以用来处理新的任务等等。</p><p>1、ResourceManager(RM)：主要接收客户端任务请求，接收和监控NodeManager(NM)的资源情况汇报，负责资源的分配与调度，启动和监控ApplicationMaster(AM)。</p><p>2、NodeManager：主要是节点上的资源管理，启动Container运行task计算，上报资源、负责把container情况给ResourceManager，把任务处理情况给ApplicationMaster。</p><p>3、
ApplicationMaster：主要是单个Application(Job)的task管理和调度，向ResourceManager进行资源的申
请，向NodeManager发出launch Container指令，接收NodeManager的task处理状态信息。</p><h3>yarn工作流程：</h3><p>1、client submit提交一个Job到ResourceManager，进入ResourceManager中的Scheduler队列供调度</p><p>2、
ResourceManager根据NodeManager汇报的资源情况(NodeManager会定时汇报资源和container使用情况)，请求
一个合适的NodeManager launch container，在该NodeManager所在机器启动运行ApplicationMaster</p><p>3、ApplicationMaster启动后，注册到ResourceManager上，以便client可以查到ApplicationMaster的信息，便于client直接和ApplicationMaster通信</p><p>4、ApplicationMaster启动后，根据Job相关情况，会和ResourceManager协商申请container资源</p><p>5、ResourceManager分配给ApplicationMaster container资源后，根据container的信息，向对应的NodeManager请求launch container</p><p>6、NodeManager启动container运行task，运行过程中向ApplicationMaster汇报进度状态信息，同时NodeManager也会定时的向ResourceManager汇报container的使用情况。</p><p>7、在application(job)执行过程中，client可以和ApplicationMaster通信，获取application相关的进度和状态信息。</p><p>8、在application(job)完成后，ApplicationMaster通知ResourceManager清除自己的相关信息（即AM自己关闭自己），并关闭，释放自己占用的container。</p><h3>尖叫提示：Container为何物？</h3><p>Container：</p><p>1、Container是yarn框架中对于资源的抽象描述，它封装了某个节点上一定量的资源（CPU与内存），你可以理解为Container是一个Java类，里面封装了对于资源的一系列描述，还封装了当前Job任务运行的片段代码。</p><p>2、Container由ApplicationMaster向ResourceManager申请的，由ResouceManager中的资源调度器异步分配给ApplicationMaster</p><p>3、Container的运行是由ApplicationMaster向资源所在的NodeManager发起的（即运行任务）</p><h3>Container分类：<br>
</h3><p>1、运行用户指定任务（ApplicationMaster）的Container：</p><p>这是由ResourceManager（向内部的资源调度器）申请和启动的，用户提交应用程序时，可指定唯一的ApplicationMaster所需的资源；<br></p><p>2、运行各类任务的Container：</p><p>这是由ApplicationMaster向ResourceManager申请的，并由ApplicationMaster与NodeManager通信以启用该Container<br></p><p>以上两类Container可能在任意节点上，它们的位置通常而言是随机的，即ApplicationMaster可能与它管理的任务运行在一个节点上。<br></p><p><b>相关术语知识点：</b></p><p>（本地松弛：是指如果某台NodeManager所能提供的Container不足，则在本台机架寻找另一台机器是否可以提供，如果本台机架所有机器都不能提供所需Container，则换一台机架找寻）</p><p>（机架感知：有兴趣的同学请查阅相关博客：http://www.cnblogs.com/ggjucheng/archive/2013/01/03/2843015.html，此处不再赘述）</p><h2>** Hadoop基础配置</h2><p>在进行Hadoop配置的时候，我们有时需要借助官方文档，毕竟那么多的配置属性，不是能全部记下来的</p><p>官方文档链接：http://hadoop.apache.org/docs/r2.5.2/</p><p>在我们的案例中，Hadoop的配置文档位于：</p><p>/opt/modules/hadoop-2.5.0/etc/hadoop<br></p><p>进入该目录，查看该目录文件结构如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-589844d539372dbe.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-589844d539372dbe.png?imageMogr2/auto-orient/strip" data-image-slug="589844d539372dbe" data-width="1671" data-height="94" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>我们配置Hadoop就是配置这里面的xml文件和sh脚本文件，如果使用vi编辑器配置的话，可能不太习惯？那么接下来我们聊聊怎么使用Notepad++来配置（没有该软件的请自行下载）</p><p>打开Notepad++，如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-589bea39d3e0c61b.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-589bea39d3e0c61b.png?imageMogr2/auto-orient/strip" data-image-slug="589bea39d3e0c61b" data-width="1913" data-height="965" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>如图所示3个地方需要注意：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-dd9fb99b8ae324bc.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-dd9fb99b8ae324bc.png?imageMogr2/auto-orient/strip" data-image-slug="dd9fb99b8ae324bc" data-width="1913" data-height="973" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>1、红框：是否开启NppFTP视图，即右边的视图</p><p>2、蓝框：点击后，选择“Profile Settings”弹出绿框内容</p><p>3、绿框：点击Add new，我这边添加了一个z01，hostname主机名为z01，port端口号为：22，Username登录系统的用户为z，Password密码为你设置的该用户的密码</p><p>配置完成后，如下图，点击框内按钮，连接登录：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-238d0f29cb3fcd03.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-238d0f29cb3fcd03.png?imageMogr2/auto-orient/strip" data-image-slug="238d0f29cb3fcd03" data-width="255" data-height="90" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>登录成功如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-120f8d7509a9cac0.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-120f8d7509a9cac0.png?imageMogr2/auto-orient/strip" data-image-slug="120f8d7509a9cac0" data-width="416" data-height="410" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>进入到/opt/modules/hadoop-2.5.0/etc/hadoop目录，即可使用Notepad++来编辑文本内容了，方便多了~</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-0051c31f3ac2b23b.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-0051c31f3ac2b23b.png?imageMogr2/auto-orient/strip" data-image-slug="0051c31f3ac2b23b" data-width="348" data-height="278" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><h3>配置正式开始</h3><h4>1、首先修改3个.sh文件中的JDK路径</h4><p>该3个文件分别是：</p><p><b>hadoop-env.sh</b></p><p><b>mapred-env.sh</b></p><p><b>yarn-env.sh</b></p><p>修改内容为：</p><p>export JAVA_HOME=/opt/modules/jdk1.8.0_111,如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-9a5302763c2fe08e.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-9a5302763c2fe08e.png?imageMogr2/auto-orient/strip" data-image-slug="9a5302763c2fe08e" data-width="472" data-height="54" style="cursor: zoom-in;"><br><div class="image-caption">修改后记得保存</div>
</div><h4>2、hdfs配置</h4><p><b>* core-site.xml</b></p><p>官方文档说明：http://hadoop.apache.org/docs/r2.5.2/hadoop-project-dist/hadoop-common/core-default.xml</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-a5044db60f9142e1.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-a5044db60f9142e1.png?imageMogr2/auto-orient/strip" data-image-slug="a5044db60f9142e1" data-width="561" data-height="310" style="cursor: zoom-in;"><br><div class="image-caption">修改后记得保存</div>
</div><p>属性解释：</p><p><b>fs.defaultFS</b>：HDFS集群访问入口地址，其中z01也可以换成当前Linux的本机ip，如果此时你还没有在Linux中设置主机名映射，请参照之前Linux中的知识点进行设置即可。</p><p><b>hadoop.tmp.dir</b>：数据存放路径</p><p><b>* hdfs-site.xml</b></p><p>官方文档说明：http://hadoop.apache.org/docs/r2.5.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-c192d71de3f15dab.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-c192d71de3f15dab.png?imageMogr2/auto-orient/strip" data-image-slug="c192d71de3f15dab" data-width="385" data-height="144" style="cursor: zoom-in;"><br><div class="image-caption">修改后记得保存</div>
</div><p>属性解释：</p><p><b>dfs.replication</b>：数据块副本数，默认为3。</p><p><b>* slaves</b></p><p>声明哪些服务器是datanode，每行一个主机名即可。</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-8b1eee686fe2d7c3.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-8b1eee686fe2d7c3.png?imageMogr2/auto-orient/strip" data-image-slug="8b1eee686fe2d7c3" data-width="356" data-height="174" style="cursor: zoom-in;"><br><div class="image-caption">此案例我们只设置1个，即当前虚拟机机器</div>
</div><h4>3、yarn配置</h4><p><b>* yarn-site.xml</b></p><p>官方文档：http://hadoop.apache.org/docs/r2.5.2/hadoop-yarn/hadoop-yarn-common/yarn-default.xml</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-b5896c8d40bc7f23.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-b5896c8d40bc7f23.png?imageMogr2/auto-orient/strip" data-image-slug="b5896c8d40bc7f23" data-width="619" data-height="588" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>属性解释：</p><p><b>yarn.nodemanager.aux-services</b>：NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序</p><p><b>yarn.resourcemanager.hostname</b>：resourcemanager的主机名，即哪一台主机当做ResourceManager</p><p><b>yarn.log-aggregation-enable</b>：是否开启日志聚合功能<br></p><p><b>yarn.log-aggregation.retain-seconds</b>：在HDFS上聚集的日志最多保存多长时间，单位：秒，86400相当于24小时</p><p>其他属性：</p><p><b>yarn.nodemanager.resource.memory-mb</b>：表示该节点上yarn可使用的物理内存总量，默认是8192MB，如果该节点机器的内存不足8G，则需要调小这个值，yarn不会智能的探测节点的物理内存总量。</p><p><b>yarn.nodemanager.vmem-pmem-ratio</b>：任务每使用1MB物理内存，最多可使用的虚拟内存量，默认为2.1。</p><p><b>yarn.nodemanager.pmem-check-enabled</b>：是否启动一个县城检查每个任务正在使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认值为true。</p><p><b>yarn.nodemanager.vmem-check-enabled</b>：是否启动一个线程检查每个任务正在使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认值为true。</p><p><b>yarn.scheduler.minimum-allocation-mb</b>：单个任务可申请的最少物理内存量，默认是1024MB，如果一个任务申请的物理内存量少于该值，则对应的值改为这个数。</p><p><b>yarn.scheduler.maximum-allocation-mb</b>：单个任务可申请的最多物理内存量，默认是8192MB。</p><h4>4、map-reduce配置</h4><p><b>* mapred-site.xml</b></p><p>官方文档：http://hadoop.apache.org/docs/r2.5.2/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-1268ac1145bcda88.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-1268ac1145bcda88.png?imageMogr2/auto-orient/strip" data-image-slug="1268ac1145bcda88" data-width="615" data-height="390" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>属性解释：<br></p><p><b>mapreduce.framework.name</b>：设置运行MapReduce任务的框架</p><p><b>mapreduce.jobhistory.address</b>：
自带了一个历史服务器，可以通过历史服务器查看已经运行完的Mapreduce作业记录，比如用了多少个Map、用了多少个Reduce、作业提交时间、
作业启动时间、作业完成时间等信息。默认情况下，Hadoop历史服务器是没有启动的。配置该地址后，启动服务就可以通过Web 
UI来查看具体使用详情了。<br></p><p><b>mapreduce.jobhistory.webapp.address</b>：web app客户端的访问入口<br></p><h3>** 启动服务</h3><p>启动过程分为如下几个过程：</p><h4>* 格式化hdfs</h4><p>由于当前主机第一次使用hdfs系统，所以使用之前需要先格式化</p><p>进入到/opt/modules/hadoop-2.5.0目录下</p><p>使用命令(#代表root用户下输入，$代表普通用户下输入，输入命令时注意不要加#或$，此处写上只为注明)</p><p>$ bin/hdfs namenode -format，成功格式化后如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-160391eddfcc1338.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-160391eddfcc1338.png?imageMogr2/auto-orient/strip" data-image-slug="160391eddfcc1338" data-width="1885" data-height="851" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-b326f2df03442eba.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-b326f2df03442eba.png?imageMogr2/auto-orient/strip" data-image-slug="b326f2df03442eba" data-width="1587" data-height="846" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p><br></p><h4>* 启动hdfs相关服务</h4><p>使用命令：</p><p>$ sbin/hadoop-daemon.sh start namenode：开启nodenode节点服务</p><p>$ sbin/hadoop-daemon.sh start datanode：开启datanode节点服务</p><p>最后通过jps命令来查看进程是否启动成功</p><p>如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-9f28390ea35e3f54.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-9f28390ea35e3f54.png?imageMogr2/auto-orient/strip" data-image-slug="9f28390ea35e3f54" data-width="1126" data-height="180" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>此时可以通过浏览器成功访问hdfs管理平台：http://z01:50070，如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-17943b15569a834e.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-17943b15569a834e.png?imageMogr2/auto-orient/strip" data-image-slug="17943b15569a834e" data-width="1920" data-height="910" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><h4>* 启动yarn相关服务</h4><p>使用命令：</p><p>$ sbin/yarn-daemon.sh start resourcemanager：开启resourcemanager</p><p>$ sbin/yarn-daemon.sh start nodemanager：开启nodemanager</p><p>完成后使用jps检查是否启动成功，如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-1391d94adaa9a4db.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-1391d94adaa9a4db.png?imageMogr2/auto-orient/strip" data-image-slug="1391d94adaa9a4db" data-width="1137" data-height="212" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>此时可以通过浏览器成功访问yarn管理平台：http://z01:8088，如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-fdccced95ea88559.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-fdccced95ea88559.png?imageMogr2/auto-orient/strip" data-image-slug="fdccced95ea88559" data-width="1920" data-height="910" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>$ sbin/mr-jobhistory-daemon.sh start historyserver：开启historyserver服务，如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-68ff81fe681d61ab.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-68ff81fe681d61ab.png?imageMogr2/auto-orient/strip" data-image-slug="68ff81fe681d61ab" data-width="1113" data-height="188" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>OK，所有的服务都已经准备完成了，下面我们来做一个小测试。</p><h2>** 测试</h2><p>经典案例：官方Demo单词统计</p><p>我们下面要做的一个案例是官方的demo，用于统计单词出现的频率，首先我们需要创建一个文档，里面有若干英文单词，然后把这个文档上传到hdfs系统中，等待mapreduce计算，最后查看结果。</p><p><b>1、创建包含若干单词的words.txt文档，注意单词用空格或者tab分割</b>，创建位置为：/opt/modules/hadoop-2.5.0，如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-dafb9ef5433d428c.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-dafb9ef5433d428c.png?imageMogr2/auto-orient/strip" data-image-slug="dafb9ef5433d428c" data-width="1920" data-height="842" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-a3eba84bc9696f94.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-a3eba84bc9696f94.png?imageMogr2/auto-orient/strip" data-image-slug="a3eba84bc9696f94" data-width="820" data-height="48" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p><b>2、在hdfs系统中创建/input/目录</b></p><p>使用命令：</p><p>$ bin/hdfs dfs -mkdir /input，如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-ba8f0ee2418f4d41.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-ba8f0ee2418f4d41.png?imageMogr2/auto-orient/strip" data-image-slug="ba8f0ee2418f4d41" data-width="612" data-height="26" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p><b>3、上传words.txt文档到该目录下</b></p><p>使用命令：</p><p>$ bin/hdfs dfs -put words.txt /input，如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-6b7b08a8a7f01d18.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-6b7b08a8a7f01d18.png?imageMogr2/auto-orient/strip" data-image-slug="6b7b08a8a7f01d18" data-width="698" data-height="27" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p><b>4、查看已上传的文件内容</b></p><p>使用命令：</p><p>$ bin/hdfs dfs -cat /input/words.txt，如图：<br></p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-6959817640427805.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-6959817640427805.png?imageMogr2/auto-orient/strip" data-image-slug="6959817640427805" data-width="661" data-height="94" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p><b>尖叫提示：当然bin/hdfs dfs中还有一些其他命令，读者可以通过输入$ bin/hdfs dfs来查看使用方式，如图：</b></p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-9c997eead9fe2ecb.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-9c997eead9fe2ecb.png?imageMogr2/auto-orient/strip" data-image-slug="9c997eead9fe2ecb" data-width="1068" data-height="771" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p><b>5、运行任务</b></p><p>使用命令：</p><p>$ bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0.jar wordcount /input/ /output/</p><p>解释：</p><p>/input/：hdfs中的路径，表示输入路径<br></p><p>/output/：hdfs中的路径，表示输出路径（统计结果会在这个目录下）<br></p><p>运行后，会出现如下内容：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-131ceef1d0832c48.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-131ceef1d0832c48.png?imageMogr2/auto-orient/strip" data-image-slug="131ceef1d0832c48" data-width="1376" data-height="201" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-7fdc0e4064058497.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-7fdc0e4064058497.png?imageMogr2/auto-orient/strip" data-image-slug="7fdc0e4064058497" data-width="1446" data-height="848" style="cursor: zoom-in;"><br><div class="image-caption">注意红框中内容的变化</div>
</div><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-8ec0777ada557084.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-8ec0777ada557084.png?imageMogr2/auto-orient/strip" data-image-slug="8ec0777ada557084" data-width="925" data-height="847" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>此时，任务已经执行完毕，下面我们来看一看执行的结果</p><p>使用命令：</p><p>$ bin/hdfs dfs -cat /output/par* ：查看output这个输出目录下的所有以par开头的文件内容（为何是par开头，稍后解释）</p><p>如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-eff0d494fba09906.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-eff0d494fba09906.png?imageMogr2/auto-orient/strip" data-image-slug="eff0d494fba09906" data-width="634" data-height="236" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>如图，单词出现频率已经出来了，下面我们来看一下web app中的变化。</p><p>6、查看web app：</p><h4>hdfs（http://z01:50070）：</h4><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-fc3e98cd4fc99c01.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-fc3e98cd4fc99c01.png?imageMogr2/auto-orient/strip" data-image-slug="fc3e98cd4fc99c01" data-width="1869" data-height="872" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>点击红框内容，选择“Browse the file system”，在搜索框中输入：/,点击GO，如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-132828e96f7ae3b5.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-132828e96f7ae3b5.png?imageMogr2/auto-orient/strip" data-image-slug="132828e96f7ae3b5" data-width="1313" data-height="322" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>在此你可以看到你的hdfs系统中的目录结构，分别点开input和output，我们来瞟一眼：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-d0c416765f9fd14a.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-d0c416765f9fd14a.png?imageMogr2/auto-orient/strip" data-image-slug="d0c416765f9fd14a" data-width="1228" data-height="224" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-72b9e4afac2bb2bd.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-72b9e4afac2bb2bd.png?imageMogr2/auto-orient/strip" data-image-slug="72b9e4afac2bb2bd" data-width="1198" data-height="266" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>注意此时output中红框内容，这就解释了为何我们刚才查看结果的时候，要查看的是par开头的文件，因为输出结果的默认文件名就是这个。</p><h4>yarn（http://z01:8088）：</h4><p>下面我们再来看看yarn平台的内容变化，刷新yarn平台后，你会发现多了一条内容：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-60727238a51936ef.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-60727238a51936ef.png?imageMogr2/auto-orient/strip" data-image-slug="60727238a51936ef" data-width="1905" data-height="379" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>点击history，我们进去瞟一眼？如图：</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-449cf64ae9d90c9a.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-449cf64ae9d90c9a.png?imageMogr2/auto-orient/strip" data-image-slug="449cf64ae9d90c9a" data-width="1920" data-height="910" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>里面展示了任务的一些特征，比如开始时间，map和reduce数量，耗时，状态等等。</p><h1>** 总结</h1><p>这就是hadoop平台的基本搭建，望对你所有帮~掌声~（收！）</p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-fb1193e1e41da09d.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-fb1193e1e41da09d.png?imageMogr2/auto-orient/strip" data-image-slug="fb1193e1e41da09d" data-width="153" data-height="256" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p>个人微博：http://weibo.com/seal13<br></p><p>QQ大数据技术交流群（广告勿入）：476966007</p><p><br></p><div class="image-package">
<img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/4951489-62ba58fe1377a8ce.png" data-original-src="http://upload-images.jianshu.io/upload_images/4951489-62ba58fe1377a8ce.png?imageMogr2/auto-orient/strip" data-image-slug="62ba58fe1377a8ce" data-width="280" data-height="355" style="cursor: zoom-in;"><br><div class="image-caption"></div>
</div><p><a href="http://www.jianshu.com/p/5265216ef648" target="_blank">下一节：Hadoop框架基础（二）</a><br></p>
        </div>
        <!--  -->

        <div class="show-foot">
          <a class="notebook" href="http://www.jianshu.com/nb/10277662">
            <i class="iconfont ic-search-notebook"></i> <span>BigData</span>
</a>          <div class="copyright" data-toggle="tooltip" data-html="true" data-original-title="转载请联系作者获得授权，并标注“简书作者”。">
            © 著作权归作者所有
          </div>
          <div class="modal-wrap" data-report-note="">
            <a id="report-modal">举报文章</a>
          </div>
        </div>
    </div>

    <!-- 文章底部作者信息 -->
      <div class="follow-detail">
        <div class="info">
          <a class="avatar" href="http://www.jianshu.com/u/a39ddf86b31d">
            <img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/b5933287-2239-4028-a7e0-8d87958ac06f.jpg" alt="144">
</a>          <a class="btn btn-success follow"><i class="iconfont ic-follow"></i><span>关注</span></a>
          <a class="title" href="http://www.jianshu.com/u/a39ddf86b31d">Z尽际</a>
            <i class="iconfont ic-man"></i>
        <p>写了 69304 字，被 107 人关注，获得了 112 个喜欢</p></div>
          <div class="signature">年轻人，应该了解处于风口浪尖的一切科技。</div>
      </div>

      <div class="support-author"></div>

    <div class="meta-bottom">
      <div class="like"><div class="btn like-group"><div class="btn-like"><a href="http://www.jianshu.com/sign_in"><i class="iconfont ic-like"></i>喜欢</a></div> <div class="modal-wrap"><a>7</a></div></div> <!----></div>
      <div class="share-group">
        <a class="share-circle" data-action="weixin-share" data-toggle="tooltip" data-original-title="分享到微信">
          <i class="iconfont ic-wechat"></i>
        </a>
        <a class="share-circle" data-toggle="tooltip" href="javascript:void((function(s,d,e,r,l,p,t,z,c){var%20f='http://v.t.sina.com.cn/share/share.php?appkey=1881139527',u=z||d.location,p=['&amp;url=',e(u),'&amp;title=',e(t||d.title),'&amp;source=',e(r),'&amp;sourceUrl=',e(l),'&amp;content=',c||'gb2312','&amp;pic=',e(p||'')].join('');function%20a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=440,height=430,left=',(s.width-440)/2,',top=',(s.height-430)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent))setTimeout(a,0);else%20a();})(screen,document,encodeURIComponent,'','','http://cwb.assets.jianshu.io/notes/images/9973710/weibo/image_9d239005fd8b.jpg',%20'%E6%8E%A8%E8%8D%90%20@%E5%B0%BD%E9%99%85iActivity%20%E7%9A%84%E6%96%87%E7%AB%A0%E3%80%8AHadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%E3%80%8B%EF%BC%88%20%E5%88%86%E4%BA%AB%E8%87%AA%20@%E7%AE%80%E4%B9%A6%20%EF%BC%89','http://www.jianshu.com/p/691544a9738f?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=weibo','%E9%A1%B5%E9%9D%A2%E7%BC%96%E7%A0%81gb2312|utf-8%E9%BB%98%E8%AE%A4gb2312'));" data-original-title="分享到微博">
          <i class="iconfont ic-weibo"></i>
        </a>
          <a class="share-circle" data-toggle="tooltip" href="http://cwb.assets.jianshu.io/notes/images/9973710/weibo/image_9d239005fd8b.jpg" target="_blank" data-original-title="下载长微博图片">
            <i class="iconfont ic-picture"></i>
          </a>
        <a class="share-circle more-share" tabindex="0" data-toggle="popover" data-placement="top" data-html="true" data-trigger="focus" href="javascript:void(0);" data-content="
          &lt;ul class=&quot;share-list&quot;&gt;
            &lt;li&gt;&lt;a href=&quot;javascript:void(function(){var d=document,e=encodeURIComponent,r='http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url='+e('http://www.jianshu.com/p/691544a9738f?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=qzone')+'&amp;title='+e('推荐 Z尽际 的文章《Hadoop框架基础（一）》'),x=function(){if(!window.open(r,'qzone','toolbar=0,resizable=1,scrollbars=yes,status=1,width=600,height=600'))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();&quot;&gt;&lt;i class=&quot;social-icon-sprite social-icon-zone&quot;&gt;&lt;/i&gt;&lt;span&gt;分享到QQ空间&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&quot;javascript:void(function(){var d=document,e=encodeURIComponent,r='https://twitter.com/share?url='+e('http://www.jianshu.com/p/691544a9738f?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=twitter')+'&amp;text='+e('推荐 Z尽际 的文章《Hadoop框架基础（一）》（ 分享自 @jianshucom ）')+'&amp;related='+e('jianshucom'),x=function(){if(!window.open(r,'twitter','toolbar=0,resizable=1,scrollbars=yes,status=1,width=600,height=600'))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();&quot;&gt;&lt;i class=&quot;social-icon-sprite social-icon-twitter&quot;&gt;&lt;/i&gt;&lt;span&gt;分享到Twitter&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&quot;javascript:void(function(){var d=document,e=encodeURIComponent,r='https://www.facebook.com/dialog/share?app_id=483126645039390&amp;display=popup&amp;href=http://www.jianshu.com/p/691544a9738f?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=facebook',x=function(){if(!window.open(r,'facebook','toolbar=0,resizable=1,scrollbars=yes,status=1,width=450,height=330'))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();&quot;&gt;&lt;i class=&quot;social-icon-sprite social-icon-facebook&quot;&gt;&lt;/i&gt;&lt;span&gt;分享到Facebook&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&quot;javascript:void(function(){var d=document,e=encodeURIComponent,r='https://plus.google.com/share?url='+e('http://www.jianshu.com/p/691544a9738f?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=google_plus'),x=function(){if(!window.open(r,'google_plus','toolbar=0,resizable=1,scrollbars=yes,status=1,width=450,height=330'))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();&quot;&gt;&lt;i class=&quot;social-icon-sprite social-icon-google&quot;&gt;&lt;/i&gt;&lt;span&gt;分享到Google+&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&quot;javascript:void(function(){var d=document,e=encodeURIComponent,s1=window.getSelection,s2=d.getSelection,s3=d.selection,s=s1?s1():s2?s2():s3?s3.createRange().text:'',r='http://www.douban.com/recommend/?url='+e('http://www.jianshu.com/p/691544a9738f?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=douban')+'&amp;title='+e('Hadoop框架基础（一）')+'&amp;sel='+e(s)+'&amp;v=1',x=function(){if(!window.open(r,'douban','toolbar=0,resizable=1,scrollbars=yes,status=1,width=450,height=330'))location.href=r+'&amp;r=1'};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})()&quot;&gt;&lt;i class=&quot;social-icon-sprite social-icon-douban&quot;&gt;&lt;/i&gt;&lt;span&gt;分享到豆瓣&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        " data-original-title="" title="">更多分享</a>
      </div>
    </div>
    <div id="vue_comment"></div>
  </div>

  <div class="side-tool"><ul><li data-placement="left" data-toggle="tooltip" data-container="body" data-original-title="回到顶部" style=""><a class="function-button"><i class="iconfont ic-backtop"></i></a></li> <!----> <!----> <li data-placement="left" data-toggle="tooltip" data-container="body" data-original-title="分享文章"><a tabindex="0" role="button" data-toggle="popover" data-placement="left" data-html="true" data-trigger="focus" href="javascript:void(0);" data-content="&lt;ul class='share-list'&gt;
                &lt;li&gt;&lt;a class=&quot;weixin-share&quot;&gt;&lt;i class=&quot;social-icon-sprite social-icon-weixin&quot;&gt;&lt;/i&gt;&lt;span&gt;分享到微信&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href=&quot;javascript:void((function(s,d,e,r,l,p,t,z,c){var%20f='http://v.t.sina.com.cn/share/share.php?appkey=1881139527',u=z||d.location,p=['&amp;url=',e(u),'&amp;title=',e(t||d.title),'&amp;source=',e(r),'&amp;sourceUrl=',e(l),'&amp;content=',c||'gb2312','&amp;pic=',e(p||'')].join('');function%20a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=440,height=430,left=',(s.width-440)/2,',top=',(s.height-430)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent))setTimeout(a,0);else%20a();})(screen,document,encodeURIComponent,'','','http://cwb.assets.jianshu.io/notes/images/9973710/weibo/image_9d239005fd8b.jpg', '推荐 @尽际iActivity 的文章《Hadoop框架基础（一）》（ 分享自 @简书 ）','http://www.jianshu.com/p/691544a9738f?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=weibo','页面编码gb2312|utf-8默认gb2312'));&quot;&gt;&lt;i class='social-icon-sprite social-icon-weibo'&gt;&lt;/i&gt;&lt;span&gt;分享到微博&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href=&quot;http://cwb.assets.jianshu.io/notes/images/9973710/weibo/image_9d239005fd8b.jpg&quot; target=&quot;_blank&quot;&gt;&lt;i class=&quot;social-icon-sprite social-icon-picture&quot;&gt;&lt;/i&gt;&lt;span&gt;下载长微博图片&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href=&quot;javascript:void(function(){var d=document,e=encodeURIComponent,r='http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url='+e('http://www.jianshu.com/p/691544a9738f?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=qzone')+'&amp;title='+e('推荐 Z尽际 的文章《Hadoop框架基础（一）》'),x=function(){if(!window.open(r,'qzone','toolbar=0,resizable=1,scrollbars=yes,status=1,width=600,height=600'))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();&quot;&gt;&lt;i class='social-icon-sprite social-icon-zone'&gt;&lt;/i&gt;&lt;span&gt;分享到QQ空间&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href=&quot;javascript:void(function(){var d=document,e=encodeURIComponent,r='https://twitter.com/share?url='+e('http://www.jianshu.com/p/691544a9738f?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=twitter')+'&amp;text='+e('推荐 Z尽际 的文章《Hadoop框架基础（一）》（ 分享自 @jianshucom ）')+'&amp;related='+e('jianshucom'),x=function(){if(!window.open(r,'twitter','toolbar=0,resizable=1,scrollbars=yes,status=1,width=600,height=600'))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();&quot;&gt;&lt;i class='social-icon-sprite social-icon-twitter'&gt;&lt;/i&gt;&lt;span&gt;分享到Twitter&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href=&quot;javascript:void(function(){var d=document,e=encodeURIComponent,r='https://www.facebook.com/dialog/share?app_id=483126645039390&amp;display=popup&amp;href=http://www.jianshu.com/p/691544a9738f?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=facebook',x=function(){if(!window.open(r,'facebook','toolbar=0,resizable=1,scrollbars=yes,status=1,width=450,height=330'))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();&quot;&gt;&lt;i class='social-icon-sprite social-icon-facebook'&gt;&lt;/i&gt;&lt;span&gt;分享到Facebook&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href=&quot;javascript:void(function(){var d=document,e=encodeURIComponent,r='https://plus.google.com/share?url='+e('http://www.jianshu.com/p/691544a9738f?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=google_plus'),x=function(){if(!window.open(r,'google_plus','toolbar=0,resizable=1,scrollbars=yes,status=1,width=450,height=330'))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();&quot;&gt;&lt;i class='social-icon-sprite social-icon-google'&gt;&lt;/i&gt;&lt;span&gt;分享到Google+&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href=&quot;javascript:void(function(){var d=document,e=encodeURIComponent,s1=window.getSelection,s2=d.getSelection,s3=d.selection,s=s1?s1():s2?s2():s3?s3.createRange().text:'',r='http://www.douban.com/recommend/?url='+e('http://www.jianshu.com/p/691544a9738f?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=douban')+'&amp;title='+e('Hadoop框架基础（一）')+'&amp;sel='+e(s)+'&amp;v=1',x=function(){if(!window.open(r,'douban','toolbar=0,resizable=1,scrollbars=yes,status=1,width=450,height=330'))location.href=r+'&amp;r=1'};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})()&quot;&gt;&lt;i class='social-icon-sprite social-icon-douban'&gt;&lt;/i&gt;&lt;span&gt;分享到豆瓣&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
              &lt;/ul&gt;" data-original-title="" title="" class="function-button"><i class="iconfont ic-share"></i></a> <!----></li></ul></div>
</div>
<div class="note-bottom">
  <div><div class="main"><div class="title">被以下专题收入，发现更多相似内容</div> <!----> <div class="include-collection"><!----> <a href="http://www.jianshu.com/c/d2f9d733c6c8?utm_source=desktop&amp;utm_medium=notes-included-collection" target="_blank" class="item"><img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/timg.jpg"><div class="name">Linux大数据教程</div></a><a href="http://www.jianshu.com/c/V2CqjW?utm_source=desktop&amp;utm_medium=notes-included-collection" target="_blank" class="item"><img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/6249340_194140034135_2.jpg"><div class="name">@IT·互联网</div></a><a href="http://www.jianshu.com/c/5c09c028a281?utm_source=desktop&amp;utm_medium=notes-included-collection" target="_blank" class="item"><img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/20140107_32188.jpg"><div class="name">Hadoop</div></a><a href="http://www.jianshu.com/c/86ff829f995f?utm_source=desktop&amp;utm_medium=notes-included-collection" target="_blank" class="item"><img src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/u_2582065815_2360012304_fm_21_gp_0.jpg"><div class="name">大数据核心技术&amp;科普</div></a> <!----></div></div> <!----> <!----></div>
  <div data-vcomp="recommended-notes" data-note-id="9973710"></div>
</div>

    <script src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/push.js"></script><script src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/hm.js"></script><script async="" src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/analytics.js"></script><script type="application/json" data-name="page-data">{"user_signed_in":false,"locale":"zh-CN","os":"windows","read_mode":"day","read_font":"font2","note_show":{"is_author":false,"is_following_author":false,"is_liked_note":false,"uuid":"62d6fb14-f7f9-44f1-affe-1c90c84c4049"},"note":{"id":9973710,"slug":"691544a9738f","user_id":4951489,"notebook_id":10277662,"commentable":true,"likes_count":7,"views_count":204,"public_wordage":4627,"comments_count":0,"total_rewards_count":0,"is_author":false,"author":{"nickname":"Z尽际","total_wordage":69304,"followers_count":107,"total_likes_count":112}}}</script>
    
    <script src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/babel-polyfill-879c5f4bc085ce8a6153.js"></script>
    <script src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/web-base-60bef14f05f21a4581be.js"></script>
<script src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/web-480e049f44d3eb16dea8.js"></script>
    
    <script src="Hadoop%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%20-%20%E7%AE%80%E4%B9%A6_files/entry-e304fd423c162fd5a868.js"></script>
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-35169517-1', 'auto');
  ga('send', 'pageview');
</script>

<script>
  var _hmt = _hmt || [];
  (function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?0c0e9d9b1e7d617b3e6842e85b9fb068";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
  })();
</script>

<script>
  (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      }
      else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
  })();
</script>

  

<!----><!----></body></html>